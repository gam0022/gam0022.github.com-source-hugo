<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gam0022.net</title>
    <link>https://gam0022.net/tags/%E3%83%AC%E3%82%A4%E3%83%9E%E3%83%BC%E3%83%81%E3%83%B3%E3%82%B0/index.xml</link>
    <description>Recent content on gam0022.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp</language>
    <copyright>&amp;copy; 2016 gam0022</copyright>
    <atom:link href="/tags/%E3%83%AC%E3%82%A4%E3%83%9E%E3%83%BC%E3%83%81%E3%83%B3%E3%82%B0/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>メガデモ勉強会2021で発表しました</title>
      <link>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</link>
      <pubDate>Mon, 15 Feb 2021 13:26:18 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2021/02/15/demoscene-study-session/</guid>
      <description>&lt;p&gt;昨日の2/14（バレンタインデー）に開催された&lt;a href=&#34;https://connpass.com/event/200294/&#34;&gt;The Tokyo Demo Fest team presents: メガデモ勉強会2021&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;私は「64KBのWebGLデモを実装する技術とデモ制作から得た『学びと発見』」というタイトルで発表を行いました。&lt;/p&gt;

&lt;p&gt;発表スライドはこちらです。&lt;/p&gt;

&lt;iframe src=&#34;https://docs.google.com/presentation/d/e/2PACX-1vRd-L7WcWWzcoE9zNpBsJdeMjJf9HelDg1Pto8cFGJTjinejpjZ1mGmzWCZPANJZ0QOCObuVOIdPuy-/embed?start=false&amp;loop=false&amp;delayms=3000&#34; frameborder=&#34;0&#34; width=&#34;960&#34; height=&#34;569&#34; allowfullscreen=&#34;true&#34; mozallowfullscreen=&#34;true&#34; webkitallowfullscreen=&#34;true&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; の発表資料です！&lt;br&gt;&lt;br&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決について解説しました。&lt;br&gt;&lt;br&gt;レイマーチングはいいぞ！&lt;a href=&#34;https://t.co/QWHOXHmZqu&#34;&gt;https://t.co/QWHOXHmZqu&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1360889255669633024?ref_src=twsrc%5Etfw&#34;&gt;February 14, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Revision2020のPC 64K Introで優勝したデモ作品『RE: SIMULATED』を題材にして、効率的なデモ制作に必要なエディタ機能やWebGLのプロジェクトの構成、制作中に直面した問題と解決方法について解説しました。&lt;/p&gt;

&lt;p&gt;発表の締めとして「CGを学ぶことで世界の解像度を上げるのが楽しい」「レイマーチングはCG入門に最適」という持論について語りました。&lt;/p&gt;

&lt;h1 id=&#34;質疑応答と補足&#34;&gt;質疑応答と補足&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;質問1: シェーダーを分割することで容量がどのくらい増えるか？

&lt;ul&gt;
&lt;li&gt;マルチパスを前提のエンジン設計にしたので、シェーダー分割してもTypeScriptのコード量は増えない&lt;/li&gt;
&lt;li&gt;重複コードはzlib（pnginator.rb）で圧縮されるため、シェーダーの圧縮後のコードもほとんど増えない&lt;/li&gt;
&lt;li&gt;前半と後半で2分割したときは45byteだけ増えた（&lt;a href=&#34;https://github.com/gam0022/resimulated/pull/112&#34;&gt;PR&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問2: シェーダーの数と行数について

&lt;ul&gt;
&lt;li&gt;サウンドシェーダーは1ファイル。グラフィックス用のシェーダーは合計10ファイル&lt;/li&gt;
&lt;li&gt;サウンドシェーダーは行数が1800行ほどだが、zlibで効率よく圧縮できるので、最終的なファイル容量にはあまり影響しなかった&lt;/li&gt;
&lt;li&gt;グラフィックス用のシェーダーは最大（宇宙空間のレイマーチング）で700行、最小（Bloomのポストエフェクト）で10行ほど&lt;/li&gt;
&lt;li&gt;用途によって幅があるが、レイマーチング用のシェーダーだと平均して400行くらい&lt;/li&gt;
&lt;li&gt;Shadertoyと同じようにCommonのシェーダーの仕組みも用意したが、重複したシェーダーはzlibで圧縮されるため、容量削減の効果は低かった&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;質問3: ディレクションについて

&lt;ul&gt;
&lt;li&gt;制作前に打ち合わせをしてBPMは決めていた

&lt;ul&gt;
&lt;li&gt;音楽と絵の同期はBPMで行っているので重要&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;方向性は絵が先行&lt;/li&gt;
&lt;li&gt;尺については音楽が先行&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足1: Bloomのポストエフェクトはエンジンのビルトイン機能にした

&lt;ul&gt;
&lt;li&gt;縮小バッファーを利用するマルチパスのBloomにしたので、ビルトインにしたほうがサイズを小さく効率よく実装できそうだったから&lt;/li&gt;
&lt;li&gt;フォント描画用のテクスチャ生成機能などShadertoyにはない仕様も何個か実装した&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;補足2: OpenGLよりWebGLの方がGLSLのコンパイル時間が長い

&lt;ul&gt;
&lt;li&gt;WebGLのデモではなく、OpenGLのexeによるデモにすれば、GLSLのコンパイル時間を短縮できる&lt;/li&gt;
&lt;li&gt;Windows版のChromeおよびFirefoxでは、ANGLEを経由してDirect3D上でWebGLを実現しているため、ANGLEを経由する分だけGLSLコンパイルに時間のかかるケースが多い（&lt;a href=&#34;https://twitter.com/gaziya5/status/1361134297315348482&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chrome.exe --use-angle=gl&lt;/code&gt; というオプション付きでChromeを起動すると、ANGLEを経由せずにWebGLを利用できる（&lt;a href=&#34;https://twitter.com/gaziya5/status/1350418640093413377&#34;&gt;Twitter&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;かなり久しぶりに日本のデモシーンの人たちとワイワイできて楽しかったです！&lt;/p&gt;

&lt;p&gt;最後のTokyoDemoFestは2018年の12月なので、もう2年以上も前なんですよね。時間が経つのは早いです。&lt;/p&gt;

&lt;p&gt;discord上の懇親会では「どうすればライブコーディングを普及できるのか？一般人でも理解できるような実況が必要という仮説」「物理的な会場のクラブの体験とVRの違い」など興味深いお話を聞けて面白かったです。&lt;/p&gt;

&lt;p&gt;素晴らしいイベントを企画・開催してくださったTDFのオーガナイザーのみなさん、本当にありがとうございました！&lt;/p&gt;

&lt;h1 id=&#34;関連記事&#34;&gt;関連記事&lt;/h1&gt;

&lt;p&gt;過去の関連登壇や記事のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2020/04/30/revision2020/&#34;&gt;Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/03/16/demoscene-study-session/&#34;&gt;メガデモ勉強会!2018で発表しました&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2016/02/16/glsl-tech/&#34;&gt;GLSL シェーダテクニック勉強会 #GLSLTechで登壇しました&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;この勉強会も5年前のバレンタインデーだったので何かの運命を感じました&lt;/li&gt;
&lt;li&gt;私がレイマーチングを始めてから5年以上も経過しているのもちょっと驚きでした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました</title>
      <link>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</link>
      <pubDate>Sun, 13 Sep 2020 20:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/09/13/cgworld-vol266/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-09-13-cgworld-vol266/Collage_Fotor.jpg&#34; alt=&#34;CGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました&#34; /&gt;&lt;/p&gt;

&lt;p&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;/p&gt;

&lt;p&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;/p&gt;

&lt;p&gt;この記事をきっかけにCGWORLD読者の方々にもデモシーンに興味をもっていただき、国内のデモシーンが盛り上がっていくことを願っています。&lt;/p&gt;

&lt;p&gt;もちろん自分の活動を知っている方々もお手に取っていただければとても嬉しいです！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;9/10（木）発売のCGWORLD vol.266（2020年10月号）に「デモシーンを支えるプロシージャル技術」という記事を寄稿しました。&lt;br&gt;&lt;br&gt;デモシーンの魅力や、64KB制限で映像作品を創るための3Dモデルやテクスチャのプロシージャル生成について解説しています。&lt;a href=&#34;https://t.co/BPf1txlSxU&#34;&gt;https://t.co/BPf1txlSxU&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/demoscene?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#demoscene&lt;/a&gt; &lt;a href=&#34;https://t.co/XXpCh1xiFw&#34;&gt;pic.twitter.com/XXpCh1xiFw&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ #CEDEC2020 9/4登壇, CGWORLD 10月号 (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1301514617588518915?ref_src=twsrc%5Etfw&#34;&gt;September 3, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;購入方法&#34;&gt;購入方法&lt;/h1&gt;

&lt;p&gt;Amazonのアフェリエイトリンクを貼っておきます。&lt;/p&gt;

&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&amp;bc1=000000&amp;IS2=1&amp;bg1=FFFFFF&amp;fc1=000000&amp;lc1=0000FF&amp;t=gam00220c-22&amp;language=ja_JP&amp;o=9&amp;p=8&amp;l=as4&amp;m=amazon&amp;f=ifr&amp;ref=as_ss_li_til&amp;asins=B08FP5NM5P&amp;linkId=8ed32da93c5253b64ba074583462b34a&#34;&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;Twitter上の反響を認知している範囲でメモしておきます。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;すごい、、表紙に「デモシーン」の文字があるぅ、、！&lt;a href=&#34;https://twitter.com/hashtag/CGWjp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#CGWjp&lt;/a&gt;&lt;/p&gt;&amp;mdash; Setsuko (@setsuko_h) &lt;a href=&#34;https://twitter.com/setsuko_h/status/1303997649582874625?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CGWORLD vol.266「デモシーンを支えるプロシージャル技術」を買ってきて読んだ。ディファードレンダリングか。まさに俺が手を付けようとしてるとこだね。これとエフェクトを何とかしないと勝負にはならないな。&lt;/p&gt;&amp;mdash; gaziya (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1303907439134220288?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;がむさん…！ &lt;a href=&#34;https://t.co/0SV02Jq91M&#34;&gt;pic.twitter.com/0SV02Jq91M&lt;/a&gt;&lt;/p&gt;&amp;mdash; さだきち : sadakkey (@sadakkey) &lt;a href=&#34;https://twitter.com/sadakkey/status/1304006171674640386?ref_src=twsrc%5Etfw&#34;&gt;September 10, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;余談&#34;&gt;余談&lt;/h1&gt;

&lt;p&gt;ついに商業誌デビュー！と思ったら、よく考えたら2007年にWindows100%のフリーゲーム紹介コーナーに自作ゲームがちょっとだけ掲載されたのを思い出しました（当時は中学生）。&lt;/p&gt;

&lt;p&gt;今回は4ページしっかりと担当できましたし、CGWORLDという映像業界において圧倒的な知名度のある雑誌に寄稿する機会をいただけて、本当に嬉しいです。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Revision2020 PC 64K Intro 優勝作品『RE: SIMULATED』の技術解説</title>
      <link>https://gam0022.net/blog/2020/04/30/revision2020/</link>
      <pubDate>Thu, 30 Apr 2020 12:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2020/04/30/revision2020/</guid>
      <description>&lt;p&gt;4月10日～4月13日に世界最大のデモパーティ&lt;a href=&#34;https://2020.revision-party.net/start&#34;&gt;Revision 2020&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;Revision 2020内で開催されたコンペのうち、&lt;a href=&#34;https://2020.revision-party.net/competitions/pc-competitions&#34;&gt;PC 64K Intro&lt;/a&gt;という64KBの容量制約のある部門で『RE: SIMULATED by gam0022 &amp;amp; sadakkey』という作品を発表しました。&lt;/p&gt;

&lt;p&gt;Tokyo Demo Fest 2018に続き、私（&lt;a href=&#34;https://twitter.com/gam0022&#34;&gt;@gam0022&lt;/a&gt;）が映像を、さだきちさん（&lt;a href=&#34;https://twitter.com/sadakkey&#34;&gt;@sadakkey&lt;/a&gt;）が音楽を制作しました。&lt;/p&gt;

&lt;p&gt;……なんと、本作品が参加者投票により1位に選ばれました！
日本人のチームがPC 64K Intro部門で優勝するのは Revision 史上初です。とても嬉しいです！&lt;/p&gt;

&lt;p&gt;本記事では、技術解説をメインに、『RE: SIMULATED by gam0022 &amp;amp; sadakkey』を紹介したいと思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/resimulated-collage.jpg&#34; alt=&#34;resimulated-collage&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;作品へのリンク&#34;&gt;作品へのリンク&lt;/h1&gt;

&lt;p&gt;WebGLとWebAudioによる64K Introなので、最新のChromeと高性能なGPUがあれば、ブラウザ上で動作します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/webgl/64k-intro_resimulated.html&#34;&gt;64KB HTML version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://neort.io/art/bqa4pgs3p9f6qoqnmujg&#34;&gt;NEORT version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;高スペックのPCを持っていない方は、YouTubeの動画をご覧ください。&lt;/p&gt;

&lt;p&gt;フラクタルをつかった映像のビットレートの高い作品ですが、4K解像度を選ぶことである程度は綺麗な状態で見れます。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/tirAdWbceak&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;こちらはpouet（デモシーンのコミュニティサイト）のリンクです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=85260&#34;&gt;RE: SIMULATED by Gam0022 &amp;amp; Sadakkey :: pouët.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;技術解説&#34;&gt;技術解説&lt;/h1&gt;

&lt;p&gt;ソースコードはすべてGitHubに公開しているので、興味がある方はぜひ見てください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated&#34;&gt;gam0022/resimulated: 1st place at Revision 2020 (PC 64K Intro)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;サウンド編についてはさだきちさんが解説されています。あわせてご覧ください！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.klab.com/jp/blog/creative/2020/revision-2020-pc-64k-intro.html&#34;&gt;Revision 2020 のPC 64K INTRO 優勝作品のサウンドについて&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;キーワードとしては、以下の技術が使われています。&lt;/p&gt;

&lt;p&gt;TypeScript, WebGL, WebAudio, webpack, pnginator.rb, Raymarching, GLSL Sound&lt;/p&gt;

&lt;h2 id=&#34;シンプルなwebglエンジン-chromatiq&#34;&gt;シンプルなWebGLエンジン『Chromatiq』&lt;/h2&gt;

&lt;p&gt;64KBの容量制約があるため、Unityやthree.jsといった既存のゲームエンジンやフレームワークを利用せずに、描画用のWebGLエンジンと制作用のツール（エディタ機能）を自作する必要がありました。&lt;/p&gt;

&lt;p&gt;OpenGLやDirectXを使わずに、WebGLを選択した理由は以下です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;WebGLでブラウザ上で動かせれば、手元のPCで動かしてもらえる可能性が高いと考えた

&lt;ul&gt;
&lt;li&gt;自分の作品は映像のビットレートが高く、動画だと綺麗にならない&lt;/li&gt;
&lt;li&gt;手元のPCで実行して綺麗な状態で見てもらいたい&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Webフロントエンドの技術をキャッチアップしたかった&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;そこで、64K Intro向けに&lt;strong&gt;ファイルサイズの最小化を目指したシンプルなWebGLエンジン『Chromatiq』&lt;/strong&gt;を開発しました。&lt;/p&gt;

&lt;p&gt;WebGLエンジンとは言うものの、本当にシンプルで最小限な機能しか &amp;ldquo;現段階では&amp;rdquo; 実装していません。&lt;/p&gt;

&lt;p&gt;なるべく作品に依存した機能は用意したくなかったので、汎用的な設計になっています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;マルチパスのImageShaderによるレンダリング（viewport square）&lt;/li&gt;
&lt;li&gt;ビルドインのBloomのポストエフェクト

&lt;ul&gt;
&lt;li&gt;どんな作品でも利用できそうなので、これだけビルドインにした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TypeScriptからuniformをアニメーションするためのインターフェース&lt;/li&gt;
&lt;li&gt;Shadertoyと互換性のあるGLSL Sound&lt;/li&gt;
&lt;li&gt;オーディオファイルの再生（mp3 / ogg）

&lt;ul&gt;
&lt;li&gt;DAWによる音楽の再生用の機能&lt;/li&gt;
&lt;li&gt;今回は先にDAWで作曲し、後からGLSLに移植する作戦にした&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;フォントをレンダリングするためのcanvasからのテクスチャ生成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;イメージとしてはGLSLエディタを排除したスタンドアローンなShadertoyが近いかもしれません。&lt;/p&gt;

&lt;p&gt;ソースコードは&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/chromatiq.ts&#34;&gt;こちら&lt;/a&gt;です。単一ファイルのTypeScriptで実装しました。&lt;/p&gt;

&lt;p&gt;圧縮後のコードサイズを気にして、変な感じの実装になっているので、微妙に読みづらいかもしれません。&lt;/p&gt;

&lt;p&gt;例えば、フィールド参照の this を頭につけるとコードサイズが増えるため、コンストラクタの中で動的にインスタンスメソッドを定義することで、this の利用を最小限にしたり、
クラス外から値を参照・設定する必要があるデータのみ、フィールドとして定義する方針とています。enumもコードサイズが増えるので禁止にしました。&lt;/p&gt;

&lt;p&gt;製作の終盤から容量が余裕そうなことが判明したので、途中からファイルサイズを考慮するのを止め、mini化の中途半端感は否めないです。
このあたりは、次のデモに向けて改良していきたいと考えています。&lt;/p&gt;

&lt;p&gt;uniform名は基本的にはShadertoyと一致させているのですが、テクスチャのサンプラーはShadertoyを踏襲せずに、直前のパスを参照する &lt;code&gt;iPrevPass&lt;/code&gt; を定義しました。
これによってGLSLを書き換えずにエフェクトの順番を入れ替えたり、気軽にパスを増やしてエフェクトをチェインしやすくしました。
このあたりの仕様も、作品の需要に応じて変更していく可能性は高いです。&lt;/p&gt;

&lt;h2 id=&#34;ファイル圧縮のためのビルドプロセス&#34;&gt;ファイル圧縮のためのビルドプロセス&lt;/h2&gt;

&lt;p&gt;圧縮には&lt;a href=&#34;https://webpack.js.org/&#34;&gt;webpack&lt;/a&gt;と&lt;a href=&#34;https://gist.github.com/gasman/2560551&#34;&gt;pnginator.rb&lt;/a&gt;を利用しています。&lt;/p&gt;

&lt;p&gt;ビルドプロセスを図にしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/build-process.svg&#34; alt=&#34;build-process&#34; /&gt;&lt;/p&gt;

&lt;p&gt;webpackですべてのファイルをbundle.jsという単一のJavaScriptに固めてから、pnginator.rbで自己解凍形式のPNGにしています。&lt;/p&gt;

&lt;p&gt;TypeScriptのminifyは完全にwebpack任せです。&lt;/p&gt;

&lt;p&gt;PNGでは画像データをzlib圧縮するため、画像データではなくても、例えば今回のようなプログラムのソースコードでちゃんと圧縮できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/364c7f76f2787e385161&#34;&gt;GLSLのminifyも検証&lt;/a&gt;はしていて、webpackのLoaderを開発する予定もあったのですが、容量が余裕だったのでGLSLの圧縮はPNG（zlib）だけになりました。&lt;/p&gt;

&lt;p&gt;また、開発用にしか必要ないコードの削除もwebpackの&lt;a href=&#34;https://webpack.js.org/plugins/define-plugin/&#34;&gt;define-plugin&lt;/a&gt;で実現できました。&lt;/p&gt;

&lt;p&gt;webpackとpnginator.rbを組み合わせる手法は、&lt;a href=&#34;https://twitter.com/FMS_Cat&#34;&gt;FMS_Catさん&lt;/a&gt;の&lt;a href=&#34;https://github.com/FMS-Cat/until/&#34;&gt;Until&lt;/a&gt;を参考にしました。&lt;/p&gt;

&lt;p&gt;当初はnode.jsでGLSLのホットリロード機能付きのWebサーバを開発しようと技術検証していたのですが、
要件は&lt;a href=&#34;https://github.com/webpack/webpack-dev-server&#34;&gt;webpack-dev-server&lt;/a&gt;ですべて実現可能だったので、webpackを採用しました。&lt;/p&gt;

&lt;p&gt;PRごとに圧縮後のファイルサイズを確認するようにしたら、圧縮後のファイルサイズについて知見が貯まりました（例）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;コードの自動フォーマットをかけると、圧縮効率が上がってファイルサイズが減る&lt;/li&gt;
&lt;li&gt;コードをコピペすると圧縮効率が高くなるので、実は無理にコードを共通化する意味は実は薄い&lt;/li&gt;
&lt;li&gt;似たよな構造になるようにコードを意識すると圧縮効率が良くなる&lt;/li&gt;
&lt;li&gt;関数の順番を入れ替えただけで微妙にサイズが減ったりと謎が多い&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;制作用のエディタ機能の紹介&#34;&gt;制作用のエディタ機能の紹介&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor.png&#34; alt=&#34;chromatiq-editor&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;製作のイテレーションを高速化するため、必要なエディタ機能は一通り実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;再生位置のシーク機能

&lt;ul&gt;
&lt;li&gt;再生・一時停止・停止・フレームのコマ送り・時間の表示単位の秒とビートの切り替え&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;GLSLやTypeScriptのホットリロード機能&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタ&lt;/li&gt;
&lt;li&gt;カメラの自由移動&lt;/li&gt;
&lt;li&gt;デバッグ用に特定のパスの表示&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;エディタ機能は容量制約に影響しないので、既存のライブラリを積極的に利用しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ボタン用のアイコンのために、&lt;a href=&#34;https://fontawesome.com/&#34;&gt;fontawesome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;uniformのパラメータのインスペクタのために、&lt;a href=&#34;https://github.com/dataarts/dat.gui&#34;&gt;dat.gui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;カメラの自由移動のために、&lt;a href=&#34;https://threejs.org/&#34;&gt;three.js&lt;/a&gt;の&lt;a href=&#34;https://threejs.org/docs/#examples/en/controls/OrbitControls&#34;&gt;OrbitControls&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gam0022/resimulated#1-get-started&#34;&gt;リポジトリ&lt;/a&gt;をcloneして、 &lt;code&gt;npm run start&lt;/code&gt; すれば、エディタ機能が使えますので、興味がある人はお試しください。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:gam0022/resimulated.git
cd resimulated
npm install

# 制作用のエディタを起動
npm run start

# 提出用のビルド（dist\resimulated.html）を生成
npm run build
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;uniformのパラメータのインスペクタ&#34;&gt;uniformのパラメータのインスペクタ&lt;/h3&gt;

&lt;p&gt;GLSL上で以下のようなuniformを宣言するだけで、そのままインスペクタに表示されるような仕組みを実装しました。&lt;/p&gt;

&lt;p&gt;コメントでは左から順に &lt;code&gt;初期値 min max カテゴリー名&lt;/code&gt; を指定しています。初期値は必須ですが、それ以外は省略可能としました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;uniform float gEmissiveIntensity;     // 6.0 0 20 emissive
uniform float gEmissiveSpeed;         // 1 0 2
uniform float gEmissiveHue;           // 0.33947042613522904 0 1
uniform float gEmissiveHueShiftBeat;  // 0 0 1
uniform float gEmissiveHueShiftZ;     // 0 0 1
uniform float gEmissiveHueShiftXY;    // 0 0 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;uniform宣言をすると、自動的にインスペクタにパラメータが追加されます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/chromatiq-editor-emissive.png&#34; alt=&#34;chromatiq-editor-emissive&#34; /&gt;&lt;/p&gt;

&lt;p&gt;私の作品では、フラクタルやIFSといったパラメータの細かな調整が重要になる表現を多用しているため、気軽にパラメータを増やして、気軽に値を調整できるようにしました。&lt;/p&gt;

&lt;p&gt;値の当たりをつけた後に、パラメータのアニメーションを&lt;a href=&#34;https://github.com/gam0022/resimulated/blob/master/src/index.common.ts#L142-L569&#34;&gt;TypeScriptのコード&lt;/a&gt;に落とし込むワークフローにしました。&lt;/p&gt;

&lt;p&gt;これは、インスペクタを動かしている様子の動画です。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;三谷先生に便乗して、MengerSponge をカットしてみました。&lt;br&gt;断面が星みたいになって面白いですね⭐️ &lt;a href=&#34;https://t.co/mCqFnfbjBF&#34;&gt;https://t.co/mCqFnfbjBF&lt;/a&gt; &lt;a href=&#34;https://t.co/QF73xfFL1y&#34;&gt;pic.twitter.com/QF73xfFL1y&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1253296266424930304?ref_src=twsrc%5Etfw&#34;&gt;April 23, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画の保存機能&#34;&gt;動画の保存機能&lt;/h3&gt;

&lt;p&gt;処理落ちなしに4K解像度で動画を出力したかったので、以下の機能を実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;映像の連番PNG保存機能&lt;/li&gt;
&lt;li&gt;サウンドの wav 保存機能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;.png と .wav を ffmpeg で .mp4 に変換してYouTubeにアップロードしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ffmpeg.exe -r 60 -i chromatiq%04d.png -i chromatiq.wav -c:v libx264 -preset slow -profile:v high -coder 1 -pix_fmt yuv420p -movflags +faststart -g 30 -bf 2 -c:a aac -b:a 384k -profile:a aac_low -b:v 68M chromatiq_68M.mp4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;YouTube用のffmpegのエンコード設定については、以下を参考にしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://support.google.com/youtube/answer/1722171?hl=ja&#34;&gt;アップロードする動画におすすめのエンコード設定&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;映像ビットレート 2160p（4k）53～68 Mbps&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/mikoim/27e4e0dc64e384adbcb91ff10a2d3678&#34;&gt;YouTube recommended encoding settings on ffmpeg (+ libx264)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/sasaki_0222/status/1248910333835530241&#34;&gt;解像度とビットレードについて by sasaki_0222&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;映像について&#34;&gt;映像について&lt;/h2&gt;

&lt;p&gt;映像の3D描画は基本的に全部レイマーチングです。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンはMandelboxをベースにしました。&lt;/p&gt;

&lt;p&gt;後半の宇宙空間とグリーティングのシーンでは、宇宙空間はレイマーチング、惑星の上のグリーティングの文字はAABBとして解析的に衝突判定をするハイブリッドなレイトレをしています。&lt;/p&gt;

&lt;p&gt;パスの構成は、最終的にこうなりました。&lt;/p&gt;

&lt;p&gt;1パス目と2パス目を分離したのは、シェーダーのコンパイル時間の短縮のためです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1パス目: 前半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;2パス目: 後半のシーンのレイマーチング&lt;/li&gt;
&lt;li&gt;3パス目: テキストの描画&lt;/li&gt;
&lt;li&gt;4～13パス目: Bloomのポストエフェクト&lt;/li&gt;
&lt;li&gt;14パス目: ポストエフェクトとトーンマッピング&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;惑星のバリエーション生成の仕組み&#34;&gt;惑星のバリエーション生成の仕組み&lt;/h3&gt;

&lt;p&gt;後半のグリーティングでは、自分が特に尊敬しているデモグループをイメージした惑星が合計14パターン登場します。&lt;/p&gt;

&lt;p&gt;様々なバリエーションの惑星を効率的に生成するための仕組みを実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;地形の高さマップの自動生成&lt;/li&gt;
&lt;li&gt;テクスチャの色のグラデーションの自動生成&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;地形の高さマップの自動生成&#34;&gt;地形の高さマップの自動生成&lt;/h4&gt;

&lt;p&gt;2DのValue Noiseを重ね合わせたfbm（Fractal Brownian Motion）で地形の高さマップを生成しました。&lt;/p&gt;

&lt;p&gt;さらに、fbm関数をネストして（fbmのUV計算にfbmをつかって）、歪んだような不思議な雰囲気の地形も生成できるようにしました。&lt;/p&gt;

&lt;p&gt;左がfbmのネストよる歪みなしで、右がfbmのネストによる歪みありです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2020-04-19-revision2020/fbm-shift.jpg&#34; alt=&#34;fbm-shift&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;fbmの各種パラメーター（振幅や周波数、Y方向のスケール、歪み用のfbmの強度）は、乱数ではなく、配列で直接指定することで、イメージ通りの結果に調整できるようにしました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// fbmAmp, fbmFreq, fbmYScale, fbmShift
vec4[PLANETS_PAT_MAX * PLANETS_NUM_MAX] planetFbmParams = vec4[](
    // MIX_A
    vec4(0.3, 17.0, 1.0, 0.01), vec4(0.05, 10.0, 1.05, 0.0), vec4(0.05, 10.0, 1.05, 0.01),
    vec4(0.05, 10.0, 4.05, 0.02), vec4(0.05, 10.0, 2.05, 00.1), vec4(0.0),
    // MIX_B
    vec4(0.0, 10.0, 1.0, 0.2), vec4(0.0, 10.0, 1.0, 0.01), vec4(0.0, 10.0, 1.0, 0.03),
    vec4(0.05, 10.0, 1.0, 00.2), vec4(0.06, 10.0, 1.0, 0.03), vec4(0.05, 10.0, 1.0, 0.03));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;このようなfbmをネストしたシンプルな関数で高さマップを生成しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 惑星の高さマップ（height map）を生成する関数
// pは球体のUV, id は惑星のID
float hPlanetsMix(vec2 p, int id) {
    p.y *= planetFbmParams[id].z;
    return fbm(p + 
        planetFbmParams[id].w * fbm(p, 4.0 * planetFbmParams[id].y), planetFbmParams[id].y);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;テクスチャの色のグラデーションの自動生成&#34;&gt;テクスチャの色のグラデーションの自動生成&lt;/h4&gt;

&lt;p&gt;iqのColor Palettesを使いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iquilezles.org/www/articles/palettes/palettes.htm&#34;&gt;Color Palettes - Inigo Quilez :: fractals, computer graphics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec3 pal(in float t, in vec3 a, in vec3 b, in vec3 c, in vec3 d) {
    return a + b * cos(TAU * (c * t + d));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pal 関数の使い方は簡単で、&lt;code&gt;a, b, c, d&lt;/code&gt; を任意に指定すれば、&lt;code&gt;t&lt;/code&gt; を変化することでグラデーションを生成できます。&lt;/p&gt;

&lt;p&gt;今回は &lt;code&gt;a, b, c&lt;/code&gt; は定数、&lt;code&gt;d&lt;/code&gt; は惑星ごとに乱数で決定しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;a, b, c&lt;/code&gt; や乱数のseed値はインスペクタで値を調整しながら、イメージ通りのグラデーションが生成されるまで試行錯誤しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;t&lt;/code&gt; は地形の高さマップにマッピングしました。&lt;/p&gt;

&lt;h3 id=&#34;無数の小惑星のランダムな配置&#34;&gt;無数の小惑星のランダムな配置&lt;/h3&gt;

&lt;p&gt;宇宙空間がスカスカすぎて寂しかったので、無数の小惑星をランダムに配置しようとしたら、予想外に苦戦しました。&lt;/p&gt;

&lt;p&gt;レイマーチングだと空間をmodすることで物体を無限に複製することは簡単なのですが、それでは規則的な配置にしかならず、かなり不自然になってしまいます。&lt;/p&gt;

&lt;p&gt;gazさんのシェーダーを参考にして、空間をgridに分割して、gridごとに乱数を生成して、乱数で確率的に物体を間引く手法を採用しました。&lt;/p&gt;

&lt;p&gt;また、アーティファクトの回避するために、rayの長さを制限する工夫も必要でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;もう忘れてるよ。自分で読み解いてしまったじゃないか。xy平面を通常のmod()で分割。z軸の奥行のみgridをseedに乱数を使い間引きしてる。z軸だけ空間移動のスピード、回転を変えてる。アーティファクト対策で、min(map(p), 1.0)を使いrayの長さを制限。effectにビルボードを使い発光を演出。&lt;/p&gt;&amp;mdash; gaz (@gaziya5) &lt;a href=&#34;https://twitter.com/gaziya5/status/1247671912521596928?ref_src=twsrc%5Etfw&#34;&gt;April 7, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;最終的に、ランダムな位置と大きさをもつ小惑星の距離関数はこうなりました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float dGomi(vec3 p) {
    // アーティファクト対策のための固定長の距離
    float d = 1.0;

    // グリット（4m四方の立方体）の計算
    vec3 g = vec3(floor(p / 4.0));

    // 座標の繰り返し
    p = mod(p, 4.0) - 2.0;

    // 確率 rate に応じて球体を配置
    vec3 rand = hash33(g);
    float rate = (gPlanetsId != PLANETS_EARTH) ? 0.08 : 0.01;
    if (rand.x &amp;lt; rate) {
        p -= (rand - 0.5);
        d = sdSphere(p, 0.1 * rand.y);
    }

    // fbmで表面の凹凸のディテールを加える
    // レイが接近したときだけに計算するのは、LODによる負荷対策
    // fbmの計算はかなり高負荷なので、LODをしないと激重になる
    if (d &amp;lt; 0.5) {
        vec2 uv = uvSphere(normalize(p));
        uv.x += dot(rand, vec3(1.0));
        d -= remapTo(rand.z, 0.01, 0.08) * fbm(uv, 5.0);
    }

    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;音楽について&#34;&gt;音楽について&lt;/h2&gt;

&lt;p&gt;基盤となるGLSLサウンド用のシーケンサーの実装は私が、それ以外のオシレーターの関数やメロディの実装はさだきちさんが担当しました。&lt;/p&gt;

&lt;p&gt;音楽もやはり容量制約のためにGLSLで実装する必要があり、さだきちさんにはコーディングによる作曲をお願いしました。
さだきちさんはプログラミングもGLSLも未経験だったので、それらの習得から始まりました。
かなり無茶なお願いだったにも関わらず、かっこいいトランスミュージックを提供してくれたさだきちさんには感謝しかありません。ありがとうございます！&lt;/p&gt;

&lt;p&gt;私が担当したGLSLサウンド用のシーケンサーはGLSLサウンド上で実装されており、GLSLサウンドを鳴らす仕組みについては、AMAGIさん（&lt;a href=&#34;https://twitter.com/amagitakayosi&#34;&gt;@amagitakayosi&lt;/a&gt;）の記事を参考に、Shadertoy互換のGLSLサウンドの再生機能を実装しました。ありがとうございます！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.amagi.dev/entry/veda-sound&#34;&gt;VEDA 2.4: GLSLで音楽を演奏できるようになったぞ！！！ - マルシテイア&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;サウンド用のシーケンサーの利用例&#34;&gt;サウンド用のシーケンサーの利用例&lt;/h3&gt;

&lt;p&gt;これはベースのパートの波形を生成するGLSLの関数です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec2 bass1(float beat, float time) {
// 1つのパターンのビート数
#define BASS1_BEAT_LEN 8

// パターンの種類
#define BASS1_DEV_PAT 10

// 楽曲全体の長さのパターン数
#define BASS1_DEV_LEN 32

    // パターンの定義
    int[BASS1_BEAT_LEN * NOTE_DIV * BASS1_DEV_PAT] notes = int[](
        // パターン0
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),
        F(0), F(33), E(0, 33), S(0, 33, 0, 33),

        // パターン1
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),

        // パターン2
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(48, 47, 43, 40),

        // パターン3
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34),

        // パターン4
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 36, 36, 36),

        // パターン5
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 34, 34, 34), S(0, 36, 36, 36),

        // パターン6
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 43, 43, 43), S(0, 55, 57, 69),

        // パターン7
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31),

        // パターン8
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33),
        E(33, 33), S(0, 33, 33, 33), S(0, 33, 33, 33), S(0, 43, 45, 57),

        // パターン9
        E(29, 29), S(0, 29, 29, 29), S(0, 29, 29, 29), S(0, 31, 33, 45),
        E(29, 29), S(0, 29, 29, 29), S(0, 31, 31, 31), S(0, 31, 31, 31));

    // パターンの進行
    int[BASS1_DEV_LEN / DEV_PACK] development = int[](
        D(0, 0, 0, 0, 0, 0, 0, 0), D(1, 1, 1, 2, 3, 4, 5, 6),
        D(7, 0, 7, 8, 7, 0, 9, 0), D(0, 0, 0, 0, 0, 0, 0, 0));

    SEQUENCER(beat, time, BASS1_BEAT_LEN, BASS1_DEV_PAT, BASS1_DEV_LEN,
        notes, development, bass)

    return ret;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターン（2小節分のノートナンバーの並び）の定義と進行は、それぞれ配列で指定できるようにしています。&lt;/p&gt;

&lt;p&gt;音の長さは下記の4種類に対応しました。
ノートナンバーに0を指定すれば、同じ長さの休符になります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;O: 全音符&lt;/li&gt;
&lt;li&gt;F: 4分音符&lt;/li&gt;
&lt;li&gt;E: 8分音符&lt;/li&gt;
&lt;li&gt;S: 16分音符&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GLSLのコンスタントバッファのサイズには上限があり、サウンド用のシェーダー全体で要素数が4096個まででしか配列を宣言できません。&lt;/p&gt;

&lt;p&gt;そこで、&lt;code&gt;O, F, E, S&lt;/code&gt; を関数マクロとし、16分音符を最小単位として各音符を16bit（うち、ノートナンバーが8bit、音の長さが8bit）ずつパッキングしています。
GLSLのintは32bitなので、int配列の1要素に16分音符なら2つ、8分音符なら1つ入るような設計です。&lt;/p&gt;

&lt;p&gt;また、パターン進行の &lt;code&gt;D&lt;/code&gt; もマクロにしていて、要素数の節約のために4bitずつパッキングをしています。&lt;/p&gt;

&lt;p&gt;続いて、&lt;code&gt;bass&lt;/code&gt; は時間とノートナンバーを入力として、波形を出力するオシレーターのGLSL関数です。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;SEQUENCER&lt;/code&gt; は、時間、パターンの定義の配列、パターンの進行の配列、オシレーターの関数を指定することで、パートごとの波形を生成して &lt;code&gt;vec2 ret&lt;/code&gt; に代入する関数マクロです。
GLSLでは関数を引数とするような高階関数は実現できませんが、関数マクロで擬似的に実現しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#define SEQUENCER(beat, time, beatLen, devPat, devLen, notes, development, toneFunc)  \
    int indexOffset = development[int(                                                \
        mod(beat / float(beatLen * DEV_PACK), float(devLen / DEV_PACK)))];            \
    indexOffset =                                                                     \
        (indexOffset &amp;gt;&amp;gt; (4 * int(mod(beat / float(beatLen), float(DEV_PACK))))) &amp;amp; 15; \
    indexOffset *= beatLen * NOTE_VDIV;                                               \
                                                                                      \
    for (int i = 0; i &amp;lt; beatLen * NOTE_VDIV;) {                                       \
        int index = i + indexOffset;                                                  \
        int shift = (index % 2 == 1) ? 16 : 0;                                        \
        int div = ((notes[index &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;gt;&amp;gt; 8) &amp;amp; 255;                          \
        int len = NOTE_VDIV * NOTE_VDIV / div;                                        \
        for (int j = 0; j &amp;lt; len; j++) {                                               \
            tmpIndexes[i + j] = i;                                                    \
        }                                                                             \
        i += len;                                                                     \
    }                                                                                 \
                                                                                      \
    float indexFloat = mod(beat * float(NOTE_VDIV), float(beatLen * NOTE_VDIV));      \
    int index = int(indexFloat);                                                      \
    int shift = (index % 2 == 1) ? 16 : 0;                                            \
    int note = (notes[(index + indexOffset) &amp;gt;&amp;gt; 1] &amp;gt;&amp;gt; shift) &amp;amp; 255;                    \
    float localTime =                                                                 \
        beatToTime((indexFloat - float(tmpIndexes[index])) / float(NOTE_VDIV));       \
    float amp = (note == 0) ? 0.0 : 1.0;                                              \
    vec2 ret = vec2(toneFunc(float(note), localTime) * amp);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パターンの定義・進行のマクロはこちらです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;// 1ビートを最大何分割するか。16分音符に対応するなら4
#define NOTE_VDIV 4

// 1ビートのpackingを考慮した分割数。32bitのintに16bitずつ詰めているので
// 4 / (32 / 16) = 2
#define NOTE_DIV 2

// 展開用の配列のpacking数。32bitのintに4bitずつ詰めているので
// 32 / 4 = 8
#define DEV_PACK 8

#define MAX_BEAT_LEN 8
int[MAX_BEAT_LEN * NOTE_VDIV] tmpIndexes;

#define O(a)                                                                      \
    (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16),     \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), \
        (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 1 &amp;lt;&amp;lt; 8) | ((a | 1 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define F(a) (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (a | 4 &amp;lt;&amp;lt; 8) | ((a | 4 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define E(a, b) (a | 8 &amp;lt;&amp;lt; 8) | ((a | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (b | 8 &amp;lt;&amp;lt; 8) | ((b | 8 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define S(a, b, c, d) \
    (a | 16 &amp;lt;&amp;lt; 8) | ((b | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16), (c | 16 &amp;lt;&amp;lt; 8) | ((d | 16 &amp;lt;&amp;lt; 8) &amp;lt;&amp;lt; 16)
#define D(a, b, c, d, e, f, g, h) \
    (a) | (b &amp;lt;&amp;lt; 4) | (c &amp;lt;&amp;lt; 8) | (d &amp;lt;&amp;lt; 12) | (e &amp;lt;&amp;lt; 16) | (f &amp;lt;&amp;lt; 20) | (g &amp;lt;&amp;lt; 24) | (h &amp;lt;&amp;lt; 28)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;re-simulated-の意味&#34;&gt;『RE: SIMULATED』の意味&lt;/h1&gt;

&lt;p&gt;タイトルの『RE: SIMULATED』には2つの意味を込めました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;前作『WORMHOLE』の64K Introとしての「再現」&lt;/li&gt;
&lt;li&gt;SIMULATED REALITY&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-前作-wormhole-の64k-introとしての-再現&#34;&gt;1. 前作『WORMHOLE』の64K Introとしての「再現」&lt;/h2&gt;

&lt;p&gt;一昨年のTokyo Demo Fest 2018のCombined Demo Compoでも、さだきちさんとチームを組んで『WORMHOLE』という作品を制作しました（&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;記事&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;前半のシーンが顕著ですが、『WORMHOLE』と表現や演出が酷似していると思います。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;フラクタルの形状変化&lt;/li&gt;
&lt;li&gt;光の色の変化&lt;/li&gt;
&lt;li&gt;シーン転換前の激しい点滅&lt;/li&gt;
&lt;li&gt;シーン転換後のホワイトイン&lt;/li&gt;
&lt;li&gt;パーティのロゴの登場&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;『WORMHOLE』はUnityで制作したので、60.7 MB（zip圧縮で 23.18MB）というファイルサイズでした。&lt;/p&gt;

&lt;p&gt;前作では、Unityを利用したことで賛否両論があったので、ツールに頼らなくても同様のビジュアルを再現できることを証明する意図がありました。&lt;/p&gt;

&lt;p&gt;また、64K Introなどの容量制限のある部門への参加が個人的にも憧れだったという理由もあります。&lt;/p&gt;

&lt;p&gt;今回は自作のシステムで作品を制作することでファイルサイズは26KBになりました。&lt;/p&gt;

&lt;p&gt;同じ表現を「再現」しつつも、容量を &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2334&lt;/sub&gt; まで圧縮する試みのコンセプトは達成できました。&lt;/p&gt;

&lt;p&gt;まさか、コンポで優勝するという結果まで「再現」してしまうのは予想外でした（笑）&lt;/p&gt;

&lt;h2 id=&#34;2-simulated-reality&#34;&gt;2. SIMULATED REALITY&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%BC%E3%83%86%E3%83%83%E3%83%89%E3%83%BB%E3%83%AA%E3%82%A2%E3%83%AA%E3%83%86%E3%82%A3&#34;&gt;Simulated Reality&lt;/a&gt;という裏設定もありました。&lt;/p&gt;

&lt;p&gt;作品の最後に「RE: SIMULATED」の文字が&lt;/p&gt;

&lt;p&gt;&lt;code&gt;RE: SIMULATED&lt;/code&gt; → &lt;code&gt;RE&lt;/code&gt; → &lt;code&gt;REALITY&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;と変化して、REALITYに変化するタイミングで「地球」がフラッシュバックするのは、Simulated Realityの暗喩です。&lt;/p&gt;

&lt;p&gt;前半のサイバーなシーンは電子的な仮想空間という設定で、シーン転換時に球体を中心に空間が歪んで圧縮するのは、宇宙誕生の爆発であるビッグバンの暗喩です。&lt;/p&gt;

&lt;p&gt;この世界は上位存在によって電子的にシミュレーションされた仮想現実で、最後に自分たちが住む地球を見つけるというストーリーでした（あくまで裏設定だったので、見た人に通じなくても良い）。&lt;/p&gt;

&lt;p&gt;できれば現実と見分けがつかないようなリアルなグラフィックで表現できたら良かったのですが、力量不足でした……。&lt;/p&gt;

&lt;h1 id=&#34;おわりに&#34;&gt;おわりに&lt;/h1&gt;

&lt;p&gt;Webフロントエンドは久しぶりで、node.jsとwebpackは初めてだったので、新しい技術を学ぶ良い機会となりました。&lt;/p&gt;

&lt;p&gt;昔はjQueryが必要だったDOMのセレクターやHTTPアクセスが、標準のAPI（&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Document/querySelector&#34;&gt;querySelector&lt;/a&gt;や&lt;a href=&#34;https://developer.mozilla.org/ja/docs/Web/API/Fetch_API/Using_Fetch&#34;&gt;Fetch&lt;/a&gt;）になっていて驚きました。&lt;/p&gt;

&lt;p&gt;TypeScript（ECMascript）に苦手意識がありましたが、最近はかなり使いやすい言語になったなぁと認識を改めました。
演算子オーバーロードがないのだけは、3Dプログラミングには必須のベクトル計算の実装の可読性が落ちて苦しい気持ちになったので、早くサポートして欲しいと感じました。&lt;/p&gt;

&lt;p&gt;また、64K Introのエントリーは今回が初めてということで、どのくらいのコンテンツが詰め込めるか感覚がつかめず、容量を半分以上も余らせてしまいました。
次の機会には64KBギリギリまで使って、もっと映像としても洗練させて、さらにCoolな作品を発表したいです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;実は26KBしか使いきれなかったので、次回は64KBギリギリまで使えるように精進します💪 &lt;a href=&#34;https://t.co/uxF2M5DZmg&#34;&gt;pic.twitter.com/uxF2M5DZmg&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ / encoder killer (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1249677712815321088?ref_src=twsrc%5Etfw&#34;&gt;April 13, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;例年のRevisionの64K Introの作品と比較すると、かなり未熟なので、もっと精進して最高のデモを作りたいという気持ちです。&lt;/p&gt;

&lt;p&gt;ともあれ、このたびは優勝作品に選んでいただき、とても光栄に思います。&lt;/p&gt;

&lt;p&gt;世界中の尊敬するデモチームの方々からいただいたお祝いのコメントも嬉しかったです。わーい！&lt;/p&gt;

&lt;p&gt;最後に、世界的に大変な状況の中、オンラインでの開催のためにご尽力いただいた皆様に、心より感謝申し上げます。
とても楽しく充実した3日間を過ごせました。来年はドイツでお会いしましょう！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>近未来教育フォーラム2019でシェーダーライブコーディングをしました</title>
      <link>https://gam0022.net/blog/2019/11/29/dhw/</link>
      <pubDate>Fri, 29 Nov 2019 10:36:17 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/11/29/dhw/</guid>
      <description>&lt;p&gt;2019/11/28にデジタルハリウッド大学で開催された&lt;a href=&#34;https://www.dhw.co.jp/forum/program.html&#34;&gt;近未来教育フォーラム&lt;/a&gt;の
「The Real Time Live &amp;amp; Reception リアルタイムグラフィックスの世界とVTuberが牽引する新たな人類」というイベントに登壇しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/FL1NE&#34;&gt;@FL1NE&lt;/a&gt;さんと一緒にデモシーンについて話しました。
私は簡単なシェーダーライブコーディングをしながらプログラミングによる形状のモデリングについて解説しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/o_ob/status/1200067621799903238&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding_init.jpg&#34; alt=&#34;シェーダーライブコーディング（初期）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_/status/1199999036964474886&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-11-29-dhw/live_coding.jpg&#34; alt=&#34;シェーダーライブコーディング（完成）&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;レポート-2020-05-09追記&#34;&gt;レポート（2020/05/09追記）&lt;/h2&gt;

&lt;p&gt;当日の様子のレポートが公開されました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dhw.co.jp/forum/report/report01.html&#34;&gt;近未来教育フォーラム2019 -In Real Time- 公演レポート&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;シェーダーライブコーディングによる作品&#34;&gt;シェーダーライブコーディングによる作品&lt;/h2&gt;

&lt;p&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;/p&gt;

&lt;p&gt;通常の3DCGでは、ツールでモデリングした3Dモデルを読み込んで表示すると思いますが、デモシーンの一部の部門には容量制限があるので、
WORMHOLEではシェーダーによるプログラミングによってプロシージャルにモデリングを行いました。&lt;/p&gt;

&lt;p&gt;発表時間が限られていたので、ハラハラ・ドキドキでしたが、なんとか意図通りの形になって良かったです。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;WORMHOLEの前半に登場したフラクタルによる複雑な形状のトンネルのモデリングについてライブコーディングしながら解説しました。&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200006025878749184?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Gam師のレイマーチング始まってる。 &lt;a href=&#34;https://t.co/MHLrFmbLpL&#34;&gt;pic.twitter.com/MHLrFmbLpL&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1199999036964474886?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&#34;動画&#34;&gt;動画&lt;/h3&gt;

&lt;p&gt;YouTube配信のアーカイブが残っています。&lt;/p&gt;

&lt;p&gt;34:46〜が自分のシェーダーライブコーディングでした。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/j0yRASXFvlQ?start=2086&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;songofsaya-さんによる解説&#34;&gt;songofsaya_ さんによる解説&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/songofsaya_&#34;&gt;@songofsaya_&lt;/a&gt; さんがTwitterで解説をしてくださっていました。ありがとうございます！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;四角形のパイプと書いたけど、再帰性があるからおそらくメンガーだろうなーと思っていたらメンガーでした。&lt;br&gt;そしてGam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります。 &lt;a href=&#34;https://t.co/VFqKT2jVoq&#34;&gt;pic.twitter.com/VFqKT2jVoq&lt;/a&gt;&lt;/p&gt;&amp;mdash; さやちゃんぐbot (@songofsaya_) &lt;a href=&#34;https://twitter.com/songofsaya__/status/1200008658916007938?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Gam師ならではのfoldRotateが登場します。これがKanetaaaaa神だとpmodと名前が変わります&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;正解です！&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;発表資料はFL1NEさんが作ってくれました。自分はライブコーディングのところを担当しました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;b3019de333a449a481ff2df647d2d098&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;感想&#34;&gt;感想&lt;/h2&gt;

&lt;p&gt;当日は&lt;a href=&#34;https://www.sli.do/&#34;&gt;sli.do&lt;/a&gt;で来場者の声がリアルタイムに見えるようになっていました。&lt;/p&gt;

&lt;p&gt;sli.doや懇親会で、メガデモとシェーダーについて「楽しそう！」「自分でも作ってみたい」といった好意的な感想をいただけました！&lt;/p&gt;

&lt;p&gt;シェーダやレイマーチングや3DCGに少しでも興味を持っていただけたのなら嬉しい限りです。ありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;メガデモとシェーダーについて&lt;br&gt;「楽しそう！」「自分でも作ってみたい」&lt;br&gt;といった好意的な感想をいただけて嬉しい限りです☺️&lt;a href=&#34;https://twitter.com/hashtag/DHW?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DHW&lt;/a&gt; &lt;a href=&#34;https://t.co/BCkGVOiAdv&#34;&gt;pic.twitter.com/BCkGVOiAdv&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1200068188043501568?ref_src=twsrc%5Etfw&#34;&gt;November 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>レイトレ合宿7でレイマーチング対応のGPUパストレーサーを実装しました！</title>
      <link>https://gam0022.net/blog/2019/09/18/rtcamp7/</link>
      <pubDate>Wed, 18 Sep 2019 10:15:43 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/09/18/rtcamp7/</guid>
      <description>&lt;p&gt;9月7日(土)～9月8日(日)に猪苗代湖で開催された&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;に参加しました。&lt;/p&gt;

&lt;p&gt;自作のレンダラーでこんな画像を &lt;strong&gt;60秒の制限時間&lt;/strong&gt; でレンダリングして4位をいただきました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/11.gam.jpg&#34; alt=&#34;本番のレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ちなみに4K解像度（3840x2160）です！&lt;/p&gt;

&lt;p&gt;事前に本番環境で動作確認できなかったこともあり、よく見ると意図しないアーティファクトが発生しているのですが、許容レベルに収まったのはラッキーでした。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レイトレ合宿とは&#34;&gt;レイトレ合宿とは&lt;/h1&gt;

&lt;p&gt;レイトレ合宿は完全自作のレイトレーサーを走らせて画像の美しさを競うイベントです。&lt;/p&gt;

&lt;p&gt;参加者はレンダラーを自作する必要がある！というだけで面白いイベントなのですが、レンダリングの制限時間が毎年どんどん短縮されているのも注目ポイントです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sites.google.com/site/rendering1h/&#34;&gt;第1回のレンダリング合宿&lt;/a&gt;では制限時間が1時間だったのですが、第7回となる今年は60秒制限でした。&lt;/p&gt;

&lt;p&gt;この制限時間はレンダラーを起動してから画像を保存するまでの時間なので、シーンの読み込みからレンダリングをすべて含めて60秒で完了させなくてはなりません。&lt;/p&gt;

&lt;p&gt;そのため、参加者はあらゆる手段をつかって、レンダラーの高速化に本気で取り組む必要があります。&lt;/p&gt;

&lt;p&gt;パストレーシングの高速化のアプローチとしては、サンプリングを効率化する、BVHなどの構造をつかってシーンとの交差判定を効率化する、ノイズを軽減するためにデノイズを行う、などが挙げられます。&lt;/p&gt;

&lt;p&gt;パストレーシングを使わないといけないルールは無いのですが、近年のレイトレ合宿ではパストレーシングが人気です。
今年のレイトレ合宿では、Stochastic Progressive Photon Mappingを実装した&lt;a href=&#34;https://github.com/tabochans&#34;&gt;tabochan&lt;/a&gt;さん以外は全員パストレーシングだったと記憶しています。&lt;/p&gt;

&lt;p&gt;また、複数コアのCPU・複数のGPUを利用したり、メモリのキャッシュ効率を上げてマシンスペックを最大限に活かし切るというのも、実はかなり難しい課題だったりします。私は今年は複数のGPUをうまく使えませんでした…&lt;/p&gt;

&lt;p&gt;参加者はプロダクションレンダラーの開発者やコンピュータグラフィック分野の研究者などのプロの人から、私のように趣味でレンダラーを開発している人まで様々です。&lt;/p&gt;

&lt;p&gt;レイトレ合宿の参加者のレベルが年々向上していて、特に今年は技術的にもアートセンスにも秀でた作品が多い中、4位と上位に食い込めて本当に嬉しかったです！&lt;/p&gt;

&lt;h1 id=&#34;前回までのレイトレ合宿の参加レポート&#34;&gt;前回までのレイトレ合宿の参加レポート&lt;/h1&gt;

&lt;p&gt;ちなみに私は今年で4回目の参加になります。過去の参加レポートはこちらです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/25/rtcamp6-part2/&#34;&gt;レイトレ合宿6 参加報告 Part2（当日編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/09/18/rtcamp6-part1/&#34;&gt;レイトレ合宿6 参加報告 前編（準備編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/10/02/rtcamp5/&#34;&gt;レイトレ合宿5‽に参加して、Rustでパストレーシングを実装しました！ | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.hatenablog.com/entry/raytracingcamp4&#34;&gt;レイトレ合宿4!? に参加しました！ - gam0022のブログ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;redflash-renderer&#34;&gt;Redflash Renderer&lt;/h1&gt;

&lt;p&gt;Redflash というGPUレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;Redflash は NVIDIA® OptiX 6.0 上で実装したパストレーシングによる物理ベースレンダラーで、ポリゴンと &lt;strong&gt;レイマーチング&lt;/strong&gt; が混在したシーンを一貫した描画ができます。&lt;/p&gt;

&lt;p&gt;GitHubにソースコードを公開しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/redflash&#34;&gt;https://github.com/gam0022/redflash&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;こちらはアーティファクトなしの想定のレンダリング結果です。レンダリングは30分です。クリックすると非圧縮形式の画像になります。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/pr33_v6_t3000_s1030_1920x1080.jpg&#34; alt=&#34;想定したレンダリング結果&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;別視点からのレンダリング結果も紹介します。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle1.jpg&#34; alt=&#34;別視点からのレンダリング結果1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle2.jpg&#34; alt=&#34;別視点からのレンダリング結果2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/camera_angle3.jpg&#34; alt=&#34;別視点からのレンダリング結果3&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;発表資料&#34;&gt;発表資料&lt;/h2&gt;

&lt;p&gt;自作レンダラーの紹介スライドです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;ba3966aad908467e8b21249e828c26d0&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;レイトレ合宿の参加者にとっては常識だと思われる箇所の説明を省略してしまったので、ここから簡単に補足解説をします。&lt;/p&gt;

&lt;h2 id=&#34;neeとmisによるサンプリングの効率化&#34;&gt;NEEとMISによるサンプリングの効率化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.003.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この2つは「パストレーシングのサンプリングを効率化する」ための非常に有名なテクニックです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Next Event Estimation (Direct Light Sampling)&lt;/li&gt;
&lt;li&gt;Multiple Importance Sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next Event EstimationはよくNEEと省略されて呼ばれます。
光源が小さいシーンでは、BSDFによる重点的サンプリングだけではなかなか光源にヒットしません。
そのため、短い計算時間ではノイズだらけの結果になってしまいます。
また、BSDFの分布と光源の方向が異なる場合、むしろBSDFによる重点的サンプリングによって悪化するケースもありえます。
そこで、光源の表面上の点を明示的にサンプリングして光転送経路を生成することで、効率的なサンプリングを行うテクニックがNEEです。&lt;/p&gt;

&lt;p&gt;Multiple Importance SamplingはよくMISと省略されて呼ばれます。
MISは複数のサンプリング戦略を組み合わせることでサンプリングの効率を向上するテクニックです。
具体的には「BSDFによる重点的サンプリング」と「NEEによるライトのサンプリング」の2つの戦略の結果を適切なウェイトで組み合わせることで、サンプリングの効率を向上します。
それぞれのサンプリング戦略が得意な部分だけウェイトを大きくすることで、分散を抑えて効率的にサンプリングができるようになります。
例えば、光源が大きくてroughnessが大きいような「BSDFによる重点的サンプリング」が得意なケースなら「BSDFによる重点的サンプリング」の重みを大きくして、
逆に光源が小さくてroughnessが小さいような「NEEによるライトのサンプリング」が得意なケースなら「NEEによるライトのサンプリング」の重みを大きくします。&lt;/p&gt;

&lt;p&gt;NEEやMISについては、レイトレ合宿の参加者でもある &lt;a href=&#34;https://twitter.com/Shocker_0x15&#34;&gt;@Shocker_0x15&lt;/a&gt; さんが日本語で詳しく記事を書かれています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/path_tracing/&#34;&gt;パストレーシング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rayspace.xyz/CG/contents/MIS/&#34;&gt;多重重点的サンプリング - Computer Graphics - memoRANDOM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;optixとレイマーチングの統合&#34;&gt;OptiXとレイマーチングの統合&lt;/h2&gt;

&lt;p&gt;OptiXには独自のプリミティブを定義する仕組みがあるため、OptiXとレイマーチングの統合はそこまで苦労しませんでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;IntersectionProgram&lt;/code&gt; と &lt;code&gt;BoundingBoxProgram&lt;/code&gt; としてレイマーチングによる交差判定とAABBの定義をCUDAで実装するだけでできました。&lt;/p&gt;

&lt;p&gt;詳細はレイトレ合宿アドベントカレンダーの記事で既に紹介しているので、気になる方は読んでみてください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/&#34;&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;衝突判定の高速化&#34;&gt;衝突判定の高速化&lt;/h2&gt;

&lt;p&gt;BVHの構築はOptiXが自動でやってくれるので、ポリゴンの衝突判定は特に高速化しませんでした。
なんとOptiX 6.0ではRTXに対応しているので、RTX 2070ではハードウェアをつかって高速化な衝突判定ができました！（が、本番環境はRTX非対応でした…）&lt;/p&gt;

&lt;p&gt;一方でレイマーチングの衝突判定については自力で行う必要がありました。
シーン全体を1個の距離関数で表現したため、BVHなどの構造では衝突判定の高速化が難しいためです。&lt;/p&gt;

&lt;h3 id=&#34;距離関数の軽量化&#34;&gt;距離関数の軽量化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.008.jpeg&#34; alt=&#34;実装機能&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レイマーチングでは1本をレイを飛ばすごとに数百回も距離関数を評価する必要があります（今回のレンダリング結果は300回）。&lt;/p&gt;

&lt;p&gt;レイマーチングの負荷は距離関数の複雑さに比例するので、距離関数の軽量化は効果が大きい最適化でした。&lt;/p&gt;

&lt;p&gt;今回はMandelboxという伝統的なフラクタル図形を距離関数として用いたのですが、
メジャーなMandelboxの実装では &lt;code&gt;sphereFold&lt;/code&gt; という操作で分岐があったりとGPUには高負荷なものでした。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sphereFold&lt;/code&gt; のどちらの分岐に入るかはMandelboxのパラメータによって決まるので、
一部のパラメータを削除したり、パラメータの範囲を狭めることで分岐を削除して処理を簡略化しました。&lt;/p&gt;

&lt;h3 id=&#34;レイマーチングの衝突判定の精度のlod&#34;&gt;レイマーチングの衝突判定の精度のLOD&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.009.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 1/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;まず速度面では、カメラに近い部分は細部まで正確に衝突判定をする必要がありますが、遠い部分は大雑把でも問題にならないため、LODが有効でした。&lt;/p&gt;

&lt;p&gt;品質面でもLODが必要でした。
Mandelboxの距離関数は厳密には Distance Estimator（距離推定器）と呼ばれるものです。
通常の距離関数は表面までの距離をぴったりと計算できるのに対して、
Distance Estimatorは有限のイテレーション回数では表面に漸近しても、距離0になりません。&lt;/p&gt;

&lt;p&gt;そのため、適当な距離 eps で衝突とみなして計算を打ち切る必要があります。
また、eps を小さくすると、より細かい detail まで可視化できるのですが、
遠景まで同じ eps で処理すると高周波成分が現れて、まるでMipMap OFFのような汚い結果となります。&lt;/p&gt;

&lt;p&gt;このようにレイマーチングの高速化と品質向上の2つの目的ために、衝突判定の精度のLODが必要でした。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.010.jpeg&#34; alt=&#34;レイマーチングの衝突判定の精度のLOD 2/2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LODはカメラからの距離に応じて動的に eps を決定することで実現しました。&lt;/p&gt;

&lt;p&gt;レイマーチングではレイを漸近的に進めるため、レイが進んだ距離を必ず計算する必要があります。
このとき &lt;code&gt;レイが進んだ距離 = カメラからの距離&lt;/code&gt; となるため、eps は簡単に決定できます。&lt;/p&gt;

&lt;p&gt;具体的にはレイが進んだ距離に定数を乗算したものを eps として扱うようにしました。&lt;/p&gt;

&lt;p&gt;今回の提出シーンのように同じレイマーチングのオブジェクトの近影〜遠景がひとつのカットで混在していても、綺麗に描画できるようになりました。&lt;/p&gt;

&lt;p&gt;また、カメラを近づけると実質無限に細部が現れるようになりました（フラクタル図形の特徴）。&lt;/p&gt;

&lt;h3 id=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34;&gt;1回のlaunchでなるべくたくさんサンプリングする戦略&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.011.jpeg&#34; alt=&#34;1回のlaunchでなるべくたくさんサンプリングする戦略&#34; /&gt;&lt;/p&gt;

&lt;p&gt;OptiXでパストレーシングを実装する場合、通常は1回のlaunchでパストレーシングの1サンプリングを行うように実装するかと思います。&lt;/p&gt;

&lt;p&gt;ところが、launchにも多少のオーバーヘッドがあるため、手元のPCで実験した結果では、
&lt;code&gt;sample_per_launch&lt;/code&gt; （1回のlaunchごとのサンプリング回数）を大きくすれば大きくするほど60秒あたりのサンプリング回数を増やすことができました。&lt;/p&gt;

&lt;p&gt;そこで、最初の4サンプリングでマシンの性能をベンチマークして時間切れにならない最大の sample_per_launch を決定するような戦略をとりました。&lt;/p&gt;

&lt;h2 id=&#34;deep-learning-denoising&#34;&gt;Deep Learning Denoising&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.012.jpeg&#34; alt=&#34;Deep Learning Denoising&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディープラーニングをつかったデノイザーの性能が驚異的に良くて驚きました。&lt;/p&gt;

&lt;p&gt;左が10spp（sample per pixel）の結果で、右がデノイズした結果です。&lt;/p&gt;

&lt;p&gt;かなり少ないサンプリング数でも非常に綺麗にデノイズができました。
特にLucy像の拡散面の部分などは効果が絶大でした。&lt;/p&gt;

&lt;p&gt;Deep Learning DenoisingはOptiXの標準機能を利用しただけなので、詳細については私は理解していません。&lt;/p&gt;

&lt;p&gt;レンダリング結果とnormalとalbedoのバッファを与えてやると、綺麗にデノイズした結果を出力してくれました。&lt;/p&gt;

&lt;p&gt;速度面でも優秀で4K解像度でも&lt;a href=&#34;https://github.com/gam0022/redflash/pull/34&#34;&gt;1.4秒程度&lt;/a&gt;でデノイズが完了しました。&lt;/p&gt;

&lt;p&gt;まだリアルタイムレンダリングには速度的には使いづらいかもしれませんが、これまでの Bilateral Filter や Non-local Means Filter を遥かに凌駕する性能なので、改めてレンダリング技術とディープラーニングの親和性の高さを実感しました。&lt;/p&gt;

&lt;p&gt;これからの時代はグラフィックエンジニアもディープラーニングも勉強しなくては！と思いました。&lt;/p&gt;

&lt;h3 id=&#34;rt-buffer-gpu-local-による最適化&#34;&gt;RT_BUFFER_GPU_LOCAL による最適化&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-09-10-rtcamp7/redflash_rtcamp7.013.jpeg&#34; alt=&#34;RT_BUFFER_GPU_LOCAL による最適化&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Deep Learning Denoising用にalbedoとnormalのバッファを生成したところ、合計で5枚もバッファが必要になりました。
バッファの読み書きもそれなりに重たい処理なので、対策を行いました。
createBuffer の第1引数に &lt;code&gt;RT_BUFFER_INPUT_OUTPUT&lt;/code&gt; を指定したところ、なんと13.6%くらい高速化しました。&lt;/p&gt;

&lt;p&gt;ディスプレイにバッファを同期するかのオプションのようでした。
ウィンドウにバッファを表示する場合はこのオプションをつけると描画結果が同期されなくなってしまいますが、
CUIモードで起動するときには同期は不要なので、このオプションを有効にすることで大幅に性能向上できました。&lt;/p&gt;

&lt;h1 id=&#34;反省-スケジュール面が厳しすぎた&#34;&gt;反省：スケジュール面が厳しすぎた&lt;/h1&gt;

&lt;p&gt;ここまでがレンダラーの紹介でした。ここからは振り返りを書こうと思います。&lt;/p&gt;

&lt;p&gt;最大の反省点はスケジュール面が厳しすぎたことでした…&lt;/p&gt;

&lt;p&gt;OptiXのキャッチアップを含めて約一ヶ月で開発したのですが、流石に無理なスケジュールだったと思います。&lt;/p&gt;

&lt;p&gt;8月は仕事のプロジェクトの追い込み時期とCEDECの登壇準備が重なって、なかなかレンダラー開発の時間を捻出できず、
睡眠時間と生活を削りすぎたため、体力的にも精神的にもかなり限界でした…&lt;/p&gt;

&lt;p&gt;そろそろ若さで無茶をカバーできない年齢になってきたので、締め切り直前になって慌てて開発するのではなく、
日頃から継続的にレンダラーを開発することが大事だろうと思います。&lt;/p&gt;

&lt;h1 id=&#34;余談-シーン作成はunity&#34;&gt;余談：シーン作成はUnity&lt;/h1&gt;

&lt;p&gt;時間がなくてシーン編集機能を実装できなかったので、
Unityで事前に距離関数のパラメータ調整や光源の配置を行ってシーンのイメージを固めてから、後からパラメータを自作レンダラーに移植しました。&lt;/p&gt;

&lt;p&gt;結果的には納得できるシーンを作成できたので、作戦は成功だったと思います。&lt;/p&gt;

&lt;p&gt;UnityのHDRPでレイマーチングを行うのには&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;@kanetaaaaa&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/kaneta1992/RaymarchingInHDRP/&#34;&gt;RaymarchingInHDRP&lt;/a&gt;を利用させていただきました。&lt;/p&gt;

&lt;p&gt;カッコいいシーンを大量に作れたので、ついスクリーンショットをたくさん撮影してしまいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unity HDRP + Raymarching by &lt;a href=&#34;https://twitter.com/kanetaaaaa?ref_src=twsrc%5Etfw&#34;&gt;@kanetaaaaa&lt;/a&gt; を試してみました！&lt;br&gt;カッコいいシーンが無限に作れてしまう😍&lt;br&gt;これは凄いです🙏&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/raymarching?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#raymarching&lt;/a&gt;&lt;a href=&#34;https://t.co/EK6JsHpTBZ&#34;&gt;https://t.co/EK6JsHpTBZ&lt;/a&gt; &lt;a href=&#34;https://t.co/ZueP2hfzet&#34;&gt;pic.twitter.com/ZueP2hfzet&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1163876089489285120?ref_src=twsrc%5Etfw&#34;&gt;August 20, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;今後やりたいこと&#34;&gt;今後やりたいこと&lt;/h1&gt;

&lt;h2 id=&#34;シーン編集機能がほしい&#34;&gt;シーン編集機能がほしい&lt;/h2&gt;

&lt;p&gt;現状はGUIでカメラ操作だけができます。&lt;/p&gt;

&lt;p&gt;シーン編集に関して、上で紹介したようなUnityからパラメータを移植する方法だと最終的なルックの確認のイテレーションの高速化がしずらいので、
Redflash自体にシーン編集機能を実装したいと思っています。&lt;/p&gt;

&lt;p&gt;距離関数を定義したCUDAファイルのホットリロード機能を実装したり、 CallableProgramをつかって距離関数を差し替え可能にしたいです。&lt;/p&gt;

&lt;p&gt;他にも距離関数やマテリアルのパラメータをインスペクタで編集するなどは最低限欲しいなと思っています。&lt;/p&gt;

&lt;p&gt;あとはオブジェクトの配置などをマニピュレーターでできるようにしたいですが、どうしても実装工数がかかるので、どういう感じが良いのか思案しているところです。
DCCツールから直接シーンを出力する形式だと、距離関数の扱いに困るため、なかなか難しい問題です。&lt;/p&gt;

&lt;h2 id=&#34;リファクタリング&#34;&gt;リファクタリング&lt;/h2&gt;

&lt;p&gt;CallableProgramでBSDFを入れ替えられるようにしたり、ファイルを適切に分割したりして、もう少しコードをリファクタリングしたいです。&lt;/p&gt;

&lt;h2 id=&#34;pngのエンコード時間の短縮&#34;&gt;PNGのエンコード時間の短縮&lt;/h2&gt;

&lt;p&gt;PNGの保存には &lt;a href=&#34;https://github.com/nothings/stb/blob/master/stb_image.h&#34;&gt;stb_image&lt;/a&gt; を使わせていただきました。&lt;/p&gt;

&lt;p&gt;ただし、4K解像度となるとPNGの保存に1.7秒前後の時間が必要でした。&lt;/p&gt;

&lt;p&gt;制限時間が短くなると、PNGの保存やGPUの初期化に要する時間が相対的に増えて、レンダリングに使える時間がどんどん短くなってしまいます。&lt;/p&gt;

&lt;p&gt;そのため、PNGの保存やGPU初期化の高速化は、来年以降のレイトレ合宿では重要な課題になるだろうと予想しています。&lt;/p&gt;

&lt;h2 id=&#34;複数gpu対応&#34;&gt;複数GPU対応&lt;/h2&gt;

&lt;p&gt;OptiXをつかっても複数のGPUをうまく使ってくれなかったので、独自の仕組みで対応が必要のようでした。&lt;/p&gt;

&lt;p&gt;単純な解決策として、プロセスを複数起動して最後にレンダリング結果をマージする方法が考えられますが、ちゃんと検証をしたいです。&lt;/p&gt;

&lt;h2 id=&#34;フルスクラッチgpuレンダラー&#34;&gt;フルスクラッチGPUレンダラー&lt;/h2&gt;

&lt;p&gt;去年まではGPUインスタンス勢は1人だけだったのですが、今年は7人（レンダラーが動かなかった人も含む）もいました。&lt;/p&gt;

&lt;p&gt;GPU勢にも、私のようにOptiXなどのレイトレーシング用のフレームワークを使う勢と、フルスクラッチ実装勢で別れていました。&lt;/p&gt;

&lt;p&gt;フルスクラッチ勢からは「OptiXでは作法がきっちり決められているのがなんとなく嫌だった」「GPU向けのBVH実装をしてみたかった」といった意見を聞きました。&lt;/p&gt;

&lt;p&gt;たしかにRTXなどの登場によって交差判定がハードウェアに移りつつある今だからこそ、勉強する価値はあるのかもしれません。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;今年は忙しいからレイトレ合宿に参加できるか怪しいと思っていましたが、なんとかちゃんとレンダラーを提出できて良かったです。&lt;/p&gt;

&lt;p&gt;思えば「レイマーチングとポリゴンが混在したシーンをパストレーシングしたい」というのは3年前のレイトレ合宿4のときに本当は実現したいテーマでした。&lt;/p&gt;

&lt;p&gt;当時はレイトレ初心者だったので、ナイーブなパストレーシングで精一杯で高速化方法が分からず、
普通にレイマーチングを組み合わせたら激重になってしまい、5時間くらいかけないとまともな絵が出ない状態でした。
結局、パストレーシングを諦めて疑似手法でAOやシャドウを計算してなんとか見れる絵を提出しました…&lt;/p&gt;

&lt;p&gt;3年間で学んだ知識でようやくやりたいことを実現できて本当に良かったです。過去の自分に勝利できました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿は自身の成長や糧となる機会を与えてくれる、とても良い合宿勉強会だなと改めて感じました。&lt;/p&gt;

&lt;p&gt;レイトレ合宿を毎年主催してくださっている&lt;a href=&#34;https://twitter.com/q_cinnamon&#34;&gt;q&lt;/a&gt;さんと&lt;a href=&#34;https://twitter.com/h013&#34;&gt;hole&lt;/a&gt;さん、その他の参加者のみなさん、本当にありがとうございました！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを実装した</title>
      <link>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</link>
      <pubDate>Mon, 05 Aug 2019 12:10:23 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/08/05/optix-raymarching-pathtracing/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://sites.google.com/site/raytracingcamp7/&#34;&gt;レイトレ合宿7&lt;/a&gt;アドベントカレンダーの記事です。&lt;/p&gt;

&lt;p&gt;NVIDIA® OptiX上で『レイマーチング×パストレーシング』による物理ベースレンダラーを開発しました。&lt;/p&gt;

&lt;p&gt;レイとオブジェクトの交差判定をレイマーチングで行い、ライティングをパストレーシングをするという、レイマーチングとパストレーシングのハイブリッドなレンダリングを実現しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;NVIDIA® OptiX上で&lt;br&gt;『レイマーチング×パストレーシング』&lt;br&gt;を実装できた😉 &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%AC%E3%82%A4%E3%83%88%E3%83%AC%E5%90%88%E5%AE%BF?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#レイトレ合宿&lt;/a&gt; &lt;a href=&#34;https://t.co/FKbuHiXqmP&#34;&gt;pic.twitter.com/FKbuHiXqmP&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155489034354843649?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;実装の方針&#34;&gt;実装の方針&lt;/h1&gt;

&lt;p&gt;Optixは、CUDA基盤上で動作する、NVIDIA製のGPUレイトレーシング用フレームワークです。&lt;/p&gt;

&lt;p&gt;Optixではユーザ独自のプリミティブを定義できるため、この機能をつかってレイマーチングで衝突判定を行う距離関数のプリミティブを定義しました。&lt;/p&gt;

&lt;p&gt;独自のプリミティブの定義に必要なProgram（Optix用語でPTXアセンブリにコンパイルされたCUDA C関数を指す）は次の2つです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bounding Box&lt;/li&gt;
&lt;li&gt;Intersection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Optixの公式サンプルプロジェクトに optixPathtracing（パストレーシングの実装例）があったので、これにレイマーチングのプリミティブを追加する形で実装しました。&lt;/p&gt;

&lt;p&gt;パストレーシングの処理はサンプルコードの実装そのまま利用させていただきました。&lt;/p&gt;

&lt;h2 id=&#34;bounding-box&#34;&gt;Bounding Box&lt;/h2&gt;

&lt;p&gt;Bounding Boxを定義するProgramです。&lt;/p&gt;

&lt;p&gt;レイマーチングのオブジェクトのBounding BoxはC++側から値を渡すようにしました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rtDeclareVariable&lt;/code&gt; でCPUからGPUへ送るバッファの宣言（GLSLのunifromと同じ）ができます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;optix_world.h&amp;gt;

rtDeclareVariable(float3, center, , );
rtDeclareVariable(float3, size, , );

RT_PROGRAM void bounds(int, float result[6])
{
    optix::Aabb* aabb = (optix::Aabb*)result;
    aabb-&amp;gt;m_min = center - size;
    aabb-&amp;gt;m_max = center + size;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;intersection&#34;&gt;Intersection&lt;/h2&gt;

&lt;p&gt;衝突判定をするProgramです。&lt;/p&gt;

&lt;p&gt;ごくごく普通のレイマーチングです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;rtDeclareVariable(int, lgt_instance, , ) = {0};
rtDeclareVariable(float3, texcoord, attribute texcoord, );
rtDeclareVariable(int, lgt_idx, attribute lgt_idx, );

RT_PROGRAM void intersect(int primIdx)
{
    const float EPS = 1e-2;
    float t = 0.0, d = 1e100;
    float3 p = ray.origin;

    for (int i = 0; i &amp;lt; 50; i++)
    {
        d = map(p);
        t += d;
        p = ray.origin + t * ray.direction;
        if (abs(d) &amp;lt; EPS)
        {
            break;
        }
    }

    if (abs(d) &amp;lt; EPS &amp;amp;&amp;amp; rtPotentialIntersection(t))
    {
        shading_normal = geometric_normal = calcNormal(p, map);
        texcoord = make_float3(p.x, p.y, 0);
        lgt_idx = lgt_instance;
        rtReportIntersection(0);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;法線計算&#34;&gt;法線計算&lt;/h3&gt;

&lt;p&gt;法線計算は四面体によるアプローチを用いました。&lt;/p&gt;

&lt;p&gt;通常は6回の距離関数の評価が必要なところ、4回の評価だけで法線を計算できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://iquilezles.org/www/articles/normalsSDF/normalsSDF.htm&#34;&gt;normals for an SDF | http://iquilezles.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://setchi.hatenablog.com/entry/2018/12/17/095532&#34;&gt;#TokyoDemoFest 2018 の GLSL Graphics Compo で2位入賞しました - setchi’s blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;map関数を差し替え可能にするためにマクロをつかって実装しました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;const float EPS_N = 1e-4;
#define calcNormal(p, dFunc) normalize(\
    make_float3( EPS_N, -EPS_N, -EPS_N) * dFunc(p + make_float3( EPS_N, -EPS_N, -EPS_N)) + \
    make_float3(-EPS_N, -EPS_N,  EPS_N) * dFunc(p + make_float3(-EPS_N, -EPS_N,  EPS_N)) + \
    make_float3(-EPS_N,  EPS_N, -EPS_N) * dFunc(p + make_float3(-EPS_N,  EPS_N, -EPS_N)) + \
    make_float3( EPS_N,  EPS_N,  EPS_N) * dFunc(p + make_float3( EPS_N,  EPS_N,  EPS_N)))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;距離関数&#34;&gt;距離関数&lt;/h3&gt;

&lt;p&gt;以前にブログで紹介したIFSによるMengerSpongeの距離関数をCUDA Cに移植しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/25/unity-raymarching/&#34;&gt;Unity×レイマーチングによる映像制作の実践手法 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Swizzle Operationを手動展開するのがしんどかったです…&lt;/p&gt;

&lt;p&gt;ベクトル版のabsやmaxは自分で定義すれば解決しますが、Swizzle OperationをCUDA C上で再現する方法は私には分かりませんでした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;CUDA C言語、absやmaxにベクトル型のオーバーロードが無いし、Swizzle Operationも無いからストレスで発狂して精神が崩壊した🤬🤪🤮 &lt;a href=&#34;https://t.co/mRPmQTTcsb&#34;&gt;pic.twitter.com/mRPmQTTcsb&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1155465784807657472?ref_src=twsrc%5Etfw&#34;&gt;July 28, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = make_float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        // z = abs(z);
        z.x = abs(z.x);
        z.y = abs(z.y);
        z.z = abs(z.z);
        z.w = abs(z.w);

        // if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.y)
        {
            float x = z.x;
            z.x = z.y;
            z.y = x;
        }

        // if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.x &amp;lt; z.z)
        {
            float x = z.x;
            z.x = z.z;
            z.z = x;
        }

        // if (z.y &amp;lt; z.z) z.yz = z.zy;
        if (z.y &amp;lt; z.z)
        {
            float y = z.y;
            z.y = z.z;
            z.z = y;
        }

        z *= scale;
        // z.xyz -= offset * (scale - 1.0);
        z.x -= offset.x * (scale - 1.0);
        z.y -= offset.y * (scale - 1.0);
        z.z -= offset.z * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    // return (length(max(abs(z.xyz) - make_float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
    return (length(make_float3(max(abs(z.x) - 1.0, 0.0), max(abs(z.y) - 1.0, 0.0), max(abs(z.z) - 1.0, 0.0))) - 0.05) / z.w;
}

float map(float3 p)
{
    float scale = 100;
    return dMenger((p - center) / scale, make_float3(1, 1, 1), 3.1) * scale;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;c-からprogramの利用&#34;&gt;C++からProgramの利用&lt;/h2&gt;

&lt;p&gt;Programを利用するには以下のようなC++のコードを書けばOKです。&lt;/p&gt;

&lt;p&gt;ProgramとGPUに送る情報のバッファを指定しているだけです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Context        context = 0;
Program        pgram_raymarching_intersection = 0;
Program        pgram_raymarching_bounding_box = 0;

// レイマーチングのオブジェクトの GeometryInstance を生成します
GeometryInstance createRaymrachingObject(
    const float3&amp;amp; center,
    const float3&amp;amp; size)
{
    Geometry raymarching = context-&amp;gt;createGeometry();
    raymarching-&amp;gt;setPrimitiveCount(1u);
    raymarching-&amp;gt;setIntersectionProgram(pgram_raymarching_intersection);
    raymarching-&amp;gt;setBoundingBoxProgram(pgram_raymarching_bounding_box);

    raymarching[&amp;quot;center&amp;quot;]-&amp;gt;setFloat(center);
    raymarching[&amp;quot;size&amp;quot;]-&amp;gt;setFloat(size);

    GeometryInstance gi = context-&amp;gt;createGeometryInstance();
    gi-&amp;gt;setGeometry(raymarching);
    return gi;
}

// ジオメトリのセットアップをします
// ※レイマーチングに直接関係ないコードは省略しています
void loadGeometry()
{
    // Set up Raymarching programs
    const char *ptx = sutil::getPtxString( SAMPLE_NAME, &amp;quot;optixRaymarching.cu&amp;quot; );
    pgram_raymarching_bounding_box = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;bounds&amp;quot; );
    pgram_raymarching_intersection = context-&amp;gt;createProgramFromPTXString( ptx, &amp;quot;intersect&amp;quot; );

    // create geometry instances
    std::vector&amp;lt;GeometryInstance&amp;gt; gis;

    // Raymarcing
    gis.push_back(createRaymrachingObject(
        make_float3(278.0f, 120.0f, 278.0f),
        make_float3(100.0f, 100.0f, 100.0f)));
    setMaterial(gis.back(), diffuse, &amp;quot;diffuse_color&amp;quot;, white);

    // Create geometry group
    GeometryGroup geometry_group = context-&amp;gt;createGeometryGroup(gis.begin(), gis.end());
    geometry_group-&amp;gt;setAcceleration( context-&amp;gt;createAcceleration( &amp;quot;Trbvh&amp;quot; ) );
    context[&amp;quot;top_object&amp;quot;]-&amp;gt;set( geometry_group );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;optixの環境構築-windows&#34;&gt;Optixの環境構築（Windows）&lt;/h1&gt;

&lt;p&gt;OptixのWindows用の環境構築の流れは&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;必要なツールを事前にインストール&lt;/li&gt;
&lt;li&gt;CamkeでVisualStudioのソリューションファイルを生成&lt;/li&gt;
&lt;li&gt;VisualStudioでビルド&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;という感じでした。&lt;/p&gt;

&lt;p&gt;morishigeさんのQiitaの記事が大変参考になりました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/morishige/items/d4a99c88b925ac31ff3d&#34;&gt;Nvidia OptiX 入門（環境構築編）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CmakeとOptixとCUDAのバージョンの組み合わせが肝のようで、Cmakeのバージョンを変えながら何回かトライしたところ、この組み合わせでCmakeビルドに成功しました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;✍️ &lt;br&gt;CUDA 10.1&lt;br&gt;OptiX SDK 6.0.0&lt;br&gt;Visual Studio 2017&lt;br&gt;Cmake 3.8.2&lt;br&gt;&lt;br&gt;freeglut / GLFW / GLEW は Nuget の最新版をインストール&lt;a href=&#34;https://t.co/OtsR6bnxmk&#34;&gt;https://t.co/OtsR6bnxmk&lt;/a&gt;&lt;br&gt;&lt;br&gt;Cmakeの設定はスクショ通り &lt;a href=&#34;https://t.co/cpBM4y2Vy1&#34;&gt;pic.twitter.com/cpBM4y2Vy1&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1150906026528391168?ref_src=twsrc%5Etfw&#34;&gt;July 15, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;CmakeでVisual Studioのバージョンを選択する際、誤って64bit版ではなく32bit版を選択してしまい、Cmake自体は成功するもののソリューションがビルドできないことがありました。&lt;/p&gt;

&lt;p&gt;Cmakeの過去のバージョンはGitHubからインストールできます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kitware/CMake/releases&#34;&gt;Releases · Kitware/CMake&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;サンプルコードの改造&#34;&gt;サンプルコードの改造&lt;/h2&gt;

&lt;p&gt;サンプルコードの改造方法はNVIDIA Developer Forumsにあります。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devtalk.nvidia.com/default/topic/1049151/optix/how-can-i-modify-a-simple-example-/&#34;&gt;How can I modify a simple example? - NVIDIA Developer Forums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Adding a new example is very simple:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Copy one of the optixIntro_01 (this is effectively optixHello) to optixIntro_10 folders,&lt;/li&gt;
&lt;li&gt;rename it,&lt;/li&gt;
&lt;li&gt;rename the project name in its copied CMakeLists.txt,&lt;/li&gt;
&lt;li&gt;add your new subdirectory in the CMakeLists.txt one folder above,&lt;/li&gt;
&lt;li&gt;rebuild the solution with CMake GUI. Done.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your new project appears and would do the same thing as the example you copied it from.
Now change it as you like.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;参考資料&#34;&gt;参考資料&lt;/h1&gt;

&lt;p&gt;以下の記事が大変参考になりました。ありがとうございます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memo.render.jp/optix&#34;&gt;optix - uimac実装メモ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/gameworks/content/gameworkslibrary/optix/optix_quickstart.htm&#34;&gt;OptiX QuickStart（公式チュートリアル）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Unity×レイマーチングによる映像制作の実践手法</title>
      <link>https://gam0022.net/blog/2019/06/25/unity-raymarching/</link>
      <pubDate>Tue, 25 Jun 2019 09:00:00 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/06/25/unity-raymarching/</guid>
      <description>&lt;p&gt;6/19に開催された&lt;a href=&#34;https://techplay.jp/event/733454&#34;&gt;UnityエンジニアによるShader勉強会！&lt;/a&gt;で「Unity×レイマーチングによる映像制作の実践手法」という発表をしました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;daf8218b7458460087137b6f23e938b3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;この記事は、発表内容をブログ向けに編集・要約したものになります。スライドだけでは伝わりにくい箇所を文章でフォローしました。&lt;/p&gt;

&lt;p&gt;発表当日の様子は前回の記事にまとめました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/&#34;&gt;UnityエンジニアによるShader勉強会！に登壇しました | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表の題材-wormhole&#34;&gt;発表の題材『WORMHOLE』&lt;/h1&gt;

&lt;p&gt;TokyoDemoFest2018で発表した『WORMHOLE』という映像作品を題材とした発表です。&lt;/p&gt;

&lt;p&gt;WORMHOLEの映像はUnityと&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング&lt;/a&gt;を組み合わせて制作しました。&lt;/p&gt;

&lt;p&gt;以下の記事で利用したテクニックは既に解説していましたが、今回は &lt;strong&gt;汎用的に役立ちそうなテクニック&lt;/strong&gt; に焦点を絞って、前回は説明しきれなかった部分を掘り下げて解説しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;Tokyo Demo Fest 2018のDemo Compo優勝作品の解説（グラフィック編） | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回の発表では &lt;strong&gt;「形状」「質感」「演出」&lt;/strong&gt; の3つをテーマとして、WORMHOLEに用いたテクニックの解説を行いました。&lt;/p&gt;

&lt;h1 id=&#34;形状-モデリング&#34;&gt;形状（モデリング）&lt;/h1&gt;

&lt;p&gt;1つ目のテーマは &lt;strong&gt;「形状」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、形状を決める作業をモデリングと呼びます。
複雑なトンネルの形状を40行ほどの距離関数でモデリングする方法を解説しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.011.jpeg&#34; alt=&#34;トンネルの距離関数の設計アプローチ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;トンネルは既存のフラクタル図形をアレンジして設計しました。
IFSと呼ばれる手法でMengerSpongeと呼ばれる有名なフラクタル図形を定義（図の左）して、IFSのパラメータを変化によって形状をアレンジ（図の中央）し、さらにfoldRotateという操作を加えるとトンネルの形状（図の右）が完成します。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.012.jpeg&#34; alt=&#34;IFS（Iterated function system）とは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IFS&lt;/strong&gt; は自身の縮小コピーを重ね合わせることでフラクタル図形を作るテクニックです。
IFSはIterated Function Systemの略で、その名前の通りforループの中で、fold、拡大や縮小、平行移動といった操作を繰り返して距離関数をつくります。
forループで空間を操作してから、最後にBoxの距離関数を return します。&lt;/p&gt;

&lt;p&gt;ループの中でスケールと位置を変化させながら空間を折りたたみをして、Boxが出現する座標空間を再帰的に繰り返すことで、Boxを再帰的に配置するイメージです。&lt;/p&gt;

&lt;p&gt;foldの部分はかなり難解なので、1行ずつコメントアウトしながら変化を確認すると理解が深まると思います。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.013.jpeg&#34; alt=&#34;IFS（Iterated function system）のアレンジ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この関数では平行移動はOffset、拡大縮小はScaleという名前のパラメータにしました。&lt;/p&gt;

&lt;p&gt;このOffsetとScaleを変化させることで、フラクタル図形をアレンジできます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.014.jpeg&#34; alt=&#34;foldRotateとは&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;foldRotate&lt;/strong&gt; （別名: &lt;strong&gt;polarMod&lt;/strong&gt; ）はある軸を中心として一定の角度で回転しながら空間を折りたたみする操作です。
この回転の角度を変化させると、任意の図形を多角形の柱のような形に変形できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;三角柱を作りたいときは、360° を N = 3 で割った θ = 120° ずつ回転します。&lt;/li&gt;
&lt;li&gt;元の形が立方体なので、N = 4 のときは変化がありませんが、元の図形の4分の1が繰り返されています。&lt;/li&gt;
&lt;li&gt;N = 6 にすれば6角柱ができます。&lt;/li&gt;
&lt;li&gt;N = 8 にすれば8角柱になります。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WORMHOLEのトンネルには8角柱のfoldRotateを利用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.018.jpeg&#34; alt=&#34;最終的なコード&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここまで使ったIFSによるMengerSpongeの距離関数とfoldRotateを組み合わせた最終的な距離関数のコードがこちらです。
なんと、わずか40行のコードで複雑な形状を定義できました！
非常に短いコードだけで複雑なモデリングができるのが距離関数の強みです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float3 _MengerOffset;
float _MengerScale;
float _MengerFold;

// IFSによるMengerSpongeの距離関数
float dMenger(float3 z0, float3 offset, float scale) {
    float4 z = float4(z0, 1.0);
    for (int n = 0; n &amp;lt; 4; n++) {
        z = abs(z);

        if (z.x &amp;lt; z.y) z.xy = z.yx;
        if (z.x &amp;lt; z.z) z.xz = z.zx;
        if (z.y &amp;lt; z.z) z.yz = z.zy;

        z *= scale;
        z.xyz -= offset * (scale - 1.0);

        if (z.z &amp;lt; -0.5 * offset.z * (scale - 1.0))
            z.z += offset.z * (scale - 1.0);
    }
    return (length(max(abs(z.xyz) - float3(1.0, 1.0, 1.0), 0.0)) - 0.05) / z.w;
}

// 2Dの回転行列の生成
float2x2 rotate(in float a) {
    float s = sin(a), c = cos(a);
    return float2x2(c, s, -s, c);
}

// 回転のfold
// https://www.shadertoy.com/view/Mlf3Wj
float2 foldRotate(in float2 p, in float s) {
    float a = PI / s - atan2(p.x, p.y);
    float n = PI2 / s;
    a = floor(a / n) * n;
    p = mul(rotate(a), p);
    return p;
}

// 最終的な距離関数
inline float DistanceFunction(float3 pos) {
    // 回転foldの適用
    pos.yx = foldRotate(pos.yx, _MengerFold);

    return dMenger(pos, _MengerOffset, _MengerScale);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;シェーダー全体: &lt;a href=&#34;https://github.com/gam0022/unity-demoscene/blob/master/Assets/Demoscene/Projects/2019-06-02-KLabTechMeetup4/Tunel.shader&#34;&gt;Tunel.shader&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;距離関数のfoldについてブログ記事を書いたので、もっと詳しく知りたい方はご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold（折りたたみ）による形状設計 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;質感-ライティング&#34;&gt;質感（ライティング）&lt;/h1&gt;

&lt;p&gt;2つ目のテーマは &lt;strong&gt;「質感」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;CGの世界では、質感はライティング処理によって計算されます。
WORMHOLEではディファードレンダリングを採用しました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.021.jpeg&#34; alt=&#34;ディファードレンダリングを採用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングは2つのパスでシーンを描画するレンダリング手法です。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;G-Bufferパス&lt;/strong&gt; でNormalやDepthなどのライティングに必要な情報を詰め込んだGバッファを生成します。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lightingパス&lt;/strong&gt; でGバッファの情報を元にライティングを計算して、最終的なレンダリング結果を生成します。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;これがディファードレンダリングの流れです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.022.jpeg&#34; alt=&#34;ディファードレンダリングを採用した3つの理由&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ディファードレンダリングを採用した理由は3つあります。&lt;/p&gt;

&lt;p&gt;1つ目の理由は &lt;strong&gt;距離関数とポリゴンが混在したシーンであっても一貫したライティングができる&lt;/strong&gt; 点です。レイマーチングの結果をGバッファに書き込む &lt;strong&gt;G-Bufferパス&lt;/strong&gt; のシェーダーを実装すれば、Gバッファ上では距離関数もポリゴンもどちらもスクリーンスペースの2Dのデータとなり、両者を区別する必要がないので、一貫したライティングができます。
&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんが開発している&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching&lt;/a&gt;というレイマーチング用のシェーダーのテンプレートを用いると、このようなシェーダーを少ない手間で書くことができます。
WORMHOLEでもuRaymarchingを利用しています。&lt;/p&gt;

&lt;p&gt;2つ目の理由は、Unityが標準で用意している &lt;strong&gt;Lightingパス&lt;/strong&gt; を利用することで、自分でライティング処理を実装しなくてもUnityの全種類の光源やReflectionProbeに対応できる点です。
もしフォワードレンダリングでレイマーチングをする場合にはライティング処理を自力で実装する必要があるので、ライティング処理を実装しなくて済むのはディファードレンダリングの強みと言えると思います。&lt;/p&gt;

&lt;p&gt;3つ目の理由は、ディファードレンダリングの特性上、光源が数が多いシーンであっても現実的な処理負荷でライティングを計算できる点です。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.023.jpeg&#34; alt=&#34;ディファードレンダリングのライティングをカスタマイズ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一方でディファードレンダリングにはデメリットもあります。
シーン全体を同じ &lt;strong&gt;Lightingパス&lt;/strong&gt; で処理するということは、
裏を返すとマテリアルごとのライティングのカスタマイズが難しくなります。&lt;/p&gt;

&lt;p&gt;このような場合、StencilやGバッファにマテリアルIDの情報を埋め込んで、
Lightingパスの中でマテリアルを判定してライティングを切り替えることが正攻法となりますが、Lightingパスの修正となると、プロジェクト全体への影響も大きいですし、手間もかかってしまいます。&lt;/p&gt;

&lt;p&gt;WORMHOLEではEmissiveを活用してこの問題を解決しました。
Emissiveは自発光（自分が放つ光の強さ）のパラメーターですが、Emissive以外のパラメータを0にすると、Emissiveの色がそのまま最終的なピクセルの色として画面に出力されます。
この性質を利用して、独自のライティング結果をEmissiveに書き込むことで、自由にライティングをカスタマイズできます。&lt;/p&gt;

&lt;h1 id=&#34;演出-テキストのアニメーション&#34;&gt;演出（テキストのアニメーション）&lt;/h1&gt;

&lt;p&gt;3つ目のテーマは &lt;strong&gt;「演出」&lt;/strong&gt; です。&lt;/p&gt;

&lt;p&gt;演出と言ってもたくさんの要素があると思いますが、今回の発表ではテキストのアニメーション演出をシェーダーで実装する話をします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.028.jpeg&#34; alt=&#34;TextMeshProとは？&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProはSDFをつかって高品質にフォントをレンダリングするためのAssetです。&lt;/p&gt;

&lt;p&gt;SDFはSigned Distance Fieldのことで、左のように文字の輪郭までの距離を画素値にした画像です。
SDFを使うとフォントを拡大してもジャギが目立たないため、フォントのレンダリングに適しています。&lt;/p&gt;

&lt;p&gt;また、勘の良い方はお気づきかと思いますが、SDFはレイマーチングの距離関数と全く同じ概念です。
距離関数の入力が3Dなのか2Dなのかというのと、コードで表現されるか、テクスチャで表現されるかという違いはありますが、本質的には同じものです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p29.gif&#34; alt=&#34;TextMeshProの描画の仕組み&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProの描画の仕組みについて説明します。&lt;/p&gt;

&lt;p&gt;まずCPUで1文字ずつMeshを生成します。
オレンジ色で示されたTextMeshProの文字をワイヤーフレーム表示を見ると、1文字ずつMeshが存在することが分かります。&lt;/p&gt;

&lt;p&gt;SDFテクスチャのUV情報はMeshの頂点データとして埋め込まれています。
次にこのMeshを描画するフラグメントシェーダーをつかってSDFテクスチャをフェッチしてフォントの内外判定をしてフォントをレンダリングします。&lt;/p&gt;

&lt;p&gt;このように TextMeshProではシェーダーをつかってフォントをレンダリングしています。&lt;/p&gt;

&lt;p&gt;つまり、 &lt;strong&gt;シェーダーを書けば、TextMeshProのレンダリングを 自由にカスタマイズできます！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.031.jpeg&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ方法&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ方法を紹介します。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TextMeshProのシェーダーをコピーします。どのシェーダーをコピーしても良いのですが、Mobileと書いてあるものは実装がシンプルなのでオススメです。&lt;/li&gt;
&lt;li&gt;好きなようにシェーダーをカスタマイズします。色を決定する部分や、SDFテクスチャをフェッチする部分を改造するのが良いかと思います。&lt;/li&gt;
&lt;li&gt;TextMeshProのインスペクタから改造したシェーダーを設定すれば、完了です。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p32.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;TextMeshProのシェーダーのカスタマイズ例を2つ紹介します。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;【左】色を決定する部分のシェーダーを書き換えて、sin関数で模様と動きをつけて、ブラウン管風のエフェクトと追加しました。&lt;/li&gt;
&lt;li&gt;【右】2種類のSDFテクスチャをブレンドすることで、平成と令和をモーフィングさせました。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p33.gif&#34; alt=&#34;TextMeshProのシェーダーのカスタマイズ例2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これはWORMHOLEのオープニング部分のエフェクトです。文字をパラパラと出現させたり消失させたりしています。&lt;/p&gt;

&lt;p&gt;これがシェーダーの差分のコードです。
SDFテクスチャをフェッチするUVをこのように時間でclampすることで、フォントを引き伸ばす効果を加えました。
わずか3行くらいの差分ですが、面白いエフェクトができたかなと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;        // PIXEL SHADER
        fixed4 PixShader(pixel_t input) : SV_Target
        {
-           half d = tex2D(_MainTex, input.texcoord0.xy).a * input.param.x;
+           half2 uv = input.texcoord0.xy;
+           uv.y = clamp(uv.y, 0.0, 0.5 + 0.5 * sin(_Time.y));
+           half d = tex2D(_MainTex, uv).a * input.param.x;
            half4 c = input.faceColor * saturate(d - input.param.w);

        #ifdef OUTLINE_ON
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TextMeshProとカスタムシェーダーを組み合わせる方法についてはQiitaに記事を投稿しているので、詳しく知りたい方は、こちらをご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/f3b7a3e9821a67a5b0f3&#34;&gt;[Unity] カスタムシェーダーでTextMeshProに独創的な演出を加える | Qiita&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;番外編-unity-timelineを活用した演出&#34;&gt;番外編: Unity Timelineを活用した演出&lt;/h2&gt;

&lt;p&gt;番外編のテキスト以外の演出の話として、Unity Timelineの活用についても紹介しました。&lt;/p&gt;

&lt;p&gt;シェーダーだけでなくUnity Timelineも利用することで、演出制作の効率を高めました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.037.jpeg&#34; alt=&#34;Unity Timelineの活用&#34; /&gt;&lt;/p&gt;

&lt;p&gt;オレンジ色の枠で囲まれているのがTimeline Windowです。&lt;/p&gt;

&lt;p&gt;演出の品質を高めるためには、演出の試行錯誤のイテレーションが必要です。
このイテレーションを高速に回すために、リアルタイムに編集結果をプレビューできる点や、自由に再生時間をシークできる点が本当に良かったです。&lt;/p&gt;

&lt;p&gt;Timelineの主な利用箇所です。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Animation Track

&lt;ul&gt;
&lt;li&gt;レイマーチング用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;li&gt;ポストエフェクト用のマテリアルのパラメータ制御&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TextMeshPro専用のCustom Track

&lt;ul&gt;
&lt;li&gt;TextMeshProのテキストを書き換えは標準のTrackでは実現できなかったので、Timelineのカスタムトラックを自作して実現しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chinemachine Track

&lt;ul&gt;
&lt;li&gt;カメラワークにはChinemachineというAssetのトラックを利用しました。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup.041.jpeg&#34; alt=&#34;演出のまとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;シェーダーが不得意な（数式で表現しにくい）演出はTimelineも活用することで、効率的に演出を制作しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;規則的な（数式で表現ができる）動きはシェーダーが得意

&lt;ul&gt;
&lt;li&gt;音楽のBPMに合わせてチカチカ点滅させるのは、シェーダーが適しています。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;不規則な（数式で表現しにくい）動きはTimelineが得意

&lt;ul&gt;
&lt;li&gt;カメラワークはTimelineを利用したほうが効率的に演出が作れると思います。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/klab_tech_meetup_p35.gif&#34; alt=&#34;まとめ&#34; /&gt;&lt;/p&gt;

&lt;p&gt;リアルな質感も、複雑な形状も、カッコいい演出も、どれもシェーダーで実現できます。&lt;/p&gt;

&lt;p&gt;短いコードだけで多彩な表現ができるため、映像作成においては &lt;strong&gt;シェーダーは最強の道具&lt;/strong&gt; だと言えるでしょう。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UnityエンジニアによるShader勉強会！に登壇しました</title>
      <link>https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/</link>
      <pubDate>Thu, 20 Jun 2019 10:04:11 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/06/20/klab-tech-meetup4/</guid>
      <description>&lt;p&gt;6/19に開催された&lt;a href=&#34;https://techplay.jp/event/733454&#34;&gt;UnityエンジニアによるShader勉強会！&lt;/a&gt;で「Unity×レイマーチングによる映像制作の実践手法」という発表をしました。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;daf8218b7458460087137b6f23e938b3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（06/25追記）&lt;/strong&gt; 発表内容をブログ向けに編集・要約して別記事にまとめました。
スライドだけでは伝わりにくい箇所を文章でフォローしました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2019/06/25/unity-raymarching/&#34;&gt;Unity×レイマーチングによる映像制作の実践手法 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表資料まとめ&#34;&gt;発表資料まとめ&lt;/h1&gt;

&lt;p&gt;発表者の資料のツイートをまとめました。&lt;/p&gt;

&lt;h2 id=&#34;kanetaaaaa-シェーダーライブコーディングのすすめ&#34;&gt;@kanetaaaaa 「シェーダーライブコーディングのすすめ」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;先日の資料を元にシェーダーライブコーディング入門の記事を書きました🤔&lt;br&gt;普段シェーダーを使ってる人の遊び道具になって欲しいです！&lt;br&gt;懇親会時に作ったシェーダーで使用したテクニックもいくつか追加で紹介しています！！&lt;a href=&#34;https://t.co/MgDFAatZre&#34;&gt;https://t.co/MgDFAatZre&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141485526815346688?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の資料のために眺めるだけでレイマーチングを完全に理解できるかもしれないシェーダーを作りました🤔&lt;a href=&#34;https://t.co/Hia4I0Dgii&#34;&gt;https://t.co/Hia4I0Dgii&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://t.co/kIuU4USxRJ&#34;&gt;pic.twitter.com/kIuU4USxRJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141307706139004934?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;gam0022-unity-レイマーチングによる映像制作の実践手法&#34;&gt;@gam0022「Unity×レイマーチングによる映像制作の実践手法」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です！&lt;br&gt;モデリングと演出とライティングを全部シェーダーで実装しました！&lt;a href=&#34;https://t.co/lwg0xVcm3J&#34;&gt;https://t.co/lwg0xVcm3J&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity3D?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3D&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/HLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#HLSL&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1141307844999778304?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログも更新しました🙏&lt;br&gt;全員の発表資料をまとめ！もあります。&lt;a href=&#34;https://t.co/TdiHF5jILF&#34;&gt;https://t.co/TdiHF5jILF&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity3D?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity3D&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Shader?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Shader&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/HLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#HLSL&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1141541272877850624?ref_src=twsrc%5Etfw&#34;&gt;2019年6月20日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;archeleeds-unityで遊べる背景シェーダーを作る&#34;&gt;@archeleeds「Unityで遊べる背景シェーダーを作る」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;KLab Tech Meetup #4&lt;br&gt;「Unityで遊べる背景シェーダーを作る」のスライドです&lt;a href=&#34;https://t.co/YyVB6gEhVk&#34;&gt;https://t.co/YyVB6gEhVk&lt;/a&gt;&lt;br&gt;拙いですが何かの参考になれば 🙇‍♂️&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt;&lt;/p&gt;&amp;mdash; リゼ (@archeleeds) &lt;a href=&#34;https://twitter.com/archeleeds/status/1141376228558983168?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;setchi-fancyscrollview-x-shader&#34;&gt;@setchi「FancyScrollView x Shader」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;スクロールビューでもシェーダー芸がしたい！&lt;br&gt;KLab TECH Meetup ＃4 で発表したスライドおよびサンプルコードです。&lt;br&gt;&lt;br&gt;GitHub: &lt;a href=&#34;https://t.co/WFqznn2vVM&#34;&gt;https://t.co/WFqznn2vVM&lt;/a&gt;&lt;br&gt;Google Slides: &lt;a href=&#34;https://t.co/TR5KBVmDUJ&#34;&gt;https://t.co/TR5KBVmDUJ&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/madewithunity?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#madewithunity&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/gamedev?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#gamedev&lt;/a&gt; &lt;a href=&#34;https://t.co/zqECmup7Qi&#34;&gt;pic.twitter.com/zqECmup7Qi&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1141313091134562304?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログ更新しました &amp;gt; スクロールビューでもシェーダー芸がしたい！&lt;a href=&#34;https://t.co/5bNo2FlQqe&#34;&gt;https://t.co/5bNo2FlQqe&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/gamedev?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#gamedev&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1142779645751783425?ref_src=twsrc%5Etfw&#34;&gt;2019年6月23日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;20分シェーダーライブコーディング-by-kanetaaaaa&#34;&gt;20分シェーダーライブコーディング by @kanetaaaaa&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;昨日の勉強会の懇親会中に20分間のライブコーディングでシェーダーを作りました！&lt;br&gt;初めて人前でコーディングをしたんですが、めちゃくちゃ楽しかったです！！&lt;br&gt;&lt;br&gt;（当日動かなかったpmod修正済です&amp;hellip;）&lt;br&gt;差分&lt;br&gt;- q.x = abs(p.x ) - 10.;&lt;br&gt;+ q.x = abs(q.x ) - 10.;&lt;a href=&#34;https://t.co/LH3TT4YzSU&#34;&gt;https://t.co/LH3TT4YzSU&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; &lt;a href=&#34;https://t.co/k61c3O2ZA1&#34;&gt;pic.twitter.com/k61c3O2ZA1&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141480732180619264?ref_src=twsrc%5Etfw&#34;&gt;2019年6月19日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;先日の &lt;a href=&#34;https://twitter.com/hashtag/klab_meetup?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#klab_meetup&lt;/a&gt; の懇親会で行った20分のライブコーディング映像を公開しました！&lt;br&gt;実況解説は&lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt; さんと&lt;a href=&#34;https://twitter.com/songofsaya_?ref_src=twsrc%5Etfw&#34;&gt;@songofsaya_&lt;/a&gt;さんです&lt;br&gt;突発ながら面白い実況で場を盛り上げてくださって非常に楽しかったです！&lt;br&gt;動画でもこの空間の楽しさが伝わると思うので是非ご覧ください！&lt;a href=&#34;https://t.co/1CDeXMfJlT&#34;&gt;https://t.co/1CDeXMfJlT&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1141987474824036353?ref_src=twsrc%5Etfw&#34;&gt;2019年6月21日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;これまでの人生で最高の勉強会でした！&lt;/p&gt;

&lt;p&gt;参加者も発表者もモチベーションがとても高く、終始ものすごい熱気に包まれていて、発表する側としても非常にやりやすかったです！&lt;/p&gt;

&lt;p&gt;勉強会のテーマがニッチすぎることから当初は参加枠を100名としていたのですが、告知開始から数時間後には満員となってしまったため、最終的に会場のキャパシティ上限の200名まで増枠することになりました。
これほど大人数の勉強会が実現されるとは思っておらず、世間のシェーダーへの関心の高さに驚きました。&lt;/p&gt;

&lt;p&gt;どの発表も尖った内容が満載だったのではないでしょうか。
シェーダーに対する理解がより深まり、興味が増したのであれば幸いです。&lt;/p&gt;

&lt;p&gt;ご参加いただいた皆さま、本当にありがとうございました！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/live-coding-original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2019-06-20-klab-tech-meetup4/live-coding.jpg&#34; alt=&#34;懇親会中のライブコーディングの様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;懇親会中のライブコーディングの様子&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>先頭にコピペするだけ！Shadertoy → GLSL Sandbox / NEORT の移植用ヘッダーコードの紹介</title>
      <link>https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/</link>
      <pubDate>Mon, 04 Mar 2019 09:01:07 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.shadertoy.com/&#34;&gt;Shadertoy&lt;/a&gt;のコードを&lt;a href=&#34;http://glslsandbox.com/&#34;&gt;GLSL Sandbox&lt;/a&gt;に一発で移植するコードを思いつきました。&lt;/p&gt;

&lt;p&gt;以下のコードをShadertoyのコードの先頭にコピペするだけで、元のコードには一切手を加えずにGLSL Sandbox用のコードに変換できます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// BEGIN: shadertoy porting template
// https://gam0022.net/blog/2019/03/04/porting-from-shadertoy-to-glslsandbox/
precision highp float;

uniform vec2 resolution;
uniform float time;
uniform vec2 mouse;

#define iResolution resolution
#define iTime time
#define iMouse mouse

void mainImage(out vec4 fragColor, in vec2 fragCoord);

void main(void) {
    vec4 col;
    mainImage(col, gl_FragCoord.xy);
    gl_FragColor = col;
}
// END: shadertoy porting template
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Shadertoyのマルチパスやテクスチャ機能をつかったShaderの移植はできませんが、普通の1パスのShaderなら移植できると思います。&lt;/p&gt;

&lt;p&gt;ぜひ使ってみてください！&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;shadertoy-neort-の移植事例&#34;&gt;Shadertoy → NEORT の移植事例&lt;/h2&gt;

&lt;p&gt;最近、&lt;a href=&#34;https://neort.io/&#34;&gt;NEORT&lt;/a&gt;という国内産Shadertoyのようなサイトが登場しました。&lt;/p&gt;

&lt;p&gt;NEORTはGLSL Sandbox互換があるので、ご紹介した方法で一発でShadertoyから移植できました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;NEORTはじめました⛩️&lt;a href=&#34;https://twitter.com/hashtag/GLSL?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#GLSL&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/creativecoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#creativecoding&lt;/a&gt; &lt;a href=&#34;https://t.co/acKyzwIU8S&#34;&gt;https://t.co/acKyzwIU8S&lt;/a&gt; &lt;a href=&#34;https://t.co/1AqphUQ5jv&#34;&gt;pic.twitter.com/1AqphUQ5jv&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1100564853985501184?ref_src=twsrc%5Etfw&#34;&gt;2019年2月27日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;解説&#34;&gt;解説&lt;/h2&gt;

&lt;p&gt;なぜこれでうまく移植できるのか、簡単に解説します。&lt;/p&gt;

&lt;h3 id=&#34;uniform名の違いの吸収&#34;&gt;uniform名の違いの吸収&lt;/h3&gt;

&lt;p&gt;まず以下のコードでShadertoyとGLSL Sandboxのuniform名の違いの吸収しています。&lt;/p&gt;

&lt;p&gt;単純に &lt;code&gt;#define&lt;/code&gt; のプリプロセッサで置換しているだけなので、特に不思議なことは無いと思います。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;uniform vec2 resolution;
uniform float time;
uniform vec2 mouse;

#define iResolution resolution
#define iTime time
#define iMouse mouse
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;エントリーポイント名の違いの吸収&#34;&gt;エントリーポイント名の違いの吸収&lt;/h3&gt;

&lt;p&gt;Shadertoyのエントリポイントは &lt;code&gt;mainImage&lt;/code&gt; で、GLSL Sandboxは &lt;code&gt;main&lt;/code&gt; です。&lt;/p&gt;

&lt;p&gt;が、よく考えてみると、ShadertoyもWebGLで実装されているからにはGLSLのルールに従って &lt;code&gt;main&lt;/code&gt; が定義されているはずです。&lt;/p&gt;

&lt;p&gt;Shadertoyのソースコードを眺めてみると、&lt;code&gt;mainImage&lt;/code&gt; を呼び出す &lt;code&gt;main&lt;/code&gt; 関数をヘッダーとして挿入する実装になっています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void main(void) {
    vec4 col;
    mainImage(col, gl_FragCoord.xy);
    gl_FragColor = col;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この「mainImage を呼び出す main を定義する」というアイデアは&lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta&lt;/a&gt;さんのこの作品からヒントをもらいました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;早速2D版🤔のGLSLコード置いているので、ご自由にお使いください🤔&lt;a href=&#34;https://t.co/OJjTYlLy0c&#34;&gt;https://t.co/OJjTYlLy0c&lt;/a&gt; &lt;a href=&#34;https://t.co/NYN6zT77sM&#34;&gt;pic.twitter.com/NYN6zT77sM&lt;/a&gt;&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1099180997269106688?ref_src=twsrc%5Etfw&#34;&gt;2019年2月23日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;次はコンパイルエラーを避けるための前方宣言です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void mainImage(out vec4 fragColor, in vec2 fragCoord);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GLSLではC言語と同様に、別の関数から呼び出される前に関数を定義するか、前方宣言する必要があります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GLSL Compoに役立つ！GLSL Sandbox互換のVSCode拡張『Shader Toy』の紹介</title>
      <link>https://gam0022.net/blog/2018/12/24/vscode-glslsandbox/</link>
      <pubDate>Mon, 24 Dec 2018 23:59:59 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/12/24/vscode-glslsandbox/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;https://qiita.com/advent-calendar/2018/webgl&#34;&gt;WebGL Advent Calendar 2018&lt;/a&gt;の24日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;みなさんはGLSL Sandboxのシェーダーをローカルで編集したりgitで管理したいと思ったことはありませんか？&lt;/p&gt;

&lt;p&gt;VSCodeの拡張機能の『Shader Toy』をインストールすれば簡単に実現できます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=stevensona.shader-toy&#34;&gt;Shader Toy - Visual Studio Marketplace
&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本拡張は&lt;a href=&#34;https://www.shadertoy.com/&#34;&gt;Shadertoy&lt;/a&gt;と&lt;a href=&#34;http://glslsandbox.com/&#34;&gt;GLSL Sandbox&lt;/a&gt;の互換性を備えており、
どちらのコードも修正なしにそのまま動作できます！&lt;/p&gt;

&lt;p&gt;WindowsとMacの両方に対応しています。&lt;/p&gt;

&lt;p&gt;次の画像は&lt;a href=&#34;https://nanka.hateblo.jp/entry/2018/12/13/080322&#34;&gt;Traveler2&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/kanetaaaaa&#34;&gt;kaneta&lt;/a&gt;（&lt;a href=&#34;http://tokyodemofest.jp/2018/&#34;&gt;Tokyo Demo Fest 2018&lt;/a&gt; GLSL Compo優勝作品）をVSCode上で動作させた様子です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/traveler2-win.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/traveler2-win.jpg&#34; alt=&#34;traveler2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;導入方法と使い方&#34;&gt;導入方法と使い方&lt;/h1&gt;

&lt;p&gt;導入方法と使い方は簡単です。&lt;/p&gt;

&lt;h2 id=&#34;導入方法&#34;&gt;導入方法&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-24-vscode-glslsandbox/install.png&#34; alt=&#34;install&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;拡張機能のウィンドウを開く&lt;/li&gt;
&lt;li&gt;「shadertoy」で検索&lt;/li&gt;
&lt;li&gt;インストールボタンを押す&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;使い方&#34;&gt;使い方&lt;/h2&gt;

&lt;p&gt;GLSLのコードを編集した状態でコマンドパレットから「Shader Toy: GLSL Preview」を開くだけです。&lt;/p&gt;

&lt;p&gt;GLSLのコードを認識しないときは、「Shader Toy: GLSL Preview」を閉じてから再実行すると認識できる場合があります。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;※以降の内容はポエム・個人的なメモです。あまり有益な情報はありませんのでご注意ください。&lt;/p&gt;

&lt;h1 id=&#34;glsl-sandbox互換の理由&#34;&gt;GLSL Sandbox互換の理由&lt;/h1&gt;

&lt;p&gt;ところで、『Shader Toy』という名前なのに、なぜGLSL Sandboxにも対応しているのでしょうか？&lt;/p&gt;

&lt;p&gt;元々は Shadertoy互換の拡張だったのですが、次のPull Requestで私がGLSL Sandbox互換を追加しました💪&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/stevensona/shader-toy/pull/37&#34;&gt;GLSLsandbox support by gam0022 · Pull Request #37 · stevensona/shader-toy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;拡張の名前から考えて、GLSL Sandbox互換の機能追加が受け入れられるか心配でしたが、爆速でマージしていただけました！
stevensonaさんありがとうございます🙏&lt;/p&gt;

&lt;h1 id=&#34;開発動機&#34;&gt;開発動機&lt;/h1&gt;

&lt;p&gt;Tokyo Demo Fest 2018のライブコーディングバトルの練習のために、
ローカル上で他人に見られないようにglslfanのコードを書きたいというのが開発の動機でした。&lt;/p&gt;

&lt;p&gt;ライブコーディングというのは、その場でコーディングを行うということです。
今回のライブコーディングバトルでは、4人の競技者が40分の制限時間内で、glslfan上でGLSLのシェーダーによる作品をつくりあげました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://glslfan.com/&#34;&gt;glslfan.com&lt;/a&gt;はdoxasさんが開発されているGLSL Sandbox互換のライブコーディングをリアルタイム配信するサイトです。
他人のシェーダコーディングをある程度リアルタイムに覗き見できることを特徴としています。
リアルタイムに配信する機能は素晴らしいのですが、ライブコーディングの練習をしている様子を一般公開したくなかったので、
ローカル上でGLSLのコードを編集できる環境を構築するために、「Shader Toy」拡張を改造しようと思いました。&lt;/p&gt;

&lt;h1 id=&#34;glsl-compo優勝者と準優勝者のお役に立てた&#34;&gt;GLSL Compo優勝者と準優勝者のお役に立てた&lt;/h1&gt;

&lt;p&gt;本家にPull Requestを送る前に&lt;a href=&#34;https://gist.github.com/gam0022/910bef95310f52995477dcb7bcc0467a&#34;&gt;改造版の拡張のインストール手順&lt;/a&gt;をTwitterで公開していました。&lt;/p&gt;

&lt;p&gt;その結果、GLSL Compoの1位と2位の方々に利用していただき、お役に立てたようで嬉しいです😆&lt;/p&gt;

&lt;p&gt;GLSL Compo1位のkanetaさんのツイート&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;法線求める時forでインライン展開押さえるのすご..&lt;br&gt;GLSL Grapherと&lt;a href=&#34;https://twitter.com/gam0022?ref_src=twsrc%5Etfw&#34;&gt;@gam0022&lt;/a&gt;先生の拡張は僕もめっちゃ使いました!&lt;/p&gt;&amp;mdash; かねた (@kanetaaaaa) &lt;a href=&#34;https://twitter.com/kanetaaaaa/status/1074471599804301312?ref_src=twsrc%5Etfw&#34;&gt;2018年12月17日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;GLSL Compo2位のsetchiさんのツイート&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ブログ更新しました &amp;gt; &lt;a href=&#34;https://twitter.com/hashtag/TokyoFemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoFemoFest&lt;/a&gt; 2018 の GLSL Graphics Compo で2位入賞しました&lt;a href=&#34;https://t.co/XyntUxDCGD&#34;&gt;https://t.co/XyntUxDCGD&lt;/a&gt;&lt;/p&gt;&amp;mdash; setchi (@setchi) &lt;a href=&#34;https://twitter.com/setchi/status/1074469119481663489?ref_src=twsrc%5Etfw&#34;&gt;2018年12月17日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;VSCode 上で GLSL 環境を探していたときに、ちょうど gam0022 先生が GLSL Sandbox 互換の VSCode 拡張を公開していたのでありがたく使わせていただきました！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;ライブコーディングバトルで優勝できた&#34;&gt;ライブコーディングバトルで優勝できた&lt;/h1&gt;

&lt;p&gt;&lt;del&gt;本拡張をつかった練習の成果によって、&lt;/del&gt; ライブコーディングバトルで優勝しました😉&lt;/p&gt;

&lt;p&gt;こんな感じの作品をGLSLのシェーダーだけで40分でつくりました！&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;シェーダーライブコーディングバトルの優勝作品です！&lt;br&gt;ありがとうございました！&lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/tdf2018?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tdf2018&lt;/a&gt;&lt;a href=&#34;https://t.co/MJwbIWFOMl&#34;&gt;https://t.co/MJwbIWFOMl&lt;/a&gt; &lt;a href=&#34;https://t.co/LVr2LYvUgi&#34;&gt;pic.twitter.com/LVr2LYvUgi&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1068782247711465472?ref_src=twsrc%5Etfw&#34;&gt;2018年12月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;（本当はを大会前日まで&lt;a href=&#34;https://gam0022.net/blog/2018/12/12/tdf2018/&#34;&gt;PC Demo Compoの作品制作をしていたので&lt;/a&gt;、ライブコーディングの練習はほとんどできませんでした😇）&lt;/p&gt;

&lt;p&gt;競技中に私の画面が真っ白になってしまい、
実況者（&lt;a href=&#34;https://twitter.com/h_doxas&#34;&gt;@h_doxas&lt;/a&gt;さん、&lt;a href=&#34;https://twitter.com/amagitakayosi&#34;&gt;@amagitakayosi&lt;/a&gt;さん）に「仕込んでますよ」「隠してますよ」「いやらしいですね」
と解説されていたのですが、本当は原因不明のバグで苦しんでいて頭も真っ白でした😨
終盤にバグの原因を突き止めてなんとか逆転優勝できました。&lt;/p&gt;

&lt;p&gt;参加者4人の作品を並べた動画はこちらです。
左上が&lt;a href=&#34;https://twitter.com/FMS_Cat&#34;&gt;@FMS_Cat&lt;/a&gt;さん、右上が&lt;a href=&#34;https://twitter.com/gyabo&#34;&gt;@gyabo&lt;/a&gt;さん、左下が&lt;a href=&#34;https://twitter.com/notargs&#34;&gt;@notargs&lt;/a&gt;さん、そして右下が私&lt;a href=&#34;https://twitter.com/gam0022&#34;&gt;@gam0022&lt;/a&gt;の作品です。
どの作品もレベルが高くて、みんな凄すぎますね👏&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;ライブコーティングバトルの最終成果物 &lt;a href=&#34;https://twitter.com/hashtag/TokyoDemoFest?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#TokyoDemoFest&lt;/a&gt; &lt;a href=&#34;https://t.co/CpIWIhcqoH&#34;&gt;pic.twitter.com/CpIWIhcqoH&lt;/a&gt;&lt;/p&gt;&amp;mdash; kaiware style🌱 (@kaiware007) &lt;a href=&#34;https://twitter.com/kaiware007/status/1068777639333126144?ref_src=twsrc%5Etfw&#34;&gt;2018年12月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;IGN JAPAN様にライブコーディングバトルを含めたTDFの1日目の様子をご紹介いただきました。興味がある方は是非ご覧ください。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jp.ign.com/event/31357/news/etokyo-demo-fest-2018&#34;&gt;eスポーツもゲーム開発もゲームエンジンも生み出したデモシーン！日本で唯一のデモシーンイベント「Tokyo Demo Fest 2018」レポ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;shadertoyとglsl-sandboxのマウスの違い&#34;&gt;ShadertoyとGLSL Sandboxのマウスの違い&lt;/h1&gt;

&lt;p&gt;開発する中でShadertoyとGLSL Sandboxのマウスの扱いの違いに苦しめられたので、後学のためにメモを残します。&lt;/p&gt;

&lt;p&gt;ShadertoyとGLSL Sandboxを相互に移植にする際などに参考にしてください。&lt;/p&gt;

&lt;p&gt;本拡張では以下のマウスの扱いの違いを考慮して実装しました。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Shadertoy&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;GLSL Sandbox&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;uniform定義&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;uniform vec4 iMouse;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;uniform vec2 mouse;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;解説（日本語）&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ピクセル座標系のマウス座標。&lt;br&gt;xy: 現在のマウス座標 (左クリック時に更新)&lt;br&gt;zw: マウスのクリック状態&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜1に正規化したマウス座標。&lt;br&gt;xy: 現在のマウス座標（毎フレーム更新）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Explanation（English）&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mouse pixel coords. &lt;br&gt;xy: current (if MLB down), &lt;br&gt;zw: click&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mouse normalized coords. &lt;br&gt;xy: current&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;xyの値域&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜解像度&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0〜1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>Tokyo Demo Fest 2018のDemo Compo優勝作品の解説（グラフィック編）</title>
      <link>https://gam0022.net/blog/2018/12/12/tdf2018/</link>
      <pubDate>Wed, 12 Dec 2018 09:49:52 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/12/12/tdf2018/</guid>
      <description>&lt;p&gt;これは&lt;a href=&#34;http://qiita.com/advent-calendar/2018/klab&#34;&gt;KLab Engineer Advent Calendar 2018&lt;/a&gt;の12日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;12月1日～12月2日に秋葉原で開催された&lt;a href=&#34;http://tokyodemofest.jp/2018/&#34;&gt;Tokyo Demo Fest 2018&lt;/a&gt;（以下、TDF）に参加しました。&lt;/p&gt;

&lt;p&gt;TDFは、日本国内で唯一のデモパーティです。
コンピュータを用いて作成された楽曲や映像作品をデモと呼び、
デモに関心のある人々が一堂に会してコンペティションを行ったり、技術を共有したりといったイベントをデモパーティと呼びます。&lt;/p&gt;

&lt;p&gt;今年のTDFでは、さだきちさん（&lt;a href=&#34;https://twitter.com/sadakkey&#34;&gt;@sadakkey&lt;/a&gt;）とチームを組み、『WORMHOLE』（映像：gam0022 / サウンド：sadakkey）という作品を発表しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tdf2018_collage_original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tdf2018_collage.jpg&#34; alt=&#34;WORMHOLE by gam0022 &amp;amp; sadakkey&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Windows実行ファイル形式のデモ作品のコンペティションであるCombined Demo Compoにて、&lt;a href=&#34;http://tokyodemofest.jp/2018/results.txt&#34;&gt;本作品が1位&lt;/a&gt;に選ばれました！&lt;/p&gt;

&lt;p&gt;この記事では『WORMHOLE』の映像制作技術について解説します。
ソースコードを公開していますので、ご興味のある方はそちらもご確認いただければと思います（スターください！）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene&#34;&gt;https://github.com/gam0022/unity-demoscene&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;サウンド編についてはさだきちさんが解説されています。あわせてご覧ください！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://klabgames.creative.blog.jp.klab.com/archives/14415590.html&#34;&gt;Tokyo Demo Fest2018のDemo Compo優勝作品の解説〜サウンド編〜 : KLabGames Creative Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;作品の概要&#34;&gt;作品の概要&lt;/h1&gt;

&lt;p&gt;「ワームホールによる空間移動」をコンセプトとして、
不思議な球体がワームホールを介して非現実なデジタル空間と水平線の広がる自然空間を行き来する映像を制作しました。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/NMNJV-Pbqtk&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;不思議な球体がトンネルを進んでいくと、周囲を明滅する光がだんだんとモノクロからカラフルに変わっていきます。
トンネルの最奥にあるワームホールへ近づくほど明滅はだんだんと激しくなっていき、ホワイトアウトとともにワームホールを越えると、球体は海上に出現します。
その後、球体はじわじわと歪んでいき、戦闘機へと形を変えます。&lt;/p&gt;

&lt;p&gt;変形中の不思議な球体の上には、私が尊敬するデモシーナーの名前を表示しました。
これはグリーティングと呼ばれるデモシーンにおける慣習です。&lt;/p&gt;

&lt;p&gt;戦闘機はパーティクルを放ちながら海上を進み、パーティクルが一瞬だけTDFのロゴを形作ります。
そして戦闘機は元の球体に変形し、突如現れたワームホールに吸い込まれるようにして冒頭のトンネルのシーンに戻っていきます。&lt;/p&gt;

&lt;p&gt;実装ならびに制作にはUnityを利用しました。
詳細は後述しますが、Timeline, TextMeshPro, Chinemachine, PostProcessingStack v2といったUnity 2018.2の新機能も活用しています。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;レンダリング&#34;&gt;レンダリング&lt;/h1&gt;

&lt;p&gt;映像の大部分は&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング&lt;/a&gt;で描画し、パーティクルやグリーティングのテキストなどのレイマーチングが苦手とする部分はラスタライザで描画するというハイブリッドなレンダリング方式を採用しました。&lt;/p&gt;

&lt;p&gt;なお、今回は制作期間が短かったため、レイマーチングのシェーディングにはUnity標準のディファードレンダリングを利用することにしました。
ディファードレンダリングにすることで、Gバッファの書き込みまでを実装すれば、それ以降のライティングの処理をUnityの標準のディファードレンダリングのシェーダーに任せることができます。
簡単に言ってしまえば、Unityでサポートされる全種類のライトやGI機能に対応するライティング処理をあえて自分で実装しなくて済むという、工数削減のメリットがあります。&lt;/p&gt;

&lt;p&gt;Unityでディファードレンダリングによるレイマーチングを実現するにあたり、
&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんの&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching&lt;/a&gt;を利用させていただきました。
uRaymarchingは距離関数とGバッファに値を書き込む部分を実装すれば、簡単にレイマーチングができる便利なシェーダーテンプレートです。&lt;/p&gt;

&lt;p&gt;他にも、鏡面反射による周囲の映り込みに、Unity標準のReflectionProbeを配置して実現しています。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;uRaymarchingとReflectionProbeによる反射と組み合わせる検証&lt;br&gt;中&lt;br&gt;&lt;br&gt;毎フレームCubemapを生成するくらいならレイトレで反射を計算したほうが速いと思っていたが、この例ならCubemapの解像度は16x16でも十分だし、Cubemapの方がポリゴンとの混在が容易なので、現実的な方法だと思う。 &lt;a href=&#34;https://t.co/sSX7WmVCEd&#34;&gt;pic.twitter.com/sSX7WmVCEd&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1003274796895895554?ref_src=twsrc%5Etfw&#34;&gt;2018年6月3日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;full-screen-quadの実装方法&#34;&gt;Full Screen Quadの実装方法&lt;/h2&gt;

&lt;p&gt;uRaymarchingの話に関連して、Full Screen Quadの実装方法について紹介します。&lt;/p&gt;

&lt;p&gt;uRaymarchingではCommandBufferでフルスクリーンQuadを表示させていましたが、
スクリプトによる制御は最小限にしてEditorモードの挙動を安定させたかったので、別のアプローチをとってみました。&lt;/p&gt;

&lt;p&gt;EditorツールでBoudingBoxを巨大にしてFrustum Cullingを無効にしたQuadを静的生成しました。&lt;/p&gt;

&lt;p&gt;これによって時々レイマーチング部分が動かないトラブルを回避できました。
また、本作品のようにFull Screen Quadが必要なレイマーチングのワールドが複数存在して、
時間によって切り替わる表現のためには、MeshRendererのenableの切り替えで制御できる単純な仕組みの方が好都合でした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;Unityで画面全体にレイマーチングをさせる最高のソリューションができた！&lt;br&gt;&lt;br&gt;CommandBufferを使う方法だとEditMode等の考慮が大変。&lt;br&gt;通常のQuadだとFrustum Cullingされて困る。&lt;br&gt;&lt;br&gt;そこで、BoudingBoxを拡張したQuadを事前生成して通常のMeshRendererで描画できるようにした。&lt;a href=&#34;https://t.co/Askoyvnq0X&#34;&gt;https://t.co/Askoyvnq0X&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1018214911367761920?ref_src=twsrc%5Etfw&#34;&gt;2018年7月14日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/pull/10&#34;&gt;RaymarchingQuadMeshCreator by gam0022 · Pull Request #10 · gam0022/unity-demoscene&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;トンネルのモデリング&#34;&gt;トンネルのモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tunnel_original.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/tunnel.jpg&#34; alt=&#34;tunnel&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;トンネルはMenger spongeという有名なフラクタル図形をベースにしています。
回転のfoldのテクニックを利用して万華鏡のように見せたり、modをつかった図形の繰り返しのテクニックを適用しました。&lt;/p&gt;

&lt;p&gt;回転のfoldは次の記事で紹介しています。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold（折りたたみ）による形状設計 | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上の4種類の画像はいずれも同じ距離関数によるトンネルの様子です。
パラメータを変化させることで形状や色などを演出に合わせて変更できるようにしました。&lt;/p&gt;

&lt;h1 id=&#34;海面のモデリング&#34;&gt;海面のモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/sea.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/sea.jpg&#34; alt=&#34;sea&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;海面は平面として衝突判定を行い、ノーマルマップだけで波が立っているように見せています。
こちらは以前にWebGLによって実装した『&lt;a href=&#34;https://gam0022.net/blog/2017/06/30/raymarching-kado/&#34;&gt;正解するカドの「カド」をレイマーチングでリアルタイム描画する | gam0022.net&lt;/a&gt;』と同じアプローチの軽量化方法です。&lt;/p&gt;

&lt;p&gt;ところで、上記の記事の作品と異なり、本作品ではLODを一切行っておりません。
カメラワーク的に海面に近づかないため、そもそもLODが必要なかったのと、
マーチングループ中でテクスチャのフェッチをするとUnityのシェーダーのコンパイルが激重になる現象を回避するためです。&lt;/p&gt;

&lt;p&gt;海面の質感は、Gバッファに書き込むパラメータの調整だけで再現しました。
ディファードレンダリングなので不透明オブジェクトとして当然ライティングされているのですが、どことなく海中を感じさせるような半透明の質感を擬似的に再現できたのではないかと思います。&lt;/p&gt;

&lt;h1 id=&#34;戦闘機のモデリング&#34;&gt;戦闘機のモデリング&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/plane.jpg&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/plane.jpg&#34; alt=&#34;plane&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;戦闘機は距離関数でモデリングしました。&lt;/p&gt;

&lt;p&gt;3つのBoxの大きさをcos/sin/abs等で調整しつつ、smoothminによるメタボールでBoxを融合することで、流線形のSFっぽい戦闘機をモデリングしました。&lt;/p&gt;

&lt;p&gt;また、フラグメントシェーダーの負荷軽減のために&lt;a href=&#34;http://i-saint.hatenablog.com/entry/2015/08/24/225254&#34;&gt;Object Space Raymarching&lt;/a&gt;を行いました。
Full Screen Quadを使わずに戦闘機と同じ大きさのSphereを配置し、Sphereのシェーダーでレイマーチングをしています。
上記の画像を拡大するとSphereのワイヤーフレームを確認できます。&lt;/p&gt;

&lt;h1 id=&#34;演出の実装&#34;&gt;演出の実装&lt;/h1&gt;

&lt;h2 id=&#34;textmeshproによるフォントのレンダリング&#34;&gt;TextMeshProによるフォントのレンダリング&lt;/h2&gt;

&lt;p&gt;フォントはプロシージャルではなくテクスチャを使用しています。
TextMeshProのEditorツールを利用して &lt;a href=&#34;https://www.fontspace.com/mixofx/azonix&#34;&gt;Azonix fontのデータ&lt;/a&gt;からSDFのフォントのアトラステクスチャを生成しました。&lt;/p&gt;

&lt;p&gt;生成したアトラステクスチャはTextMeshProのシェーダーでレンダリングしています。&lt;/p&gt;

&lt;p&gt;次のような簡単な文字の出現と消滅のエフェクトを、TextMeshProの標準シェーダーの一部を改造して実装しました。
この演出に関する解説を&lt;a href=&#34;https://qiita.com/advent-calendar/2018/unity2&#34;&gt;Unity #2 Advent Calendar 2018&lt;/a&gt;の19日目の記事で行いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/gam0022/items/f3b7a3e9821a67a5b0f3&#34;&gt;[Unity] カスタムシェーダーでTextMeshProに独創的な演出を加える&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-conversation=&#34;none&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;TextMeshPro シェーダー遊び その3&lt;a href=&#34;https://twitter.com/hashtag/unity3d?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#unity3d&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/Unity?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#Unity&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/creativecoding?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#creativecoding&lt;/a&gt; &lt;a href=&#34;https://t.co/bUJvfyDhBr&#34;&gt;pic.twitter.com/bUJvfyDhBr&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/1056398353569697792?ref_src=twsrc%5Etfw&#34;&gt;2018年10月28日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&#34;animation-track-vs-custom-track&#34;&gt;Animation Track vs Custom Track&lt;/h2&gt;

&lt;p&gt;UnityのTimelineではトラックを自作することができます（以降、自作トラックのことをCustom Trackと書きます）。&lt;/p&gt;

&lt;p&gt;Custom Trackの実装はそれなりに工数がかかります。
たとえば、クリップのパラメータを1つでも増やすと複数箇所に変更が発生します。
工数が限られている場合や試行錯誤しながら色々なパータンを作る場合には、Animation Trackでは実現できないのかを事前に確認することをおすすめします。&lt;/p&gt;

&lt;p&gt;本作品でも、基本的にはAnimation Trackを利用し、アニメーションでは制御できないTextMeshProの文字列指定においてのみCustom Trackを利用する方針としました。&lt;/p&gt;

&lt;h2 id=&#34;パーティクル&#34;&gt;パーティクル&lt;/h2&gt;

&lt;p&gt;パーティクルはUnityのParticleSystemを利用しました。&lt;/p&gt;

&lt;p&gt;次の画像はポストエフェクトとSkyboxをOFFにした状態でパーティクルをワイヤーフレーム表示したものです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/particle_discard.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/particle_discard.png&#34; alt=&#34;particle_discard&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;パーティクルの形状は5種類でしたが、パーティクル用のモデルは1種類しか用意しませんでした。
四角形のQuadをフラグメントシェーダーでdiscardして形状を変化させました。
すべてのパーティクルを1マテリアルで表現できるので、全パーティクルを1ドローコールで描画できました。&lt;/p&gt;

&lt;p&gt;4種類のパーティクルが当時に登場する演出では、Custom Vertex Streamsを用いてランダム値をシェーダーに渡し、シェーダーで形状の切り替えを行いました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://goisagi-517.hatenablog.com/entry/2018/05/15/011845&#34;&gt;【Unity】Shuriken Particle「Custom Vertex Streams」  - ゴイサギ日記&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ワームホールの実装&#34;&gt;ワームホールの実装&lt;/h2&gt;

&lt;p&gt;「ワームホールの中身だけ別の世界になる」演出にも戦闘機と同じObject Space Raymarchingの仕組みを利用しました。&lt;/p&gt;

&lt;p&gt;まずHoudiniでワームホールの八角形のポリゴンメッシュを作成しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/houdini.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/houdini.png&#34; alt=&#34;houdini&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この八角形のメッシュのシェーダーでObject Space Raymarchingを行えば、別の世界と繋がる演出ができます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/gate.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2018-12-12-tdf2018/gate.jpg&#34; alt=&#34;gate&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ところが、カメラの原点からレイを進めると、別世界が3Dの立体映像のように飛び出してしまうという罠にハマってしまいました。
この問題はレイを物体の表面から進めることで回避できました。&lt;/p&gt;

&lt;p&gt;ワームホールの内側は現在の世界（上の画像では海の世界）のレイマーチングのシェーダーを無効にしたかったので、Stencilを利用しようとしたのですが、
UnityのディファードレンダリングではStencilの利用が制限されていました。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.unity3d.com/ja/current/Manual/SL-Stencil.html&#34;&gt;ShaderLab: ステンシル - Unity マニュアル&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;deferred レンダリングパスでレンダリングするオブジェクトのためのステンシル機能はいくらか制限されます。それらの 2 つのステージの間、シェーダーで定義されるステンシルステートは無視され、最終的なパスの間に考慮されるだけです。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;そこで、DepthテストとRenderQueueによる制御でStencilを代用しました。&lt;/p&gt;

&lt;h2 id=&#34;reflectionprobeの映り込みによる演出&#34;&gt;ReflectionProbeの映り込みによる演出&lt;/h2&gt;

&lt;p&gt;2回目のワームホール出現時（2:05〜）に海面が黒く侵食されていく演出があります。&lt;/p&gt;

&lt;div class=&#34;movie-wrap&#34;&gt;
&lt;iframe width=&#34;1920&#34; height=&#34;1080&#34; src=&#34;https://www.youtube.com/embed/NMNJV-Pbqtk?start=125&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;これは、ワームホールの向こう側の景色がReflectionProbeに映り込み、Unityのライティング機能によって自動的に水面に反映された結果です。
意図的に演出したものではなく偶然の産物でしたが、気に入ったのでこのまま採用しました。&lt;/p&gt;

&lt;h2 id=&#34;揺らぎ&#34;&gt;揺らぎ&lt;/h2&gt;

&lt;!-- 直す --&gt;

&lt;p&gt;揺らぎは2箇所で利用しました。
単純でコストもかからない工夫ですが、効果は大きいと感じました。&lt;/p&gt;

&lt;p&gt;カメラにfbmノイズを加えて手ブレ感を出すことで臨場感が生まれました。&lt;/p&gt;

&lt;p&gt;それから、戦闘機をcos波で振り子のように左右に揺らしています。
戦闘機の動き自体はZ軸に直進するだけなのですが、機体の揺れとカメラワークによって旋回しているような雰囲気が出ているのではないでしょうか。&lt;/p&gt;

&lt;h1 id=&#34;音楽との同期方法&#34;&gt;音楽との同期方法&lt;/h1&gt;

&lt;h2 id=&#34;ビート単位でのシェーダー制御&#34;&gt;ビート単位でのシェーダー制御&lt;/h2&gt;

&lt;p&gt;シェーダーの入力をビートにし、演出を「ビート単位」で制御することで、映像と音楽を同期させました。
時間単位（秒単位）で制御するよりも、BPM変更に柔軟に対応できるというメリットがあります。&lt;/p&gt;

&lt;p&gt;秒数 &lt;code&gt;time&lt;/code&gt; を特定のBPM &lt;code&gt;bpm&lt;/code&gt; のビートに変換するには &lt;code&gt;beat = time * bpm / 60&lt;/code&gt; を計算します。&lt;/p&gt;

&lt;h2 id=&#34;カメラのカット切り替えやパーティクルの同期&#34;&gt;カメラのカット切り替えやパーティクルの同期&lt;/h2&gt;

&lt;p&gt;カメラのカットやパーティクルのエミットのタイミングといったシェーダーで制御していない部分は、
音楽に合わせてTimelineのクリップを手動で配置する必要がありました。&lt;/p&gt;

&lt;p&gt;こちらは音楽を120BPMで制作していただいたことで、かなり楽に解決できました。&lt;/p&gt;

&lt;p&gt;120BPMでは、1ビートが0.5秒となります。&lt;/p&gt;

&lt;p&gt;4分の4拍子であれば1小節の長さが2秒となるため、カメラのカット切り替えを2秒単位にすると音楽と映像が自然に同期します。
同様に、4分の3拍子であればカット切り替えを1.5秒単位にすればよいわけです。&lt;/p&gt;

&lt;p&gt;パーティクルは、エミット間隔を0.5秒ごとに設定することで音楽とタイミングを合わせています。&lt;/p&gt;

&lt;h1 id=&#34;来年の抱負&#34;&gt;来年の抱負&lt;/h1&gt;

&lt;p&gt;次はライティングに凝ってみたいです。&lt;/p&gt;

&lt;p&gt;物理ベースレンダリング（PBR）で攻めるのであれば今回のライティングはUnityに任せる作戦で正解だと思いますが、
非現実的なレンダリング（NPR）には対応できないので、ディファードレンダリングのライティングパスの独自実装などを調査したいです。&lt;/p&gt;

&lt;p&gt;他にも、Unityの新機能のScriptable Render Pipeline (SRP) や
High Definition Render Pipeline（HDRP）とレイマーチングを組み合わせる検証などもしてみたいです。&lt;/p&gt;

&lt;h1 id=&#34;おわりに&#34;&gt;おわりに&lt;/h1&gt;

&lt;p&gt;『WORMHOLE』の映像を作るための取り組みや手法について技術的な視点で解説しました。&lt;/p&gt;

&lt;p&gt;上記の通り、『WORMHOLE』の制作にはUnityの機能やライブラリを多く利用しています。
巨人の肩の上に立つことで表現の部分に注力でき、3週間弱という短い制作期間の中で完成度の高い作品に仕上げることができました。&lt;/p&gt;

&lt;p&gt;とはいえ、制作期間中は『WORMHOLE』を受け入れてもらえないのではと常に不安を感じていました。
デモシーンの世界ではゲームエンジンの機能に頼らない高度な実装力こそ評価されると思っていたからです。
そんな予想に反し、Unityで作成したデモ作品を高く評価していただけて大変光栄です。&lt;/p&gt;

&lt;p&gt;Unityには初心者～上級者まで様々なレベルの方を対象とした資料や教材があります。
『WORMHOLE』では使用しませんでしたが、たくさんのアセットも用意されています。
デモシーンに興味はあるもののハードルが高そうで踏みとどまっている方や、レンダリング技術の学習に挫折してしまった方に、Unityでもデモ作品を作成できることをお伝えしたいです。
また、日頃の業務でUnityを利用している方に、自分でも作れそうな身近なものとしてデモシーンに興味を持ってもらえれば嬉しいです。
『WORMHOLE』が新たなデモシーナーを生み出すきっかけとなれば幸いです。&lt;/p&gt;

&lt;p&gt;最後に、素晴らしいサウンドを生み出してくれたさだきちさんに感謝申し上げます。
チームでTDFに参加するのは今回が初めてでしたが、非常に良い経験をさせてもらいました。
自分の映像にかっこいい音楽が組み合わさった時の喜びや興奮は忘れられません！ありがとうございました！！&lt;/p&gt;

&lt;h1 id=&#34;関連情報&#34;&gt;関連情報&lt;/h1&gt;

&lt;h2 id=&#34;wormhole-を高画質で見るには&#34;&gt;『WORMHOLE』を高画質で見るには&lt;/h2&gt;

&lt;p&gt;下記の実行ファイルか動画ファイルをダウンロードしていただくと、エンコード前の綺麗な画質でご覧いただけます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://files.scene.org/view/parties/2018/tokyodemofest18/demo/wormhole.zip&#34;&gt;Windowsの実行ファイル&lt;/a&gt;（GTX1070以上のGPU推奨）&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1GxyxjOyGBRcofMVKILmJtlmYaMZ5XoGx/view&#34;&gt;動画ファイル&lt;/a&gt;（ブラウザ上だとエンコードされた状態で再生されるのでダウンロードしてください）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;wormhole-の感想をお待ちしております&#34;&gt;『WORMHOLE』の感想をお待ちしております！&lt;/h2&gt;

&lt;p&gt;pouet.netという世界中のデモ情報を集めたポータルサイトに作品を公開しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pouet.net/prod.php?which=79380&#34;&gt;pouet.net内の『WORMHOLE』のページ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;作品の感想をYouTubeやpouet.netでいただけると泣いて喜びます。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メガデモ勉強会!2018で発表しました</title>
      <link>https://gam0022.net/blog/2018/03/16/demoscene-study-session/</link>
      <pubDate>Fri, 16 Mar 2018 10:14:35 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2018/03/16/demoscene-study-session/</guid>
      <description>&lt;p&gt;3/10（土）に開催された&lt;a href=&#34;https://atnd.org/events/93843&#34;&gt;メガデモ勉強会! 2018&lt;/a&gt;で発表しました。&lt;/p&gt;

&lt;p&gt;発表タイトルは「もっと綺麗で写実的な絵作りをしたい！レイマーチング向けのシェーディング技術」です。&lt;/p&gt;

&lt;p&gt;発表の概要はこんな感じです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;レイマーチングのおさらい&lt;/li&gt;
&lt;li&gt;レイマーチングでいい感じにシェーディングするための理論と実践

&lt;ul&gt;
&lt;li&gt;写実的なレンダリングに不可欠な &lt;strong&gt;大域照明&lt;/strong&gt; を説明&lt;/li&gt;
&lt;li&gt;大域照明を構成する間接照明を近似する &lt;strong&gt;AO&lt;/strong&gt; を説明&lt;/li&gt;
&lt;li&gt;レイマーチングによるAO計算の実装を図で解説&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;レイマーチングによるマテリアル実装のベストプラクティスを紹介&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AOがどういう意味を持つのか、大域照明にどんな関係にあるのか、などを学んでいただけたら嬉しいです。
レイマーチングによるAO計算の動作原理を図で解説した日本語の資料は見たことが無いので、
この発表を聞いて「なるほどな」と思ってもらえれば幸いです。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;74ea75d0686849238368f73150a7adba&#34; data-ratio=&#34;1.33333333333333&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です😇 &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;a href=&#34;https://t.co/pxqSbH3DPl&#34;&gt;https://t.co/pxqSbH3DPl&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ😇 (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/972340970892111874?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&#34;発表の紹介と感想&#34;&gt;発表の紹介と感想&lt;/h1&gt;

&lt;p&gt;自分以外の発表について、自分の感想を混じえながら紹介します。&lt;/p&gt;

&lt;h2 id=&#34;notargs-さんの-デモのためのunity講座&#34;&gt;@notargs さんの「デモのためのUnity講座」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日のメガデモ勉強会で発表した資料です&lt;a href=&#34;https://t.co/DStmEyNQ5a&#34;&gt;https://t.co/DStmEyNQ5a&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;/p&gt;&amp;mdash; のたぐすキャット (@notargs) &lt;a href=&#34;https://twitter.com/notargs/status/972345507111616512?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;去年の末に&lt;a href=&#34;https://gam0022.net/blog/2017/12/25/unity-demoscene/&#34;&gt;Unityによるデモを作成&lt;/a&gt;を試みていたところだったので、参考になる情報がたくさんありました。&lt;/p&gt;

&lt;p&gt;音響にエフェクトをかけるための&lt;code&gt;OnAudioFilterRead&lt;/code&gt;で入力を無視して波形を作れば、プロシージャルに音楽も作れますね。
良いことを知りました。&lt;/p&gt;

&lt;h2 id=&#34;soma-arc-さんの-鏡映によるフラクタルとglslによる描画&#34;&gt;@soma_arc さんの「鏡映によるフラクタルとGLSLによる描画」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; 「鏡映によるフラクタルとGLSLによる描画」で使用した資料を公開しました．本日はありがとうございました．&lt;a href=&#34;https://t.co/r3o3Rajbpn&#34;&gt;https://t.co/r3o3Rajbpn&lt;/a&gt;&lt;a href=&#34;https://t.co/wL36mO8d6e&#34;&gt;https://t.co/wL36mO8d6e&lt;/a&gt;&lt;/p&gt;&amp;mdash; 蘇摩 (@soma_arc) &lt;a href=&#34;https://twitter.com/soma_arc/status/972426826772434945?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;ずっと聞いてみたかった内容でした。資料も説明も上手で理解しやすかったです。&lt;/p&gt;

&lt;p&gt;以前にブログで紹介した&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfold&lt;/a&gt;に近いものを感じました。&lt;/p&gt;

&lt;p&gt;foldでは平面の鏡を使いましたが、この発表では円形の鏡を使うイメージだと理解しました。&lt;/p&gt;

&lt;p&gt;円の鏡映では、まず円形の鏡を配置します。すると鏡同士で相互に反射するので、合わせ鏡のように、映り込んだ円がさらに再帰的に別の円の鏡に映り込みます。反射の再帰の深度に応じて色をつけると、単純な円から美しい模様が生成できると理解しました。&lt;/p&gt;

&lt;p&gt;円の外にテクスチャを置いた例や、2D -&amp;gt; 3D に拡張した球の鏡による例も紹介されていました。&lt;/p&gt;

&lt;h2 id=&#34;fl1ne-さんの-tokyodemofestとfrontl1neのご紹介&#34;&gt;@FL1NE   さんの「TokyoDemoFestとFRONTL1NEのご紹介」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の発表資料です &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt; &lt;a href=&#34;https://t.co/NkgvYkD8eH&#34;&gt;https://t.co/NkgvYkD8eH&lt;/a&gt;&lt;/p&gt;&amp;mdash; ΓL1ИΞ@GDC2018 (@FL1NE) &lt;a href=&#34;https://twitter.com/FL1NE/status/972377117815009280?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Tokyo Demo Fest 2018 は10月〜11月に開催予定！&lt;/p&gt;

&lt;p&gt;Meet the Meatのパワーワード感がすごい！&lt;/p&gt;

&lt;h2 id=&#34;fms-cat-さんの-glslで音楽を作ります&#34;&gt;@FMS_Cat さんの「GLSLで音楽を作ります」&lt;/h2&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;本日の勉強会で使ったサンプルコードおよびスライドです。 &lt;a href=&#34;https://t.co/tkAqql021E&#34;&gt;https://t.co/tkAqql021E&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/%E3%83%A1%E3%82%AC%E3%83%87%E3%83%A2%E5%8B%89%E5%BC%B7%E4%BC%9A?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#メガデモ勉強会&lt;/a&gt;&lt;/p&gt;&amp;mdash; JPEG Depression (@FMS_Cat) &lt;a href=&#34;https://twitter.com/FMS_Cat/status/972495648883752960?ref_src=twsrc%5Etfw&#34;&gt;2018年3月10日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;シェーダーで音楽を作ってみたいと思いながらも、音楽知識が0で諦めていた私のような人のための発表でした。&lt;/p&gt;

&lt;p&gt;資料も説明も素晴らしくて、素人の私でもすっと頭に入ってきました。&lt;/p&gt;

&lt;p&gt;「ステレオサウンド」「音量・音階・音色」「コード」のような基礎用語の説明がカバーされていて助かりました。
GLSLの実装を踏まえた説明だったので、よく知らない音楽の概念も理解できました。&lt;/p&gt;

&lt;p&gt;特に印象的だったのは楽器編成です。
sin波や矩形波といった単純な波形をベースにして、本物の楽器のような音色を作れることに感動しました。&lt;/p&gt;

&lt;p&gt;またコードを構成する音からランダムに音を選択し、オクターブもランダムに変化させることで、
ランダムながらかなり曲っぽい感じになることにびっくりしました（アルペジオ？）。&lt;/p&gt;

&lt;p&gt;音楽は諦めかけていましたが、この発表のおかげで自分で音楽を制作する道筋が見えました。
発表で使われたコードはGitHubでも公開されているので、実際にShadertoyで動かして理解を深めているところです。
素敵な発表ありがとうございました！&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;勉強会から帰宅した後、FMS_Catさんの発表でオススメされていた「Moleman 2」という動画を家で見ました。
メガデモの起源から現在に至るまで、メガデモの歴史を1時間30分に凝縮された動画になっていて、デモシーナー必見の内容でした。&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/iRkZcTg1JWU&#34; frameborder=&#34;0&#34; allow=&#34;autoplay; encrypted-media&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h1 id=&#34;さいごに&#34;&gt;さいごに&lt;/h1&gt;

&lt;p&gt;ずっと気になっていた内容を聞けて大満足でした。どの発表も資料も説明も分かりやすくて素晴らしかったです。
懇親会では、以前の自分の発表でレイマーチングを知って、卒業制作にレイマーチングを使ったという学生とお話しました。
自分の活動を通して何かを得た人もいるということに嬉しくなりました。&lt;/p&gt;

&lt;p&gt;メガデモ制作のモチベーションが高まってきたので、今年の10〜11月のTDFに向けて頑張りたいです！&lt;/p&gt;

&lt;p&gt;運営の方々、発表者の方々、会場を提供していただいたさくらインターネット様、ご参加いただいた方々、ありがとうございました！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unityでメガデモ制作に挑戦（uRaymarchingとTimelineを試す）</title>
      <link>https://gam0022.net/blog/2017/12/25/unity-demoscene/</link>
      <pubDate>Mon, 25 Dec 2017 09:30:11 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2017/12/25/unity-demoscene/</guid>
      <description>&lt;p&gt;これは &lt;a href=&#34;https://qiita.com/advent-calendar/2017/unity2&#34;&gt;Unity #2 Advent Calendar 2017&lt;/a&gt; 21日目の記事です。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%A2%E3%82%B7%E3%83%BC%E3%83%B3&#34;&gt;デモシーン&lt;/a&gt;界隈では、美しいCGアニメーションをリアルタイムに生成するプログラムを「デモ」と呼びます。&lt;/p&gt;

&lt;p&gt;今回はUnityを使ったデモの制作に初挑戦しました。
13秒の短い無音の動画です。&lt;/p&gt;

&lt;iframe width=&#34;720&#34; height=&#34;405&#34; src=&#34;https://www.youtube.com/embed/BZGO5xXuPj8&#34; frameborder=&#34;0&#34; gesture=&#34;media&#34; allow=&#34;encrypted-media&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;!--
[![THE GLOW](/images/posts/2017-12-21-unity-demoscene/cut1.jpg)](/images/posts/2017-12-21-unity-demoscene/cut1.jpg)
--&gt;

&lt;h1 id=&#34;作品の解説&#34;&gt;作品の解説&lt;/h1&gt;

&lt;p&gt;「レイマーチングで動的に生成したモデル」と「ポリゴンメッシュのモデル」を混在させた作品です。
ロボットは通常の3Dモデルですが、床や柱のモデルはレイマーチングでプロシージャルに生成しました。&lt;/p&gt;

&lt;p&gt;レイマーチングにはuRaymarchingというAssetを利用しました。&lt;/p&gt;

&lt;p&gt;映像作品と相性が良さそうなので、Unity2017のTimelineも利用しました。&lt;/p&gt;

&lt;p&gt;今回は試作という意味から、uRaymarchingとTimelineの他にも様々なアセットを試しました。
色々と試行錯誤をしたので、この記事ではそのノウハウを共有したいと思います。&lt;/p&gt;

&lt;p&gt;Unityのバージョンは執筆時点の最新版である2017.2.1f1を用いました。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;uraymarchingによるレイマーチング&#34;&gt;uRaymarchingによるレイマーチング&lt;/h2&gt;

&lt;p&gt;uRaymarchingはレイマーチングのシェーダの作成をサポートするシェーダ群とエディタ拡張です。
開発者は&lt;a href=&#34;https://twitter.com/hecomi&#34;&gt;@hecomi&lt;/a&gt;さんです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hecomi/uRaymarching&#34;&gt;uRaymarching | GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tips.hecomi.com/entry/2016/10/11/225541&#34;&gt;Unity でレイマーチングするシェーダを簡単に作成できるツールを作ってみた&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;uRaymarchingではDefferedシェーディングを採用しており、レイマーチングのシェーダはGバッファに対して結果を書き込みます。
そのため、今回のようにレイマーチングとポリゴンのモデルが混在したシーンであっても、一貫したシェーディングを実現できました！&lt;/p&gt;

&lt;p&gt;レイマーチングの衝突判定などの共通処理は、uRaymarchingが提供する共通のシェーダが肩代わりしてくれます。
uRaymarchingの利用者は、レイマーチングの距離関数の定義とGバッファの書き込みの処理だけに集中できるため、開発効率が向上しました。&lt;/p&gt;

&lt;p&gt;具体的な使い方を簡単に説明しますと、まずはuRaymarchingのエディタ拡張でレイマーチングシェーダの雛形を作成します。
次に雛形シェーダの2つの関数をカスタマイズすれば、独自のレイマーチングシェーダをお手軽に作成できました。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;距離関数の定義を&lt;code&gt;DistanceFunction&lt;/code&gt;関数に記述&lt;/li&gt;
&lt;li&gt;Gバッファへの書き込み処理を&lt;code&gt;PostEffect&lt;/code&gt;関数に記述&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;uRaymarchingのチュートリアル動画です。&lt;/p&gt;

&lt;iframe width=&#34;720&#34; height=&#34;540&#34; src=&#34;//www.youtube.com/embed/AppyVflAagc?wmode=transparent&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;距離関数の設計&#34;&gt;距離関数の設計&lt;/h3&gt;

&lt;p&gt;Boxの組み合わせだけでシーンを構成しました。
床はBoxを敷き詰めているのは見た目通りだと思いますが、柱もBoxの組み合わせで作っています！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/03/02/raymarching-fold/&#34;&gt;距離関数のfoldの記事&lt;/a&gt;で紹介した回転のfoldを利用して、
Boxから上から見たときに多角形になる柱を生成しました。&lt;/p&gt;

&lt;p&gt;単純なBoxの形状だけでも、時間経過で形状が変化する面白い形ができたと思っています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/distance-function.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/distance-function.jpg&#34; alt=&#34;柱の様子&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;床がランダムな順番に光る演出&#34;&gt;床がランダムな順番に光る演出&lt;/h3&gt;

&lt;p&gt;床をランダムに光らせる演出は自分でも気に入っています。&lt;/p&gt;

&lt;p&gt;この演出はお手軽な方法で実装できました！&lt;/p&gt;

&lt;p&gt;まずは、Y座標に応じて光るように、Gバッファに書き出すemissionを設定します。
光らせるY座標の位置は時間でアニメーションさせます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 _SlideEmission;

inline void PostEffect(RaymarchInfo ray, inout PostEffectOutput o)
{
    float a = frac(4.0 * ray.endPos.y - 2.0 * _Time.x - 0.5);
    float width = 0.04;
    o.emission = _SlideEmission * abs(sin(PI * 12.0 * _Time.x)) * step(a, width) * ((a + 0.5 * width) / width);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、床のブロックの高さの動きをランダムに設定します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float dFloor(float3 pos)
{
    float3 p = pos;
    p.xz = Repeat(p.xz, 0.5);
    p.y += 1 + 0.1 * sin(36.0 * _Time.x + 2.0 * Rand(floor(2.0 * pos.xz)));
    return sdBox(p, float3(0.2, 0.2, 0.2));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけで、床をにランダムに光らせる演出の完成です！&lt;/p&gt;

&lt;p&gt;床の高さがバラバラになっているので、等高線で光らせるとタイミングが微妙にずれて、いい感じにバラバラのタイミングで光ります！&lt;/p&gt;

&lt;h3 id=&#34;uraymarchingのトラブルシューティング&#34;&gt;uRaymarchingのトラブルシューティング&lt;/h3&gt;

&lt;p&gt;2点だけつまずいたポイントがあったので、後学のためにメモを残しておきます。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ShaderTemplates で Direct GBuffer を選択すると、影が落ちない（Shadow Caster が動作しない）

&lt;ul&gt;
&lt;li&gt;これはUnityの仕様に原因があるらしく、hecomiさんの記事にも書いてありました&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;プロジェクトの設定で &lt;code&gt;metalEditorSupport: 0&lt;/code&gt; にしないと、Macで動作しない

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/commit/47f19613bbc032bef1b8b35b9b972f3f9983debc&#34;&gt;修正のコミット&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;timelineとの連携&#34;&gt;Timelineとの連携&lt;/h2&gt;

&lt;p&gt;Unity2017のTimeline機能でカメラワークやロボットの動き、UI上のテキストなどの演出の制御をしました。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline.jpg&#34; alt=&#34;timeline&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;カメラワーク&#34;&gt;カメラワーク&lt;/h3&gt;

&lt;p&gt;Timelineからゲームオブジェクトを操作する2つの方法があります。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Playables&lt;/code&gt;を実装・利用する方法

&lt;ul&gt;
&lt;li&gt;APIは複雑で、気軽に使うのは難しい&lt;/li&gt;
&lt;li&gt;作り込めば何でもできる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ITimeControl&lt;/code&gt;を継承したコンポーネントを実装・利用する方法

&lt;ul&gt;
&lt;li&gt;APIは単純で、気軽に使える&lt;/li&gt;
&lt;li&gt;できることが少ない（クリップの現在時間しか受け取れない）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;カメラワークの制御をどちらで行うのか悩みましたが、最終的には以下の理由で&lt;code&gt;ITimeControl&lt;/code&gt;に決めました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;とりあえずカメラを動かすだけなら、&lt;code&gt;ITimeControl&lt;/code&gt;が手っ取り早いと感じた&lt;/li&gt;
&lt;li&gt;カメラワークを汎用的な&lt;code&gt;Playables&lt;/code&gt;に落とし込む時間もスキルも足りなかった&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;とりあえずカメラワークを&lt;code&gt;ITimeControl&lt;/code&gt;で実装することはできましたが、
&lt;code&gt;ITimeControl&lt;/code&gt;では再生時間の情報しか受け取れず、クリップごとにパラメータを持たすことすらできません。
三角関数などを駆使してカメラのtransformを操作して、無理やりカメラワークを実装しましたが、
&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/blob/bdb84d7517b812f742363c971174d9435cea0cb2/Assets/Demoscene/TheGlow/TheGlowCameraWork.cs&#34;&gt;職人芸すぎてメンテナンスが困難なコード&lt;/a&gt;になりました。&lt;/p&gt;

&lt;p&gt;今回は満足するものはできなかったので、次回はこれらの方法でカメラワークに再挑戦したいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/95266&#34;&gt;Default Playables&lt;/a&gt;
に含まれているTimeline Playable Wizardを使えば、&lt;code&gt;Playables&lt;/code&gt;の雛形コードを作成できるそうなので、これを利用して独自&lt;code&gt;Playables&lt;/code&gt;の実装に再挑戦する&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tsubakit1.hateblo.jp/entry/2017/06/15/225504&#34;&gt;Cinemachine&lt;/a&gt;というUnity公式のカメラワークを作るための&lt;code&gt;Playables&lt;/code&gt;を利用する&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ロボットの動き&#34;&gt;ロボットの動き&lt;/h3&gt;

&lt;p&gt;ロボットに&lt;code&gt;Animator&lt;/code&gt;コンポーネントをアタッチすれば、普通に&lt;code&gt;Animation Track&lt;/code&gt;でクリップを再生できました。&lt;/p&gt;

&lt;p&gt;2つの&lt;code&gt;Animation Track&lt;/code&gt;のクリップを重ねるように配置すると、モーションのブレンドができるので、
待機モーションから走るモーションへのブレンドはこれを利用しました。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Animation Track&lt;/code&gt;の中に作成できる&lt;code&gt;Override Track&lt;/code&gt;でキャラクターの移動を実現しました。
&lt;code&gt;Override Track&lt;/code&gt;ではパラメータのアニメーションのカーブを直接編集できます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline-animation.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/timeline-animation.png&#34; alt=&#34;Animation Trackによるロボットの制御&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;テキスト&#34;&gt;テキスト&lt;/h3&gt;

&lt;p&gt;後半のタイトル文字には&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/84126&#34;&gt;TextMesh Pro&lt;/a&gt;を使用しました。
Timelineとの連携は、Activation Trackを使って実現しています。
1文字ずつ表示する部分は、TextMesh ProのサンプルのTextConsoleSimulatorクラスを使って制御しています。
しかし、このクラスはTimelineは考慮されておらず、通常再生時と録画時とで表示速度がずれる問題が残りました。
将来的には独自の&lt;code&gt;Playables&lt;/code&gt;を実装して、これらの問題を解決したいです。&lt;/p&gt;

&lt;h3 id=&#34;パーティクル&#34;&gt;パーティクル&lt;/h3&gt;

&lt;p&gt;ロボットの足元の火花には、&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/73777&#34;&gt;Unity Particle Pack&lt;/a&gt;
に含まれている「ElectricalSparksEffect」を使用しました。
Timelineとの連携は、Activation Trackを使って実現しています。&lt;/p&gt;

&lt;h2 id=&#34;その他&#34;&gt;その他&lt;/h2&gt;

&lt;h3 id=&#34;ポストエフェクト&#34;&gt;ポストエフェクト&lt;/h3&gt;

&lt;p&gt;ポストエフェクトには、&lt;a href=&#34;https://github.com/Unity-Technologies/PostProcessing&#34;&gt;Post-processing Stack v2&lt;/a&gt;を利用しました。&lt;/p&gt;

&lt;p&gt;以下のポストエフェクトを利用しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fog

&lt;ul&gt;
&lt;li&gt;レイマーチングでは遠景にエイリアシングが発生して汚くなる弱点があるので、Fogで遠景を暗くしました&lt;/li&gt;
&lt;li&gt;現実でも距離の二乗に比例して光が減衰するので、Fogで現実感が増します&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Bloom

&lt;ul&gt;
&lt;li&gt;Bloomは明るい光源からの光が周囲に漏れるように見える効果です&lt;/li&gt;
&lt;li&gt;今回はemissionを多用したシーンなので、Bloomが効果的に機能しました&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ambient Occlusion

&lt;ul&gt;
&lt;li&gt;AOで大域照明感を出しました&lt;/li&gt;
&lt;li&gt;暗いシーンなので、違いは分かりにくいかもしれませんね&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ポストエフェクトの有無で比較画像を用意しました。
左がポストエフェクトOFF、右がポストエフェクトONです。
違いが一目瞭然ですね！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/postprocessing.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-12-21-unity-demoscene/postprocessing.jpg&#34; alt=&#34;ポストエフェクトの有無で比較&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;3d素材&#34;&gt;3D素材&lt;/h3&gt;

&lt;p&gt;ロボットの3Dモデルは&lt;a href=&#34;https://www.assetstore.unity3d.com/jp/#!/content/4696&#34;&gt;Space Robot Kyle&lt;/a&gt;を使わせていただきました。&lt;/p&gt;

&lt;p&gt;モーションは&lt;a href=&#34;http://unity-chan.com/download/releaseNote.php?id=UnityChan&#34;&gt;ユニティちゃん 3Dモデルデータ&lt;/a&gt;を利用しました。&lt;/p&gt;

&lt;h3 id=&#34;動画撮影&#34;&gt;動画撮影&lt;/h3&gt;

&lt;p&gt;冒頭のYouTubeの動画は、&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder&#34;&gt;Unity Recorder&lt;/a&gt;を使って撮影しました。
このアセットは、Unityの画面を録画し、動画として保存してくれます。
固定フレームレートに対応しているので、非力なPCでも撮影が可能です。&lt;/p&gt;

&lt;p&gt;Unity Recorderには、Timelineとの連携機能もありました。
Recorder trackをタイムラインに追加すると、エディター再生時に自動で録画ができます。&lt;/p&gt;

&lt;p&gt;注意点として、&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder/issues/11&#34;&gt;v0.1ではUIが録画できないという不具合&lt;/a&gt;がありました。
&lt;a href=&#34;https://github.com/Unity-Technologies/GenericFrameRecorder/releases&#34;&gt;GitHubのReleases&lt;/a&gt;から、v0.2（現時点の最新版）をダウンロードすることで解決できました。&lt;/p&gt;

&lt;h1 id=&#34;感想&#34;&gt;感想&lt;/h1&gt;

&lt;p&gt;Unityを上手に利用すれば効率的にデモ作成できると感じました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;便利なAssetがたくさん提供されている&lt;/li&gt;
&lt;li&gt;リアルタイムに見た目を確認しながら、シェーダのパラメータを調整できる

&lt;ul&gt;
&lt;li&gt;シェーダ（ShaderLab）に数行コードを足すだけで、インスペクタにパラメータを露出できる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;リアルタイムに見た目を確認しながら、シェーダやスクリプトを編集できる

&lt;ul&gt;
&lt;li&gt;Unityに標準搭載されているホットリロード機能によって、シーンの再生中でもシェーダやスクリプトの変更が反映できる&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!--
まだUnityを使いこなせていない感があるので、もっとUnityの経験値を貯めたいです。
--&gt;

&lt;h1 id=&#34;ソースコード&#34;&gt;ソースコード&lt;/h1&gt;

&lt;p&gt;UnityのプロジェクトをGitHubで公開しています。スターが欲しいです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gam0022/unity-demoscene&#34;&gt;Unity Demoscene | GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回のデモ用のファイルは&lt;a href=&#34;https://github.com/gam0022/unity-demoscene/tree/master/Assets/Demoscene/TheGlow&#34;&gt;&lt;code&gt;Assets/Demoscene/TheGlow&lt;/code&gt;&lt;/a&gt;のディレクトリにあります。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>正解するカドの「カド」をレイマーチングでリアルタイム描画する</title>
      <link>https://gam0022.net/blog/2017/06/30/raymarching-kado/</link>
      <pubDate>Fri, 30 Jun 2017 04:33:31 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2017/06/30/raymarching-kado/</guid>
      <description>&lt;p&gt;今夜はアニメ&lt;a href=&#34;http://seikaisuru-kado.com/&#34;&gt;「正解するカド」&lt;/a&gt;の最終回ですね。&lt;/p&gt;

&lt;p&gt;フラクタル図形（カド）や折り紙（ワム）が重要な要素になっていて、個人的にとても刺さるアニメでした。&lt;/p&gt;

&lt;p&gt;最終回は楽しみですが、今日で終わってしまうと思うと寂しくも感じます。&lt;/p&gt;

&lt;p&gt;さて、&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング（スフィアトレーシング）&lt;/a&gt;は「カド」のようなフラクタル図形の描画がとても得意です。&lt;/p&gt;

&lt;p&gt;そこで、WebGLによるレイマーチングでカドのレンダリングに挑戦しました！！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/kado.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/kado.png&#34; alt=&#34;カド&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;レイマーチングでカド(MandelBox)を描画した結果です。&lt;/p&gt;

&lt;p&gt;次のリンクからブラウザ上から動かすこともできます。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.net/webgl/#raymarching_kado&#34;&gt;http://gam0022.net/webgl/#raymarching_kado&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PauseをOFFにすると、カドがアニメーションします（負荷注意）。&lt;/p&gt;

&lt;p&gt;描画の負荷が重たすぎる場合には、Pixel Ratioを1/2xか1/4xにしてください。&lt;/p&gt;

&lt;!--

Pixel Ratioを2xにすると、綺麗な結果になりますが、描画の負荷が4倍になります。

2xにする場合は、PauseをONにするのがオススメです。カメラを動かさない限り再描画が行われなくなり、描画の負荷が下がります。

--&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;解説&#34;&gt;解説&lt;/h1&gt;

&lt;p&gt;制作における工夫点や参考資料を紹介していきます。&lt;/p&gt;

&lt;h2 id=&#34;カドのレンダリング&#34;&gt;カドのレンダリング&lt;/h2&gt;

&lt;p&gt;アニメの「カド」はMandelBoxと呼ばれるフラクタル図形をベースに改造したもののようです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cgworld.jp/feature/201602-kado01-cgw211.html&#34;&gt;謎に満ちたアニメCGプロジェクト『正解するカド』（総監督：村田和也）に迫る 〜 mystery 01：3Dフラクタル 〜&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;今回はベーシックなMandelBoxをレイマーチングで普通に描画しました。&lt;/p&gt;

&lt;p&gt;MandelBoxの距離関数は以下のサイトを参考に実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.hvidtfeldts.net/index.php/2011/11/distance-estimated-3d-fractals-vi-the-mandelbox/&#34;&gt;Distance Estimated 3D Fractals (VI): The Mandelbox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;カドのシェーディングは&lt;a href=&#34;http://gam0022.net/blog/2017/02/24/tdf2017/&#34;&gt;TokyoDemoFest2017の作品&lt;/a&gt;の実装をほぼそのまま流用しました。&lt;/p&gt;

&lt;p&gt;独特なカラフルな色は色相をレイマーチングのステップ数などによって変化させることで実現しています。&lt;/p&gt;

&lt;p&gt;IBL(Image Based Lighting)やAO(Ambient Occlusion)でシェーディングの品質を高めました。IBLのためのキューブマップ画像は以下のサイトのものを利用しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.custommapmakers.org/skyboxes.php&#34;&gt;Skyboxes for download&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;水面のレンダリング&#34;&gt;水面のレンダリング&lt;/h2&gt;

&lt;p&gt;カドのレンダリングは特に特殊なことはしていませんが、水面には色々な工夫をこらしました。&lt;/p&gt;

&lt;h3 id=&#34;cpuによるパーリンノイズの生成&#34;&gt;CPUによるパーリンノイズの生成&lt;/h3&gt;

&lt;p&gt;フラクタルノイズの1種であるパーリンノイズをハイトマップとして、水面を表現しました。&lt;/p&gt;

&lt;p&gt;ハイトマップとの衝突判定もレイマーチングにより行いました。
ハイトマップの距離関数は非常にシンプルに実装できます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float sdGround(in vec3 p) {
	return p.y - texture2D(groundHeight, p.xz * 0.1).r + GROUND_BASE;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;パーリンノイズの生成は起動時にCPU側で行っています。&lt;/p&gt;

&lt;p&gt;次のサイトを参考にして、JavaScriptでパーリンノイズの計算を実装しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://postd.cc/understanding-perlin-noise/&#34;&gt;パーリンノイズを理解する&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この記事を読んで、今まで「パーリンノイズ」だと思い込んでいたものが、「バリューノイズ」だと知りました。&lt;/p&gt;

&lt;p&gt;勾配を使った本物のパーリンノイズの実装は今回が初めてだったので、勉強になりました。&lt;/p&gt;

&lt;h3 id=&#34;水面のアニメーション&#34;&gt;水面のアニメーション&lt;/h3&gt;

&lt;p&gt;3Dのパーリンノイズを実装したので、時間方向にパーリンノイズを動かすことで、水面のアニメーションもできます。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Animate Water&lt;/code&gt;というチェックボックスをONにすると、水面のアニメーションができます。&lt;/p&gt;

&lt;p&gt;毎フレーム毎にCPU計算で256x256のパーリンノイズを生成するため、かなり激重です。ハイエンドPCでもまともに動きませんｗ&lt;/p&gt;

&lt;p&gt;起動時にまとめて生成すれば良いような気がしますが、起動時間が長くなるのが嫌なので、このような仕様となっています。&lt;/p&gt;

&lt;h3 id=&#34;衝突判定の軽量化&#34;&gt;衝突判定の軽量化&lt;/h3&gt;

&lt;p&gt;単純に水面のハイトマップをテクスチャとして参照する実装にしたところ、テクスチャのフェッチ回数が危険領域に突入しました。&lt;/p&gt;

&lt;p&gt;そこで、カメラの近くの水面だけハイトマップからレイマーチングを行うようにして、
カメラから離れた水面は凹凸のない平面として扱い、判定式から解析的に衝突判定を行うことで、軽量化を図りました。&lt;/p&gt;

&lt;p&gt;遠くの水面は形状的には平面ですが、シェーディングの法線計算ではハイトマップを参照するようにして、見た目の品質を向上しました。
ノーマルマップと全く同じ原理です。&lt;/p&gt;

&lt;p&gt;ちなみに、今回のシーンように水面がXZ平面になっていれば、レイとの衝突判定は非常に低コストに行うことができます。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;GROUND_BASE&lt;/code&gt; を水面の高さとして、次の &lt;code&gt;t&lt;/code&gt; を計算し、&lt;code&gt;t &amp;gt; 0.0&lt;/code&gt; であればレイと平面が交差しています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float t = -(ray.origin.y - GROUND_BASE) / ray.direction.y;
if (t &amp;gt; 0.0) {
  // Hit!!
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;なんと、floatの引き算と割り算一回ずつだけで、平面とレイの衝突判定ができます！&lt;/p&gt;

&lt;h3 id=&#34;fresnel反射&#34;&gt;Fresnel反射&lt;/h3&gt;

&lt;p&gt;雑にFresnel反射も入れました。&lt;/p&gt;

&lt;p&gt;俯瞰視点にすると、遠くの方の水面は鏡面のようになっていることが分かると思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/fresnel.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/fresnel.png&#34; alt=&#34;Fresnel反射&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;水面がXZ平面になっていれば、衝突判定と同様にFresnel反射率の近似値もかなり低コストに計算できます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;float f0 = 0.7;// 垂直に入射した時の反射率。かなり大きめな値に設定。
intersection.reflectance = f0 + (1.0 - f0) * pow(1.0 + ray.direction.y, 5.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;試作&#34;&gt;試作&lt;/h1&gt;

&lt;p&gt;最終的には海の上にカドが浮かんでいるシーンとしましたが、ビルのシーンも試作しました。せっかくなので画像を残しておきます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/proto.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/proto.png&#34; alt=&#34;ビルの試作段階&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;余談&#34;&gt;余談&lt;/h1&gt;

&lt;p&gt;最後に余談なのですが、作品の重要な要素であるカドとワムのどちらとも知り合いが関わっていて、あまりの世間の狭さに驚きました。&lt;/p&gt;

&lt;p&gt;カドのレンダリングはレイトレ合宿などで繋がりのある&lt;a href=&#34;https://twitter.com/_Pheema_/&#34;&gt;Pheemaさん&lt;/a&gt;のUnityのレイマーチングによるものでした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;先程TOKYOMXで放送された『正解するカド』で、「カド」などの3Dフラクタル描画に関わりましたー。Unityでゴリゴリとレイマーチングしております！よろしくお願いいたしますー！ / &lt;a href=&#34;https://t.co/8J8e3Yrff8&#34;&gt;https://t.co/8J8e3Yrff8&lt;/a&gt;&lt;/p&gt;&amp;mdash; Pheema (@&lt;em&gt;Pheema&lt;/em&gt;) &lt;a href=&#34;https://twitter.com/_Pheema_/status/850347680039489536&#34;&gt;2017年4月7日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;さらに、ワムは大学時代の指導教官の三谷純先生の幾何学折り紙そのものでした。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;東映のフル3Dアニメ 「正解するカド」&lt;a href=&#34;https://t.co/M6ae6WIZa3&#34;&gt;https://t.co/M6ae6WIZa3&lt;/a&gt;&lt;br&gt;の第5話に立体折り紙（球体）の制作シーンが登場。&lt;br&gt;スタッフロールに資料協力として名前を掲載いただきました。&lt;br&gt;&lt;br&gt;こちらの作品のイメージに近い感じでした。&lt;a href=&#34;https://twitter.com/hashtag/%E6%AD%A3%E8%A7%A3%E3%81%99%E3%82%8B%E3%82%AB%E3%83%89?src=hash&#34;&gt;#正解するカド&lt;/a&gt; &lt;a href=&#34;https://t.co/2yjpB1643t&#34;&gt;pic.twitter.com/2yjpB1643t&lt;/a&gt;&lt;/p&gt;&amp;mdash; 三谷 純 Jun MITANI (@jmitani) &lt;a href=&#34;https://twitter.com/jmitani/status/860644756417765376&#34;&gt;2017年5月5日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;こんなことってあるんですね…！&lt;/p&gt;

&lt;h1 id=&#34;アニメ版のカドの再現-2017-07-03追記&#34;&gt;アニメ版のカドの再現（2017/07/03追記）&lt;/h1&gt;

&lt;p&gt;notargsさんがアニメ版のカドの再現のヒントをくださったので、自分もチャンジしました。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;- カドの内部に入った光は全て吸収する（レイが通り抜けた場合は出力を黒にする）&lt;br&gt;- ２つのMandelboxを重ねる&lt;br&gt;- zに掛けるScaleの値をマイナスにする&lt;br&gt;あたりがカドっぽくするコツだった&lt;/p&gt;&amp;mdash; !args(のたぐす) (@notargs) &lt;a href=&#34;https://twitter.com/notargs/status/881448613993267201&#34;&gt;2017年7月2日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;こちらは&lt;a href=&#34;https://cgworld.jp/feature/201602-kado01-cgw211.html&#34;&gt;CGWORLDの記事&lt;/a&gt;の画像の転載です。これをリファレンスとします。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/reference.jpg&#34; alt=&#34;CGWORLDの記事のリファレンス画像&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Scaleをマイナスにして、大小の違う2つのMandelBoxを重ねてみました。
内部に入った光を吸収させる替わりにAOを強めにしました。
すると、本当にアニメ版のカドにかなり近い結果になりました！！これは面白いですね！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/anime.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/anime.png&#34; alt=&#34;アニメ版のカドの再現&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/anime2.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-06-30-raymarching-kado/anime2.png&#34; alt=&#34;アニメ版のカドの再現2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;こちらからアニメ版に近いカドを動かすことができます。MandelBoxを2つ重ねたことで、負荷が約2倍になりました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.net/webgl/#raymarching_kado_anime&#34;&gt;http://gam0022.net/webgl/#raymarching_kado_anime&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;カドを再現する人たち-2017-07-03追記&#34;&gt;カドを再現する人たち（2017/07/03追記）&lt;/h1&gt;

&lt;p&gt;カドのレンダリングに挑戦している方が自分以外にも現れたので、観測範囲内でまとめました。&lt;/p&gt;

&lt;p&gt;notargsさん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;カドをほぼ再現できました！ &lt;a href=&#34;https://t.co/nXFYvFRN9w&#34;&gt;pic.twitter.com/nXFYvFRN9w&lt;/a&gt;&lt;/p&gt;&amp;mdash; !args(のたぐす) (@notargs) &lt;a href=&#34;https://twitter.com/notargs/status/881444119666491392&#34;&gt;2017年7月2日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;cx20さん&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;[WebGL] Grimoire.js で &lt;a href=&#34;https://twitter.com/hashtag/%E6%AD%A3%E8%A7%A3%E3%81%99%E3%82%8B%E3%82%AB%E3%83%89?src=hash&#34;&gt;#正解するカド&lt;/a&gt; っぽいものを表現してみるテスト &lt;a href=&#34;https://twitter.com/hashtag/jsdoit?src=hash&#34;&gt;#jsdoit&lt;/a&gt; &lt;a href=&#34;https://t.co/OORNMSemzo&#34;&gt;https://t.co/OORNMSemzo&lt;/a&gt;&lt;/p&gt;&amp;mdash; cx20 (@cx20) &lt;a href=&#34;https://twitter.com/cx20/status/881121051186417664&#34;&gt;2017年7月1日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;自分&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/%E6%AD%A3%E8%A7%A3%E3%81%99%E3%82%8B%E3%82%AB%E3%83%89?src=hash&#34;&gt;#正解するカド&lt;/a&gt; の「カド」を &lt;a href=&#34;https://twitter.com/hashtag/WebGL?src=hash&#34;&gt;#WebGL&lt;/a&gt; のレイマーチングでリアルタイムに描画しました！いい感じに仕上がったので、徹夜した甲斐がありました！今晩の最終話が楽しみです！ &lt;a href=&#34;https://twitter.com/hashtag/threejs?src=hash&#34;&gt;#threejs&lt;/a&gt;&lt;a href=&#34;https://t.co/pMRREywdyy&#34;&gt;https://t.co/pMRREywdyy&lt;/a&gt;&lt;/p&gt;&amp;mdash; がむ (@gam0022) &lt;a href=&#34;https://twitter.com/gam0022/status/880562345990275072&#34;&gt;2017年6月29日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>距離関数のfold（折りたたみ）による形状設計</title>
      <link>https://gam0022.net/blog/2017/03/02/raymarching-fold/</link>
      <pubDate>Thu, 02 Mar 2017 23:24:26 +0900</pubDate>
      
      <guid>https://gam0022.net/blog/2017/03/02/raymarching-fold/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.slideshare.net/shohosoda9/threejs-58238484&#34;&gt;レイマーチング（別名 Sphere Tracing）&lt;/a&gt;とは、距離関数と呼ばれる数式で定義したシーンに対して、レイの衝突判定を行って絵を出す手法です。&lt;/p&gt;

&lt;p&gt;この距離関数に対し、fold（折りたたみ）の操作を行うと、万華鏡のような美しい形状や、フラクタルのような複雑な形状の設計が可能です。&lt;/p&gt;

&lt;p&gt;先日のTokyoDemoFest2017でも、このfoldを用いた作品を投稿しました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gam0022.net/blog/2017/02/24/tdf2017/&#34;&gt;#TokyoDemoFest 2017 の GLSL Graphics Compo で3位入賞！ | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gam0022.net/webgl/#raymarching_tdf2017&#34;&gt;Fusioned Bismuth | gam0022.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.shadertoy.com/view/Msscz7&#34;&gt;Fusioned Bismuth | Shadertoy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;この記事では、距離関数のfoldについて、解説していきます。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;2dのfold&#34;&gt;2Dのfold&lt;/h1&gt;

&lt;p&gt;分かりやすさのために、まずは2Dの例から説明します。&lt;/p&gt;

&lt;p&gt;2Dのfoldの分かりやすい例は「鏡文字」です。&lt;/p&gt;

&lt;p&gt;アルファベットのGをY軸中心に折りたたんだ鏡文字の2Dシェーダのサンプルを作りました。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://glslsandbox.com/e#38938.1&#34;&gt;Gの鏡文字のシェーダ | GLSL sandbox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/mirror2.png&#34; alt=&#34;Gの鏡文字&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このようなY軸中心のfold(Y軸中心 == X方向へのfold)は、単純にxを絶対値することにより実現できます。&lt;/p&gt;

&lt;p&gt;絶対値をとることで、Xの負の方向の領域が正の方向の領域と一致して鏡文字になります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec2 foldX(vec2 p) {
    p.x = abs(p.x);
    return p;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;foldXの使用方法です。距離関数の引数pにfoldXを適用すればOKです。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;p = foldX(p);// Y軸方向を中心に空間(p)を折りたたむ
p -= vec2(0.4, 0.0);// 右方向に平行移動
float color = sign(dCharG(p));// 距離関数の符号で色分け
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3dのfold&#34;&gt;3Dのfold&lt;/h1&gt;

&lt;p&gt;次は3Dのfoldです。&lt;/p&gt;

&lt;p&gt;このように箱をZ軸に時計回りに回転させたものをYZ平面にfoldすると、距離関数としては1つの箱なのに、左右2つに枝分かれさせることができます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/fold-1.png&#34; alt=&#34;YZ平面にfoldしたBox&#34; /&gt;&lt;/p&gt;

&lt;p&gt;前の例では2DだったのでY軸に対するfoldでしたが、今回は3DなのでYZ平面に対するfoldになっています。
foldの中心が軸から面になりましたが、処理的には2Dと変わりません。
foldXの中身も一緒で、引数と返り値の型がvec2からvec3になったことが変更点です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vec3 foldX(vec3 p) {
    p.x = abs(p.x);
    return p;
}

mat2 rotate(float a) {
    float s = sin(a),c = cos(a);
    return mat2(c, s, -s, c);
}

float dTree(vec3 p) {
    vec3 size = vec3(0.1, 1.0, 0.1);
    float d = sdBox(p, size);
    p = foldX(p);
    p.y -= 0.1;
    p.xy *= rotate(-1.2);
    d = min(d, sdBox(p, size));
    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;再帰的なfold&#34;&gt;再帰的なfold&lt;/h1&gt;

&lt;p&gt;このfoldを再帰的に適用すると、フラクタル図形ができます。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/fold-2.png&#34; alt=&#34;再帰的なfold&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これがGLSLの距離関数です。&lt;/p&gt;

&lt;p&gt;ループの末尾でpを更新することで、再帰的にfoldを適用しています。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;float dTree(vec3 p) {
    float scale = 0.8;
    vec3 size = vec3(0.1, 1.0, 0.1);
    float d = sdBox(p, size);
    for (int i = 0; i &amp;lt; 7; i++) {
        vec3 q = foldX(p);
        q.y -= size.y;
        q.xy *= rotate(-0.5);
        d = min(d, sdBox(p, size));
        p = q;
        size *= scale;
    }
    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常、フラクタル図形を表現するためには再帰関数が必要ですが、距離関数を用いればループで十分表現できるというのが興味深いポイントですね。
たとえば、&lt;code&gt;dTree&lt;/code&gt; の中には、sdBoxがたったの2回しか登場していません。再帰的に &lt;code&gt;foldX&lt;/code&gt; を適用することで、Boxを無数に複製しています。&lt;/p&gt;

&lt;h1 id=&#34;回転のfold&#34;&gt;回転のfold&lt;/h1&gt;

&lt;p&gt;これまでは面に対するfoldを扱いましたが、特定の軸を中心に回転させたfoldも考えられます。&lt;/p&gt;

&lt;p&gt;回転のfoldは&lt;a href=&#34;https://twitter.com/gaziya5&#34;&gt;@gaziya5&lt;/a&gt;さんの&lt;a href=&#34;https://www.shadertoy.com/view/Mlf3Wj&#34;&gt;DE used folding&lt;/a&gt;からお借りしました。&lt;/p&gt;

&lt;p&gt;dTreeの木のような形をうまく調整し、Z軸方向に6回転させるfoldを適用すると「Fusioned Bismuth」に登場した雪の結晶のような形状を得られます。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/snow.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/snow.png&#34; alt=&#34;Fusioned Bismuth - 雪の結晶&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;mat2 rotate(in float a) {
    float s = sin(a), c = cos(a);
    return mat2(c, s, -s, c);
}

// https://www.shadertoy.com/view/Mlf3Wj
vec2 foldRotate(in vec2 p, in float s) {
    float a = PI / s - atan(p.x, p.y);
    float n = PI2 / s;
    a = floor(a / n) * n;
    p *= rotate(a);
    return p;
}

float dTree(vec3 p) {
    float scale = 0.6 * saturate(1.5 * sin(0.05 * time));
    float width = mix(0.3 * scale, 0.0, saturate(p.y));
    vec3 size = vec3(width, 1.0, width);
    float d = sdBox(p, size);
    for (int i = 0; i &amp;lt; 10; i++) {
        vec3 q = p;
        q.x = abs(q.x);
        q.y -= 0.5 * size.y;
        q.xy *= rotate(-1.2);
        d = min(d, sdBox(p, size));
        p = q;
        size *= scale;
    }
    return d;
}

float dSnowCrystal(inout vec3 p) {
    p.xy = foldRotate(p.xy, 6.0);
    return dTree(p);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;回転のfoldの別例&#34;&gt;回転のfoldの別例&lt;/h2&gt;

&lt;p&gt;この &lt;code&gt;foldRotate&lt;/code&gt; はUFO風の形状にも利用しています。
たった4つのBoxに&lt;code&gt;mod&lt;/code&gt; や &lt;code&gt;foldRotate&lt;/code&gt; を適用しただけなのに、それなりに雰囲気を出すことができたと思っています。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/ufo.png&#34;&gt;&lt;img src=&#34;https://gam0022.net/images/posts/2017-02-24-tdf2017/ufo.png&#34; alt=&#34;Fusioned Bismuth - UFO風の形状&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#define opRep(p, interval) (mod(p, interval) - 0.5 * interval)
#define opRepLimit(p, interval, limit) (mod(clamp(p, -limit, limit), interval) - 0.5 * interval)

float dWing(in vec3 p) {
    float t = time;
    float l = length(p.xz);
    float fusion = gauss(time * 2.0);

    float a = 0.1 + 0.06 * (1.0 + sin(PI * t + l));
    float b = min(0.2 * t, 10.0) * gauss(l) + 0.1 * fusion * hWave(p.xz, t);
    p.y += -b + 15.0;

    vec3 p1 = p;
    p1.xz = opRepLimit(p.xz, 1.0, 20.0);

    vec3 p2 = p;
    p2 = opRep(p, 0.5);

    float d =   sdBox(p1, vec3(0.2 + a * 3.0, 12.0 - a,       0.2 + a));
    d = min(d,  sdBox(p1, vec3(0.4 - a,       13.0 - 4.0 * a, 0.1 + a)));
    d = max(d, -sdBox(p1, vec3(0.3 - a,       14.0 - 4.0 * a, a)));
    d = max(d, -sdBox(p2, vec3(0.8 * a, 1.0 - a, 0.8 * a)));
    return d;
}

float dUfo(inout vec3 p) {
    float t = max(time * 0.5, 1.0);
    float t1 = floor(t);
    float t2 = t1 + easeInOutCubic(t - t1);

    p.xz = foldRotate(p.xz, min(t2, 10.0));
    p.z -= 0.5;

    float d = dWing(p);
    return d;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;一般化されたfold&#34;&gt;一般化されたfold&lt;/h1&gt;

&lt;p&gt;任意の法線 &lt;code&gt;n&lt;/code&gt; を持った面に対する一般化されたfoldがSyntopiaに紹介されています。興味のある方は、見てみると良いでしょう。&lt;/p&gt;

&lt;p&gt;absによるfoldでは、座標軸に垂直な特殊な平面に限定されていましたが、これで自由な向きにfoldができます！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.hvidtfeldts.net/index.php/2011/08/distance-estimated-3d-fractals-iii-folding-space/&#34;&gt;Distance Estimated 3D Fractals (III): Folding Space&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;p -= 2.0 * min(0.0, dot(p, n)) * n;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;距離関数のfoldについて、実例を踏まえて紹介しました。&lt;/p&gt;

&lt;p&gt;foldは直感的に理解することが難しく、使いこなすのも大変ですが、かなり強力なテクニックだと思います！&lt;/p&gt;

&lt;p&gt;もしこの記事がお役に立てたのなら幸いです。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
