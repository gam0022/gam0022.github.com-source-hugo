+++
date = "2018-12-04T09:49:52+09:00"
draft = false
image = ""
math = false
slug = "tdf2018"
tags = []
title = "TokyoDemoFest 2018のDemo Compo優勝作品の解説"
toc = true

+++

12月1日～12月2日に秋葉原で開催された[Tokyo Demo Fest 2018](http://tokyodemofest.jp/2018/)（以下、TDF）に参加しました。

TDFはデモ（プログラミングによる楽曲制作や映像製作）に興味のある人たちが一堂に会する、日本国内では唯一のデモパーティです。
2日間にわたり様々なコンペティションやセミナーが開催されます。

今年のTDFでは、さだきちさん（[@sadakkey](https://twitter.com/sadakkey)）とチームを組み、『WORMHOLE』（映像：gam0022 / サウンド：sadakkey）という作品を発表しました。

本作品がCombined PC Demo Compo（Windows実行ファイル形式のデモ作品のコンペティション）にて最優秀作品に選ばれました！！！
多くの方に選んでいただき、大変光栄です。ありがとうございました。

<iframe width="720" height="405" src="https://www.youtube.com/embed/k5MotEfghjQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 

下記の実行ファイルを起動していただければ、より高画質でご覧いただけます。

- [Windowsの実行ファイル（GTX1070以上のGPU推奨）](https://files.scene.org/view/parties/2018/tokyodemofest18/demo/wormhole.zip)
- [pouet.net（世界中のデモの情報を集めたポータルサイト）](https://www.pouet.net/prod.php?which=79380)
- [動画ファイル（ダウンロードすればエンコード前の綺麗な状態で視聴可能）](https://drive.google.com/file/d/1GxyxjOyGBRcofMVKILmJtlmYaMZ5XoGx/view)

映像はUnityで制作しましたが、アセットはほとんど使わずにシェーダーによるプロシージャルに映像を生成しました。
レイトレーシング（レイマーチング）とラスタライザをハイブリッドに組み合わせたレンダリング方式を採用しました。

この記事ではWORMHOLEの映像について解説してききます。

# 作品の概要
テーマは「ワームホールによる空間移動」です。

不思議な球体がトンネルを超えて、ワームホールによって海に出ます。

そして再び最初のトンネルに戻ります（ループ）。

# Unityとの連携

映像はUnityで実装と制作をしました。

Unity 2018.2の目玉機能も複数利用したので、Unityの良い応用事例だと思います。

- Timeline
    - タイムライン（時系列によるコンテンツの再生に利用）
    - 一部はTimelineのカスタムトラックを実装
- TextMeshPro
    - フォントのレンダリングに利用
- Chinemachine
    - カメラワークに利用
- PostProcessingStack v2
    - DoFやBloomのポストエフェクトに利用

# レンダリング

大部分はレイマーチングで描画し、パーティクルやグリーティングのテキストなどのレイマーチングが苦手とする部分はラスタライザで描画するというハイブリッドなレンダリング方式を採用しました。

レイマーチング（別名 Sphere Tracing）とは、距離関数と呼ばれる数式で定義したシーンに対して、レイの衝突判定を行って絵を出すレイトレーシングに分類される手法です。詳細は次の資料にまとめてあります。

- [シェーダだけで世界を創る！three.jsによるレイマーチング](https://www.slideshare.net/shohosoda9/threejs-58238484)

また、レイマーチングのシェーディングはディファードレンダリングを採用しました。

UnityのサポートするすべてのライトやGI機能に対応するシェーダーを実装するのは膨大な工数が必要になってしまうので、
Gバッファだけ書き込んでライティングはUnityの標準のディファードレンダリングのシェーダーに任せるのが賢いと判断しました。

Unityでディファードレンダリングによるレイマーチングを実現するために、
[@hecomi](https://twitter.com/hecomi)さんの[uRaymarching](https://github.com/hecomi/uRaymarching)を利用させていただきました。
距離関数とGバッファに値を書き込む部分を実装すれば、すぐにレイマーチングができる便利なシェーダーテンプレートです。
今回はワームホールやFog表現のためにuRaymarchingを少しだけ改造して利用しました。

またuRaymarchingではCommandBufferでフルスクリーンQuadを表示させていましたが、
スクリプトによる制御は最小限にしてEditorモードの挙動を安定させたかったので、別のアプローチとってみました。

EditorツールでBoudingBoxを巨大にしてFrustum Cullingを無効にしたQuadを静的生成しました。

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">Unityで画面全体にレイマーチングをさせる最高のソリューションができた！<br><br>CommandBufferを使う方法だとEditMode等の考慮が大変。<br>通常のQuadだとFrustum Cullingされて困る。<br><br>そこで、BoudingBoxを拡張したQuadを事前生成して通常のMeshRendererで描画できるようにした。<a href="https://t.co/Askoyvnq0X">https://t.co/Askoyvnq0X</a></p>&mdash; がむ (@gam0022) <a href="https://twitter.com/gam0022/status/1018214911367761920?ref_src=twsrc%5Etfw">2018年7月14日</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

- [RaymarchingQuadMeshCreator by gam0022 · Pull Request #10 · gam0022/unity-demoscene](https://github.com/gam0022/unity-demoscene/pull/10)

# モデリング

テキストとパーティクル以外は距離関数でモデリングしました。簡単に設計方法について紹介します。

## トンネル

Menger spongeという有名なフラクタル図形をすこしアレンジしました。

去年も利用した回転のfoldのテクニックを利用して万華鏡にように見せたり、modをつかった図形の繰り返しのテクニックを適用しました。
回転のfoldは次の記事で紹介しています。

- [距離関数のfold（折りたたみ）による形状設計 | gam0022.net](https://gam0022.net/blog/2017/03/02/raymarching-fold/)

## 海

軽量化のために平面として衝突判定を行い、ノーマルマップだけで海っぽく見せています。
この軽量化の方法は去年にWebGLによって実装した「正解するカドの「カド」をレイマーチングでリアルタイム描画する」のアプローチと同じです。
去年はLOD的で近影だけはハイトマップによるレイマーチングをしましたが、今回はLODも行わずにすべて平面として衝突判定しました。

- [正解するカドの「カド」をレイマーチングでリアルタイム描画する | gam0022.net](https://gam0022.net/blog/2017/06/30/raymarching-kado/)

## 戦闘機

戦闘機は地道に距離関数でモデリングしました。

3つのBoxをcos/sinで大きさを調整して歪めつつ、smoothminでメタボールで組み合わせることで、流線形のSFっぽい戦闘機をモデリングしました。

# 音楽との同期

## 時間からビートに変換

音楽と時間を同期する方法について紹介します。

まず、「時間からビートに変換」して、シェーダーの演出はすべてビート単位で制御するようにしました。

これによりBPM変更にも柔軟に対応できますし、あまり意識せずとも演出がビートと自動的に同期されます。

ちなみに時間からビートに変換する処理は非常に簡単で `beat = time * bpm / 60` で計算できます。

具体的には `TimelineTimeControl` という `ITimeControl` インターフェースを実装したクラスを用意しました。
このクラスで `Shader.SetGlobalFloat` 経由でビートを渡すことで、ビートをすべてのシェーダーから参照できるグローバルなuniformにしました。

https://github.com/gam0022/unity-demoscene/blob/master/Assets/Demoscene/Scripts/Timeline/TimelineTimeControl.cs#L14

## カットの切り替えやパーティクルのエミット

シェーダーで制御する部分は上記の時間からビートに変換する作戦でうまくいくのですが、
カメラのカットやパーティクルのエミットのタイミングはTimelineのクリップを手動で音楽に合わせて配置する必要がありました。

これらの問題に対しては、音楽を120BPMをにすることで、かなり楽に解決できました。

120BPMにすることで、1ビートが0.5秒となり、4分の4拍子の曲なら1小節が2秒となるため、
カメラのカット切り替えは必ず2の倍数の秒数のタイミングにするルールを守れば、自然に音楽と同期できます。

パーティクルのエミットの間隔も0.5秒ごとに設定すればビートと同期できました。

# 映像を考えるまでの流れ

# 演出の実装

## TextMeshProを利用したフォントの描画とカスタムシェーダーによるエフェクトの組み合わせ

## パーティクル

## 揺らぎの重要性

## ReflectionProbe

# 感想

デモシーンの世界では容量などの制約のある中でかっこいい映像と音楽をつくるのがロマンがあると個人的には思っていて、
今回はUnityを利用したことで圧縮後の容量が20MBもあるし、ゲームエンジンの便利な機能に依存してしまったので、
もし受け入れられなかったらどうしようとも思ったのですが、
大半の参加者に受け入れられて優勝という結果を残すことができてよかったです。

# ライブコーディングバトル