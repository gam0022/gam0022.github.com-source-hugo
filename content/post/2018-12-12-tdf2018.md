+++
date = "2018-12-12T09:49:52+09:00"
draft = false
image = ""
math = false
slug = "tdf2018"
tags = ["event", "CG", "レイマーチング", "TokyoDemoFest", "Unity"]
title = "TokyoDemoFest 2018のDemo Compo優勝作品の解説"
toc = true

+++

12月1日～12月2日に秋葉原で開催された[Tokyo Demo Fest 2018](http://tokyodemofest.jp/2018/)（以下、TDF）に参加しました。

TDFはデモ（プログラミングによる楽曲制作や映像製作）に興味のある人たちが一堂に会する、日本国内では唯一のデモパーティです。
2日間にわたり様々なコンペティションやセミナーが開催されます。

今年のTDFでは、さだきちさん（[@sadakkey](https://twitter.com/sadakkey)）とチームを組み、『WORMHOLE』（映像：gam0022 / サウンド：sadakkey）という作品を発表しました。

本作品がCombined Demo Compoにて1位に選ばれました！

Combined Demo CompoはWindows実行ファイル形式のデモ作品のコンペティションで、TDFの中で最も注目度の高いメイン部門です。

デモパーティでは参加者の投票によって順位が決まります。
多くの方に選んでいただき、たいへん嬉しいです。ありがとうございました！

<iframe width="720" height="405" src="https://www.youtube.com/embed/k5MotEfghjQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 

下記の実行ファイルを起動していただければ、より高画質でご覧いただけます。

- [Windowsの実行ファイル（GTX1070以上のGPU推奨）](https://files.scene.org/view/parties/2018/tokyodemofest18/demo/wormhole.zip)
- [pouet.net（世界中のデモの情報を集めたポータルサイト）](https://www.pouet.net/prod.php?which=79380)
- [動画ファイル（ダウンロードすればエンコード前の綺麗な状態で視聴可能）](https://drive.google.com/file/d/1GxyxjOyGBRcofMVKILmJtlmYaMZ5XoGx/view)

映像はUnityで制作しましたが、アセットはほとんど使わずにシェーダーによるプロシージャルに映像を生成しました。
レイトレーシング（レイマーチング）とラスタライザをハイブリッドに組み合わせたレンダリング方式を採用しました。

この記事ではWORMHOLEの映像について解説してききます。

# 作品の概要
テーマは「ワームホールによる空間移動」です。

不思議な球体がトンネルを超えて、ワームホールによって海に出ます。

そして再び最初のトンネルに戻って冒頭にループします。

# Unityとの連携

映像はUnityで実装と制作をしました。

Unity 2018.2の目玉機能も複数利用したので、Unityの良い応用事例だと思います。

- Timeline
    - タイムライン（時系列によるコンテンツの再生に利用）
    - 一部はTimelineのカスタムトラックを実装
- TextMeshPro
    - フォントのレンダリングに利用
- Chinemachine
    - カメラワークに利用
- PostProcessingStack v2
    - DoFやBloomのポストエフェクトに利用

# レンダリング

大部分はレイマーチングで描画し、パーティクルやグリーティングのテキストなどのレイマーチングが苦手とする部分はラスタライザで描画するというハイブリッドなレンダリング方式を採用しました。

レイマーチング（別名 Sphere Tracing）とは、距離関数と呼ばれる数式で定義したシーンに対して、レイの衝突判定を行って絵を出すレイトレーシングに分類される手法です。詳細は次の資料にまとめてあります。

- [シェーダだけで世界を創る！three.jsによるレイマーチング](https://www.slideshare.net/shohosoda9/threejs-58238484)

また、レイマーチングのシェーディングはディファードレンダリングを採用しました。

Unityがサポートする全種類のライトやGI機能に対応するシェーダーを実装するのは膨大な工数が必要になってしまうので、
Gバッファだけ書き込んでライティングはUnityの標準のディファードレンダリングのシェーダーに任せるのが賢いと判断しました。

Unityでディファードレンダリングによるレイマーチングを実現するために、
[@hecomi](https://twitter.com/hecomi)さんの[uRaymarching](https://github.com/hecomi/uRaymarching)を利用させていただきました。
距離関数とGバッファに値を書き込む部分を実装すれば、すぐにレイマーチングができる便利なシェーダーテンプレートです。
今回はワームホールやFog表現のためにuRaymarchingを少しだけ改造して利用しました。

鏡面反射もUnity標準のReflectionProbeを配置して実現しました。
Unityの標準機能を利用させていただく巨人の肩の上に立つ作戦でコードを書かずに鏡面反射を実現しました。

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">uRaymarchingとReflectionProbeによる反射と組み合わせる検証<br>中<br><br>毎フレームCubemapを生成するくらいならレイトレで反射を計算したほうが速いと思っていたが、この例ならCubemapの解像度は16x16でも十分だし、Cubemapの方がポリゴンとの混在が容易なので、現実的な方法だと思う。 <a href="https://t.co/sSX7WmVCEd">pic.twitter.com/sSX7WmVCEd</a></p>&mdash; がむ (@gam0022) <a href="https://twitter.com/gam0022/status/1003274796895895554?ref_src=twsrc%5Etfw">2018年6月3日</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

今回はUnityの標準機能や便利なライブラリを活用することで工数を削減する方針で作業を進めました。
悪く言えばズルい作戦ですが、制作時間が限られている中で表現の部分に注力できたので、総合的には正解だったと思います。

## Full Screen Quad

余談に近いですが、せっかくなのでFull Screen Quadの実装方法について紹介します。

uRaymarchingではCommandBufferでフルスクリーンQuadを表示させていましたが、
スクリプトによる制御は最小限にしてEditorモードの挙動を安定させたかったので、別のアプローチとってみました。

EditorツールでBoudingBoxを巨大にしてFrustum Cullingを無効にしたQuadを静的生成しました。

これによって時々レイマーチング部分が動かないトラブルを回避できました。
また、本作品のようにFull Screen Quadが必要なレイマーチングのワールドが複数存在して、
時間によって切り替わる表現のためには、MeshRendererのenableの切り替えで制御できる単純な仕組みの方が好都合でした。

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">Unityで画面全体にレイマーチングをさせる最高のソリューションができた！<br><br>CommandBufferを使う方法だとEditMode等の考慮が大変。<br>通常のQuadだとFrustum Cullingされて困る。<br><br>そこで、BoudingBoxを拡張したQuadを事前生成して通常のMeshRendererで描画できるようにした。<a href="https://t.co/Askoyvnq0X">https://t.co/Askoyvnq0X</a></p>&mdash; がむ (@gam0022) <a href="https://twitter.com/gam0022/status/1018214911367761920?ref_src=twsrc%5Etfw">2018年7月14日</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

- [RaymarchingQuadMeshCreator by gam0022 · Pull Request #10 · gam0022/unity-demoscene](https://github.com/gam0022/unity-demoscene/pull/10)

# 距離関数によるモデリング

前半のトンネル、後半の海と戦闘機はいずれも距離関数でモデリングしました。設計方法について紹介します。

## トンネル

Menger spongeという有名なフラクタル図形をすこしアレンジしました。

去年も利用した回転のfoldのテクニックを利用して万華鏡にように見せたり、modをつかった図形の繰り返しのテクニックを適用しました。

回転のfoldは次の記事で紹介しています。

- [距離関数のfold（折りたたみ）による形状設計 | gam0022.net](https://gam0022.net/blog/2017/03/02/raymarching-fold/)

## 海

軽量化のために平面として衝突判定を行い、ノーマルマップだけで海っぽく見せています。
この軽量化の方法は去年にWebGLによって実装した「正解するカドの「カド」をレイマーチングでリアルタイム描画する」のアプローチと同じです。

- [正解するカドの「カド」をレイマーチングでリアルタイム描画する | gam0022.net](https://gam0022.net/blog/2017/06/30/raymarching-kado/)

前回は近影はハイトマップによるレイマーチング、遠影はノーマルマップというようにLOD的に仕組みを併用しましたが、
本作品はLODも行わずにすべて平面として衝突判定しました。

これはカメラワーク的に海に近づかないのでLODが必要なかったのと、
マーチングループ中でテクスチャのフェッチをするとUnityのシェーダーのコンパイルが激重になる現象を回避するための作戦でした。

後からforの前に `[loop]` というキーワードを付けることでループの展開がされずにコンパイルの速度が速くなることに気が付きましたが、
TDFの2日前だったので時すでに遅しでした…やはりUnityには知られざる秘密がまだまだ隠されていそうですねｗ！

海の質感の再現はGバッファに書き込むパラメータの調整だけで行いました。
ディファードレンダリングなの不透明としてライティングしていますが、空の反射だけで水っぽい半透明の質感を擬似的に再現できたのではないかと思います。

## 戦闘機

戦闘機は地道に距離関数でモデリングしました。

3つのBoxをcos/sinで大きさを調整して歪めつつ、smoothminでメタボールで組み合わせることで、流線形のSFっぽい戦闘機をモデリングしました。

# 音楽との同期

音楽と時間を同期する方法について紹介します。

## 時間からビートの変換

まずC#から「時間からビートに変換」し、ビートをシェーダーに渡すことで「ビート単位」で演出を制御するようにしました。

これにより意識せずとも演出がビートと自動的に同期され、BPM変更にも柔軟に対応できるようになりました。

時間からビートに変換する処理はとても簡単で `beat = time * bpm / 60` で計算できます。

具体的には `TimelineTimeControl` という `ITimeControl` インターフェースを実装したクラスを用意しました。
このクラスで `Shader.SetGlobalFloat` 経由でビートを渡すことで、ビートをすべてのシェーダーから参照できるグローバルなuniformにしました。

https://github.com/gam0022/unity-demoscene/blob/master/Assets/Demoscene/Scripts/Timeline/TimelineTimeControl.cs#L14

## カメラのカット切り替えやパーティクルの同期

シェーダーで制御する部分は上記の時間からビートに変換する作戦でうまくいくのですが、
カメラのカットやパーティクルのエミットのタイミングはTimelineのクリップを手動で音楽に合わせて配置する必要がありました。

これらの問題に対しては、音楽を120BPMをにすることで、かなり楽に解決できました。

120BPMにすることで、1ビートが0.5秒となり、4分の4拍子なら1小節の長さが2秒（4分の3拍子なら1小節の長さが1.5秒）となるため、
カメラのカット切り替えは必ず2秒単位にするルールを守れば、自然に音楽と同期できました。

パーティクルのエミットの間隔も0.5秒ごとに設定すれば音楽とタイミングが一致できました。

# 映像を考えるまでの流れ

# 演出の実装

## Animation Track vs Custom Track

UnityのTimelineのトラックは自作できます。この記事では自作トラックのことをCustom Trackと呼びます。

どういう風にCustom Trackを設計すると作業効率が良いのか様々に検証を行いましたが、
ほとんどの場合ではCustom Trackを自作する前にAnimation Trackで実現できないか検討したほうが良さそうだと感じました。
ただし、これは映像を1人で全部つくって、さらに工数も非常に限られているという条件付きなので、大規模なら別です。

本作品では、なるべくAnimation Trackに寄せて、Animation Trackで無理なテキストの文字列指定だけはCustom Trackとする方針としました。

Custom Trackの実装はそれなりに面倒で工数もかかります。
最低でも5つのクラスの作成が必要で、1つでもクリップのパラメータを増やすと複数箇所に変更が発生します。
クラスの作成は下記のウィザードである程度は解決しましたが、1つのパラメータ追加で複数箇所に変更が必要な問題は解決しませんでした。

- [【Unity】Timelineの独自Playableを超簡単に作るウィザード - テラシュールブログ](http://tsubakit1.hateblo.jp/entry/2017/10/15/195736)

## TextMeshProによる演出

フォントはプロシージャルではなくテクスチャを使用しました。

こちらのフォントデータを元にTextMeshProのEditorツールを利用してSDFのフォントのアトラステクスチャを生成して、
距離関数からシェーダーでフォントをレンダリングしました。

https://www.fontspace.com/mixofx/azonix

## パーティクル

パーティクルの形状も5種類くらいあるのですが、これはモデルを用意せずにフラグメントシェーダーで四角形のQuadをdiscardして刳り貫いて形状を変化させました。

すべてのパーティクルを1マテリアルで表現できるので、全パーティクルを1ドローコールで描画できました。

## 揺らぎ

## ReflectionProbeの性質を利用した演出

# 感想

デモシーンの世界では容量などの制約のある中でかっこいい映像と音楽をつくるのがロマンがあると個人的には思っていて、
今回はUnityを利用したことで圧縮後の容量が20MBもあるし、ゲームエンジンの便利な機能に依存してしまったので、
もし受け入れられなかったらどうしようとも思ったのですが、
大半の参加者に受け入れられて優勝という結果を残すことができてよかったです。

## 来年

PBRで攻めるなら今回の作戦は良さそう

NPRで攻めるなら今回の作戦は微妙

HDRPやディファードレンダリングのライティングパスの独自実装なども調査したい。

# ライブコーディングバトル